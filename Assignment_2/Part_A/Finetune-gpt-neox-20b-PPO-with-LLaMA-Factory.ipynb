{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1vdde4YmXRslZh91VbR_lS4y7h4zMtyMN","timestamp":1726509781572},{"file_id":"1eRTPn37ltBbYsISy9Aw2NuI2Aq5CQrD9","timestamp":1726384183354}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## Install Dependencies"],"metadata":{"id":"lr7rB3szzhtx"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"giM74oK1rRIH","executionInfo":{"status":"ok","timestamp":1726510059491,"user_tz":420,"elapsed":259387,"user":{"displayName":"Samarth Sharma","userId":"03778731126873596478"}},"outputId":"83ef6574-71f2-4143-db6f-189aee1878a1","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","Cloning into 'LLaMA-Factory'...\n","remote: Enumerating objects: 315, done.\u001b[K\n","remote: Counting objects: 100% (315/315), done.\u001b[K\n","remote: Compressing objects: 100% (245/245), done.\u001b[K\n","remote: Total 315 (delta 80), reused 158 (delta 57), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (315/315), 8.94 MiB | 10.96 MiB/s, done.\n","Resolving deltas: 100% (80/80), done.\n","/content/LLaMA-Factory\n","\u001b[0m\u001b[01;34massets\u001b[0m/       \u001b[01;34mdocker\u001b[0m/      LICENSE      pyproject.toml  requirements.txt  \u001b[01;34msrc\u001b[0m/\n","CITATION.cff  \u001b[01;34mevaluation\u001b[0m/  Makefile     README.md       \u001b[01;34mscripts\u001b[0m/          \u001b[01;34mtests\u001b[0m/\n","\u001b[01;34mdata\u001b[0m/         \u001b[01;34mexamples\u001b[0m/    MANIFEST.in  README_zh.md    setup.py\n","Collecting torch==2.3.1\n","  Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n","Collecting torchvision==0.18.1\n","  Downloading torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n","Collecting torchaudio==2.3.1\n","  Downloading torchaudio-2.3.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.4 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (3.16.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (1.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1) (2024.6.1)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.1)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.1)\n","  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.1)\n","  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.1)\n","  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.1)\n","  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.1)\n","  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.1)\n","  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.1)\n","  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.1)\n","  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.1)\n","  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.1)\n","  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n","Collecting triton==2.3.1 (from torch==2.3.1)\n","  Downloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.18.1) (1.26.4)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.18.1) (9.4.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.1)\n","  Downloading nvidia_nvjitlink_cu12-12.6.68-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.3.1) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.3.1) (1.3.0)\n","Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m95.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading torchaudio-2.3.1-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.68-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n","  Attempting uninstall: nvidia-nccl-cu12\n","    Found existing installation: nvidia-nccl-cu12 2.23.4\n","    Uninstalling nvidia-nccl-cu12-2.23.4:\n","      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n","  Attempting uninstall: torch\n","    Found existing installation: torch 2.4.0+cu121\n","    Uninstalling torch-2.4.0+cu121:\n","      Successfully uninstalled torch-2.4.0+cu121\n","  Attempting uninstall: torchvision\n","    Found existing installation: torchvision 0.19.0+cu121\n","    Uninstalling torchvision-0.19.0+cu121:\n","      Successfully uninstalled torchvision-0.19.0+cu121\n","  Attempting uninstall: torchaudio\n","    Found existing installation: torchaudio 2.4.0+cu121\n","    Uninstalling torchaudio-2.4.0+cu121:\n","      Successfully uninstalled torchaudio-2.4.0+cu121\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.68 nvidia-nvtx-cu12-12.1.105 torch-2.3.1 torchaudio-2.3.1 torchvision-0.18.1 triton-2.3.1\n","Found existing installation: jax 0.4.26\n","Uninstalling jax-0.4.26:\n","  Successfully uninstalled jax-0.4.26\n","Obtaining file:///content/LLaMA-Factory\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n","  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: transformers<=4.45.0,>=4.41.2 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (4.44.2)\n","Collecting datasets<=2.21.0,>=2.16.0 (from llamafactory==0.9.1.dev0)\n","  Downloading datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n","Requirement already satisfied: accelerate<=0.34.2,>=0.30.1 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (0.34.2)\n","Collecting peft<=0.12.0,>=0.11.1 (from llamafactory==0.9.1.dev0)\n","  Downloading peft-0.12.0-py3-none-any.whl.metadata (13 kB)\n","Collecting trl<=0.9.6,>=0.8.6 (from llamafactory==0.9.1.dev0)\n","  Downloading trl-0.9.6-py3-none-any.whl.metadata (12 kB)\n","Collecting gradio>=4.0.0 (from llamafactory==0.9.1.dev0)\n","  Downloading gradio-4.44.0-py3-none-any.whl.metadata (15 kB)\n","Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (2.1.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (1.13.1)\n","Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (0.8.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (0.1.99)\n","Collecting tiktoken (from llamafactory==0.9.1.dev0)\n","  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (3.20.3)\n","Collecting uvicorn (from llamafactory==0.9.1.dev0)\n","  Downloading uvicorn-0.30.6-py3-none-any.whl.metadata (6.6 kB)\n","Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (2.9.1)\n","Collecting fastapi (from llamafactory==0.9.1.dev0)\n","  Downloading fastapi-0.114.2-py3-none-any.whl.metadata (27 kB)\n","Collecting sse-starlette (from llamafactory==0.9.1.dev0)\n","  Downloading sse_starlette-2.1.3-py3-none-any.whl.metadata (5.8 kB)\n","Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (3.7.1)\n","Collecting fire (from llamafactory==0.9.1.dev0)\n","  Downloading fire-0.6.0.tar.gz (88 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.4/88.4 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (24.1)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (6.0.2)\n","Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (1.26.4)\n","Collecting liger-kernel (from llamafactory==0.9.1.dev0)\n","  Downloading liger_kernel-0.3.0-py3-none-any.whl.metadata (25 kB)\n","Collecting bitsandbytes>=0.39.0 (from llamafactory==0.9.1.dev0)\n","  Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n","Requirement already satisfied: torch>=1.13.1 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.9.1.dev0) (2.3.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate<=0.34.2,>=0.30.1->llamafactory==0.9.1.dev0) (5.9.5)\n","Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate<=0.34.2,>=0.30.1->llamafactory==0.9.1.dev0) (0.24.7)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate<=0.34.2,>=0.30.1->llamafactory==0.9.1.dev0) (0.4.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (3.16.0)\n","Collecting pyarrow>=15.0.0 (from datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0)\n","  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (4.66.5)\n","Collecting xxhash (from datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0)\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess (from datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (2024.6.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (3.10.5)\n","Collecting aiofiles<24.0,>=22.0 (from gradio>=4.0.0->llamafactory==0.9.1.dev0)\n","  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n","Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.9.1.dev0) (3.7.1)\n","Collecting ffmpy (from gradio>=4.0.0->llamafactory==0.9.1.dev0)\n","  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n","Collecting gradio-client==1.3.0 (from gradio>=4.0.0->llamafactory==0.9.1.dev0)\n","  Downloading gradio_client-1.3.0-py3-none-any.whl.metadata (7.1 kB)\n","Collecting httpx>=0.24.1 (from gradio>=4.0.0->llamafactory==0.9.1.dev0)\n","  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n","Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.9.1.dev0) (6.4.5)\n","Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.9.1.dev0) (3.1.4)\n","Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.9.1.dev0) (2.1.5)\n","Collecting orjson~=3.0 (from gradio>=4.0.0->llamafactory==0.9.1.dev0)\n","  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.9.1.dev0) (9.4.0)\n","Collecting pydub (from gradio>=4.0.0->llamafactory==0.9.1.dev0)\n","  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n","Collecting python-multipart>=0.0.9 (from gradio>=4.0.0->llamafactory==0.9.1.dev0)\n","  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n","Collecting ruff>=0.2.2 (from gradio>=4.0.0->llamafactory==0.9.1.dev0)\n","  Downloading ruff-0.6.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n","Collecting semantic-version~=2.0 (from gradio>=4.0.0->llamafactory==0.9.1.dev0)\n","  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n","Collecting tomlkit==0.12.0 (from gradio>=4.0.0->llamafactory==0.9.1.dev0)\n","  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n","Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.9.1.dev0) (0.12.5)\n","Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.9.1.dev0) (4.12.2)\n","Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.9.1.dev0) (2.0.7)\n","Collecting websockets<13.0,>=10.0 (from gradio-client==1.3.0->gradio>=4.0.0->llamafactory==0.9.1.dev0)\n","  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Collecting starlette<0.39.0,>=0.37.2 (from fastapi->llamafactory==0.9.1.dev0)\n","  Downloading starlette-0.38.5-py3-none-any.whl.metadata (6.0 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.1.dev0) (1.3.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.1.dev0) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.1.dev0) (4.53.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.1.dev0) (1.4.7)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.1.dev0) (3.1.4)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.9.1.dev0) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->llamafactory==0.9.1.dev0) (2024.2)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->llamafactory==0.9.1.dev0) (2024.1)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->llamafactory==0.9.1.dev0) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.3 in /usr/local/lib/python3.10/dist-packages (from pydantic->llamafactory==0.9.1.dev0) (2.23.3)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->llamafactory==0.9.1.dev0) (1.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->llamafactory==0.9.1.dev0) (3.3)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->llamafactory==0.9.1.dev0) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->llamafactory==0.9.1.dev0) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->llamafactory==0.9.1.dev0) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->llamafactory==0.9.1.dev0) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->llamafactory==0.9.1.dev0) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->llamafactory==0.9.1.dev0) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->llamafactory==0.9.1.dev0) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->llamafactory==0.9.1.dev0) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->llamafactory==0.9.1.dev0) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->llamafactory==0.9.1.dev0) (2.20.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->llamafactory==0.9.1.dev0) (12.1.105)\n","Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->llamafactory==0.9.1.dev0) (2.3.1)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.1->llamafactory==0.9.1.dev0) (12.6.68)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.45.0,>=4.41.2->llamafactory==0.9.1.dev0) (2024.5.15)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.45.0,>=4.41.2->llamafactory==0.9.1.dev0) (0.19.1)\n","Collecting tyro>=0.5.11 (from trl<=0.9.6,>=0.8.6->llamafactory==0.9.1.dev0)\n","  Downloading tyro-0.8.10-py3-none-any.whl.metadata (8.4 kB)\n","Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn->llamafactory==0.9.1.dev0) (8.1.7)\n","Collecting h11>=0.8 (from uvicorn->llamafactory==0.9.1.dev0)\n","  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire->llamafactory==0.9.1.dev0) (1.16.0)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->llamafactory==0.9.1.dev0) (2.4.0)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio>=4.0.0->llamafactory==0.9.1.dev0) (3.8)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio>=4.0.0->llamafactory==0.9.1.dev0) (1.3.1)\n","Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio>=4.0.0->llamafactory==0.9.1.dev0) (1.2.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (2.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (1.11.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (4.0.3)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio>=4.0.0->llamafactory==0.9.1.dev0) (2024.8.30)\n","Collecting httpcore==1.* (from httpx>=0.24.1->gradio>=4.0.0->llamafactory==0.9.1.dev0)\n","  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets<=2.21.0,>=2.16.0->llamafactory==0.9.1.dev0) (3.3.2)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.9.1.dev0) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.9.1.dev0) (13.8.1)\n","Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl<=0.9.6,>=0.8.6->llamafactory==0.9.1.dev0) (0.16)\n","Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl<=0.9.6,>=0.8.6->llamafactory==0.9.1.dev0)\n","  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.1->llamafactory==0.9.1.dev0) (1.3.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.9.1.dev0) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.9.1.dev0) (2.16.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.9.1.dev0) (0.1.2)\n","Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl (137.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading datasets-2.21.0-py3-none-any.whl (527 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.3/527.3 kB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gradio-4.44.0-py3-none-any.whl (18.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading gradio_client-1.3.0-py3-none-any.whl (318 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n","Downloading fastapi-0.114.2-py3-none-any.whl (94 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.0/94.0 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading peft-0.12.0-py3-none-any.whl (296 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.4/296.4 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading trl-0.9.6-py3-none-any.whl (245 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.8/245.8 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading uvicorn-0.30.6-py3-none-any.whl (62 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading liger_kernel-0.3.0-py3-none-any.whl (58 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading sse_starlette-2.1.3-py3-none-any.whl (9.4 kB)\n","Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n","Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n","Downloading ruff-0.6.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m105.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n","Downloading starlette-0.38.5-py3-none-any.whl (71 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tyro-0.8.10-py3-none-any.whl (105 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.7/105.7 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n","Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n","Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\n","Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: llamafactory, fire\n","  Building editable for llamafactory (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for llamafactory: filename=llamafactory-0.9.1.dev0-0.editable-py3-none-any.whl size=22355 sha256=3aeb33682e6fffe7c9c6335a3d31a29d57b93c4de3e40617ddb916e3bfc16edf\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-vx4x6jm1/wheels/de/aa/c5/27b5682c5592b7c0eecc3e208f176dedf6b11a61cf2a910b85\n","  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fire: filename=fire-0.6.0-py2.py3-none-any.whl size=117030 sha256=93828a08cf5e1c1807b11a5f3c2c2f93ba5fd95fac7d7bb7e8a6eb127f78e743\n","  Stored in directory: /root/.cache/pip/wheels/d6/6d/5d/5b73fa0f46d01a793713f8859201361e9e581ced8c75e5c6a3\n","Successfully built llamafactory fire\n","Installing collected packages: pydub, xxhash, websockets, tomlkit, shtab, semantic-version, ruff, python-multipart, pyarrow, orjson, h11, fire, ffmpy, dill, aiofiles, uvicorn, tiktoken, starlette, multiprocess, httpcore, tyro, sse-starlette, httpx, fastapi, gradio-client, bitsandbytes, peft, liger-kernel, gradio, datasets, trl, llamafactory\n","  Attempting uninstall: tomlkit\n","    Found existing installation: tomlkit 0.13.2\n","    Uninstalling tomlkit-0.13.2:\n","      Successfully uninstalled tomlkit-0.13.2\n","  Attempting uninstall: pyarrow\n","    Found existing installation: pyarrow 14.0.2\n","    Uninstalling pyarrow-14.0.2:\n","      Successfully uninstalled pyarrow-14.0.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n","ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed aiofiles-23.2.1 bitsandbytes-0.43.3 datasets-2.21.0 dill-0.3.8 fastapi-0.114.2 ffmpy-0.4.0 fire-0.6.0 gradio-4.44.0 gradio-client-1.3.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 liger-kernel-0.3.0 llamafactory-0.9.1.dev0 multiprocess-0.70.16 orjson-3.10.7 peft-0.12.0 pyarrow-17.0.0 pydub-0.25.1 python-multipart-0.0.9 ruff-0.6.5 semantic-version-2.10.0 shtab-1.7.1 sse-starlette-2.1.3 starlette-0.38.5 tiktoken-0.7.0 tomlkit-0.12.0 trl-0.9.6 tyro-0.8.10 uvicorn-0.30.6 websockets-12.0 xxhash-3.5.0\n"]}],"source":["%cd /content/\n","%rm -rf LLaMA-Factory\n","!git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git\n","%cd LLaMA-Factory\n","%ls\n","!pip install torch==2.3.1 torchvision==0.18.1 torchaudio==2.3.1\n","!pip uninstall -y jax\n","!pip install -e .[torch,bitsandbytes,liger-kernel]"]},{"cell_type":"markdown","source":["### Check GPU environment"],"metadata":{"id":"H9RXn_YQnn9f"}},{"cell_type":"code","source":["import torch\n","try:\n","  assert torch.cuda.is_available() is True\n","except AssertionError:\n","  print(\"Please set up a GPU before using LLaMA Factory\")"],"metadata":{"id":"ZkN-ktlsnrdU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!huggingface-cli login"],"metadata":{"id":"mcNcHcA4bf4Z","executionInfo":{"status":"ok","timestamp":1726510082946,"user_tz":420,"elapsed":15849,"user":{"displayName":"Samarth Sharma","userId":"03778731126873596478"}},"outputId":"1c595087-6a39-480e-8993-1ef57a0f1472","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n","    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n","    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n","    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n","    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n","\n","    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n","Enter your token (input will not be visible): \n","Add token as git credential? (Y/n) n\n","Token is valid (permission: read).\n","Your token has been saved to /root/.cache/huggingface/token\n","Login successful\n"]}]},{"cell_type":"markdown","source":["## Fine-tune model via LLaMA Board"],"metadata":{"id":"2QiXcvdzzW3Y"}},{"cell_type":"code","source":["%cd /content/LLaMA-Factory/\n","!GRADIO_SHARE=1 llamafactory-cli webui"],"metadata":{"id":"YLsdS6V5yUMy","outputId":"c74ec72e-8dea-4d7e-d7eb-4342b95ce25e","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/LLaMA-Factory\n","2024-09-16 18:08:13.628689: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-09-16 18:08:13.849185: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-09-16 18:08:13.911452: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-09-16 18:08:14.272605: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-09-16 18:08:16.351834: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Running on local URL:  http://0.0.0.0:7860\n","Running on public URL: https://36fbde3effdae4a575.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n","09/16/2024 18:14:31 - WARNING - llamafactory.webui.common - Found complex path, some features may be not available.\n","2024-09-16 18:14:36.019455: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-09-16 18:14:36.053527: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-09-16 18:14:36.064623: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-09-16 18:14:36.087759: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-09-16 18:14:37.669493: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","09/16/2024 18:14:42 - INFO - llamafactory.hparams.parser - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, compute dtype: torch.bfloat16\n","config.json: 100% 736/736 [00:00<00:00, 5.89MB/s]\n","[INFO|configuration_utils.py:733] 2024-09-16 18:14:42,471 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/config.json\n","[INFO|configuration_utils.py:800] 2024-09-16 18:14:42,474 >> Model config PhiConfig {\n","  \"_name_or_path\": \"microsoft/phi-1_5\",\n","  \"architectures\": [\n","    \"PhiForCausalLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": null,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": null,\n","  \"hidden_act\": \"gelu_new\",\n","  \"hidden_size\": 2048,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 2048,\n","  \"model_type\": \"phi\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 24,\n","  \"num_key_value_heads\": 32,\n","  \"partial_rotary_factor\": 0.5,\n","  \"qk_layernorm\": false,\n","  \"resid_pdrop\": 0.0,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"float16\",\n","  \"transformers_version\": \"4.44.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 51200\n","}\n","\n","tokenizer_config.json: 100% 237/237 [00:00<00:00, 1.44MB/s]\n","vocab.json: 100% 798k/798k [00:00<00:00, 2.44MB/s]\n","merges.txt: 100% 456k/456k [00:00<00:00, 1.86MB/s]\n","tokenizer.json: 100% 2.11M/2.11M [00:00<00:00, 12.5MB/s]\n","added_tokens.json: 100% 1.08k/1.08k [00:00<00:00, 8.36MB/s]\n","special_tokens_map.json: 100% 99.0/99.0 [00:00<00:00, 907kB/s]\n","[INFO|tokenization_utils_base.py:2269] 2024-09-16 18:14:44,545 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/vocab.json\n","[INFO|tokenization_utils_base.py:2269] 2024-09-16 18:14:44,545 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/merges.txt\n","[INFO|tokenization_utils_base.py:2269] 2024-09-16 18:14:44,545 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/tokenizer.json\n","[INFO|tokenization_utils_base.py:2269] 2024-09-16 18:14:44,545 >> loading file added_tokens.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/added_tokens.json\n","[INFO|tokenization_utils_base.py:2269] 2024-09-16 18:14:44,545 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2269] 2024-09-16 18:14:44,546 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/tokenizer_config.json\n","[INFO|configuration_utils.py:733] 2024-09-16 18:14:45,094 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/config.json\n","[INFO|configuration_utils.py:800] 2024-09-16 18:14:45,095 >> Model config PhiConfig {\n","  \"_name_or_path\": \"microsoft/phi-1_5\",\n","  \"architectures\": [\n","    \"PhiForCausalLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": null,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": null,\n","  \"hidden_act\": \"gelu_new\",\n","  \"hidden_size\": 2048,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 2048,\n","  \"model_type\": \"phi\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 24,\n","  \"num_key_value_heads\": 32,\n","  \"partial_rotary_factor\": 0.5,\n","  \"qk_layernorm\": false,\n","  \"resid_pdrop\": 0.0,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"float16\",\n","  \"transformers_version\": \"4.44.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 51200\n","}\n","\n","[INFO|tokenization_utils_base.py:2269] 2024-09-16 18:14:45,199 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/vocab.json\n","[INFO|tokenization_utils_base.py:2269] 2024-09-16 18:14:45,199 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/merges.txt\n","[INFO|tokenization_utils_base.py:2269] 2024-09-16 18:14:45,199 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/tokenizer.json\n","[INFO|tokenization_utils_base.py:2269] 2024-09-16 18:14:45,200 >> loading file added_tokens.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/added_tokens.json\n","[INFO|tokenization_utils_base.py:2269] 2024-09-16 18:14:45,200 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2269] 2024-09-16 18:14:45,200 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/tokenizer_config.json\n","09/16/2024 18:14:45 - INFO - llamafactory.data.template - Add pad token: <|endoftext|>\n","09/16/2024 18:14:45 - INFO - llamafactory.data.loader - Loading dataset alpaca_en_demo.json...\n","Generating train split: 1000 examples [00:00, 20300.98 examples/s]\n","Converting format of dataset (num_proc=16): 100% 500/500 [00:00<00:00, 877.67 examples/s] \n","Running tokenizer on dataset (num_proc=16): 100% 500/500 [00:03<00:00, 142.04 examples/s]\n","training example:\n","input_ids:\n","[20490, 25, 39373, 4892, 257, 1429, 286, 1642, 1126, 12272, 13, 198, 48902, 25]\n","inputs:\n","Human: Describe a process of making crepes.\n","Assistant:\n","[INFO|configuration_utils.py:733] 2024-09-16 18:14:50,862 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/config.json\n","[INFO|configuration_utils.py:800] 2024-09-16 18:14:50,864 >> Model config PhiConfig {\n","  \"_name_or_path\": \"microsoft/phi-1_5\",\n","  \"architectures\": [\n","    \"PhiForCausalLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": null,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": null,\n","  \"hidden_act\": \"gelu_new\",\n","  \"hidden_size\": 2048,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 2048,\n","  \"model_type\": \"phi\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 24,\n","  \"num_key_value_heads\": 32,\n","  \"partial_rotary_factor\": 0.5,\n","  \"qk_layernorm\": false,\n","  \"resid_pdrop\": 0.0,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"float16\",\n","  \"transformers_version\": \"4.44.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 51200\n","}\n","\n","model.safetensors: 100% 2.84G/2.84G [00:29<00:00, 94.6MB/s]\n","[INFO|modeling_utils.py:3678] 2024-09-16 18:15:21,268 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/model.safetensors\n","[INFO|modeling_utils.py:1606] 2024-09-16 18:15:21,403 >> Instantiating PhiForCausalLM model under default dtype torch.bfloat16.\n","[INFO|configuration_utils.py:1038] 2024-09-16 18:15:21,406 >> Generate config GenerationConfig {}\n","\n","[INFO|modeling_utils.py:4507] 2024-09-16 18:15:26,942 >> All model checkpoint weights were used when initializing PhiForCausalLM.\n","\n","[INFO|modeling_utils.py:4515] 2024-09-16 18:15:26,943 >> All the weights of PhiForCausalLM were initialized from the model checkpoint at microsoft/phi-1_5.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use PhiForCausalLM for predictions without further training.\n","generation_config.json: 100% 74.0/74.0 [00:00<00:00, 575kB/s]\n","[INFO|configuration_utils.py:993] 2024-09-16 18:15:27,168 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/generation_config.json\n","[INFO|configuration_utils.py:1038] 2024-09-16 18:15:27,169 >> Generate config GenerationConfig {}\n","\n","09/16/2024 18:15:27 - INFO - llamafactory.model.model_utils.checkpointing - Gradient checkpointing enabled.\n","09/16/2024 18:15:27 - INFO - llamafactory.model.model_utils.attention - Using torch SDPA for faster training and inference.\n","09/16/2024 18:15:27 - INFO - llamafactory.model.adapter - Upcasting trainable params to float32.\n","09/16/2024 18:15:27 - INFO - llamafactory.model.adapter - Fine-tuning method: LoRA\n","09/16/2024 18:15:27 - INFO - llamafactory.model.model_utils.misc - Found linear modules: dense,q_proj,fc1,v_proj,fc2,k_proj\n","09/16/2024 18:15:28 - INFO - llamafactory.model.model_utils.valuehead - Provided path (microsoft/phi-1_5) does not contain value head weights: microsoft/phi-1_5 does not appear to have a file named value_head.bin. Checkout 'https://huggingface.co/microsoft/phi-1_5/tree/main' for available files..\n","09/16/2024 18:15:28 - INFO - llamafactory.model.model_utils.valuehead - Ignore the above message if you are not resuming the training of a value head model.\n","09/16/2024 18:15:28 - INFO - llamafactory.model.loader - trainable params: 1,771,521 || all params: 1,420,042,241 || trainable%: 0.1248\n","adapter_config.json: 100% 1.05k/1.05k [00:00<00:00, 6.91MB/s]\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/llamafactory-cli\", line 8, in <module>\n","    sys.exit(main())\n","  File \"/content/LLaMA-Factory/src/llamafactory/cli.py\", line 111, in main\n","    run_exp()\n","  File \"/content/LLaMA-Factory/src/llamafactory/train/tuner.py\", line 54, in run_exp\n","    run_ppo(model_args, data_args, training_args, finetuning_args, generating_args, callbacks)\n","  File \"/content/LLaMA-Factory/src/llamafactory/train/ppo/workflow.py\", line 53, in run_ppo\n","    reward_model = create_reward_model(model, model_args, finetuning_args)\n","  File \"/content/LLaMA-Factory/src/llamafactory/train/trainer_utils.py\", line 146, in create_reward_model\n","    model.pretrained_model.load_adapter(finetuning_args.reward_model, \"reward\")\n","  File \"/usr/local/lib/python3.10/dist-packages/peft/peft_model.py\", line 1098, in load_adapter\n","    PeftConfig._get_peft_type(\n","  File \"/usr/local/lib/python3.10/dist-packages/peft/config.py\", line 214, in _get_peft_type\n","    return loaded_attributes[\"peft_type\"]\n","KeyError: 'peft_type'\n","09/16/2024 18:26:11 - WARNING - llamafactory.webui.common - Found complex path, some features may be not available.\n","2024-09-16 18:26:15.065605: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-09-16 18:26:15.098861: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-09-16 18:26:15.110984: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-09-16 18:26:15.131616: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-09-16 18:26:16.839345: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","09/16/2024 18:26:22 - INFO - llamafactory.hparams.parser - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, compute dtype: torch.bfloat16\n","[INFO|configuration_utils.py:733] 2024-09-16 18:26:22,286 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/config.json\n","[INFO|configuration_utils.py:800] 2024-09-16 18:26:22,288 >> Model config PhiConfig {\n","  \"_name_or_path\": \"microsoft/phi-1_5\",\n","  \"architectures\": [\n","    \"PhiForCausalLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": null,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": null,\n","  \"hidden_act\": \"gelu_new\",\n","  \"hidden_size\": 2048,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 2048,\n","  \"model_type\": \"phi\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 24,\n","  \"num_key_value_heads\": 32,\n","  \"partial_rotary_factor\": 0.5,\n","  \"qk_layernorm\": false,\n","  \"resid_pdrop\": 0.0,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"float16\",\n","  \"transformers_version\": \"4.44.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 51200\n","}\n","\n","[INFO|tokenization_utils_base.py:2269] 2024-09-16 18:26:22,396 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/vocab.json\n","[INFO|tokenization_utils_base.py:2269] 2024-09-16 18:26:22,396 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/merges.txt\n","[INFO|tokenization_utils_base.py:2269] 2024-09-16 18:26:22,396 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/tokenizer.json\n","[INFO|tokenization_utils_base.py:2269] 2024-09-16 18:26:22,396 >> loading file added_tokens.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/added_tokens.json\n","[INFO|tokenization_utils_base.py:2269] 2024-09-16 18:26:22,397 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2269] 2024-09-16 18:26:22,397 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/tokenizer_config.json\n","[INFO|configuration_utils.py:733] 2024-09-16 18:26:22,929 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/config.json\n","[INFO|configuration_utils.py:800] 2024-09-16 18:26:22,930 >> Model config PhiConfig {\n","  \"_name_or_path\": \"microsoft/phi-1_5\",\n","  \"architectures\": [\n","    \"PhiForCausalLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": null,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": null,\n","  \"hidden_act\": \"gelu_new\",\n","  \"hidden_size\": 2048,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 2048,\n","  \"model_type\": \"phi\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 24,\n","  \"num_key_value_heads\": 32,\n","  \"partial_rotary_factor\": 0.5,\n","  \"qk_layernorm\": false,\n","  \"resid_pdrop\": 0.0,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"float16\",\n","  \"transformers_version\": \"4.44.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 51200\n","}\n","\n","[INFO|tokenization_utils_base.py:2269] 2024-09-16 18:26:23,037 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/vocab.json\n","[INFO|tokenization_utils_base.py:2269] 2024-09-16 18:26:23,037 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/merges.txt\n","[INFO|tokenization_utils_base.py:2269] 2024-09-16 18:26:23,037 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/tokenizer.json\n","[INFO|tokenization_utils_base.py:2269] 2024-09-16 18:26:23,037 >> loading file added_tokens.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/added_tokens.json\n","[INFO|tokenization_utils_base.py:2269] 2024-09-16 18:26:23,038 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2269] 2024-09-16 18:26:23,038 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/tokenizer_config.json\n","09/16/2024 18:26:23 - INFO - llamafactory.data.template - Add pad token: <|endoftext|>\n","09/16/2024 18:26:23 - INFO - llamafactory.data.loader - Loading dataset alpaca_en_demo.json...\n","training example:\n","input_ids:\n","[20490, 25, 39373, 4892, 257, 1429, 286, 1642, 1126, 12272, 13, 198, 48902, 25]\n","inputs:\n","Human: Describe a process of making crepes.\n","Assistant:\n","[INFO|configuration_utils.py:733] 2024-09-16 18:26:23,711 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/config.json\n","[INFO|configuration_utils.py:800] 2024-09-16 18:26:23,712 >> Model config PhiConfig {\n","  \"_name_or_path\": \"microsoft/phi-1_5\",\n","  \"architectures\": [\n","    \"PhiForCausalLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": null,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": null,\n","  \"hidden_act\": \"gelu_new\",\n","  \"hidden_size\": 2048,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 2048,\n","  \"model_type\": \"phi\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 24,\n","  \"num_key_value_heads\": 32,\n","  \"partial_rotary_factor\": 0.5,\n","  \"qk_layernorm\": false,\n","  \"resid_pdrop\": 0.0,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"float16\",\n","  \"transformers_version\": \"4.44.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 51200\n","}\n","\n","[INFO|modeling_utils.py:3678] 2024-09-16 18:26:23,749 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/model.safetensors\n","[INFO|modeling_utils.py:1606] 2024-09-16 18:26:23,763 >> Instantiating PhiForCausalLM model under default dtype torch.bfloat16.\n","[INFO|configuration_utils.py:1038] 2024-09-16 18:26:23,766 >> Generate config GenerationConfig {}\n","\n","[INFO|modeling_utils.py:4507] 2024-09-16 18:26:28,827 >> All model checkpoint weights were used when initializing PhiForCausalLM.\n","\n","[INFO|modeling_utils.py:4515] 2024-09-16 18:26:28,827 >> All the weights of PhiForCausalLM were initialized from the model checkpoint at microsoft/phi-1_5.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use PhiForCausalLM for predictions without further training.\n","[INFO|configuration_utils.py:993] 2024-09-16 18:26:28,942 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/generation_config.json\n","[INFO|configuration_utils.py:1038] 2024-09-16 18:26:28,942 >> Generate config GenerationConfig {}\n","\n","09/16/2024 18:26:28 - INFO - llamafactory.model.model_utils.checkpointing - Gradient checkpointing enabled.\n","09/16/2024 18:26:28 - INFO - llamafactory.model.model_utils.attention - Using torch SDPA for faster training and inference.\n","09/16/2024 18:26:28 - INFO - llamafactory.model.adapter - Upcasting trainable params to float32.\n","09/16/2024 18:26:28 - INFO - llamafactory.model.adapter - Fine-tuning method: LoRA\n","09/16/2024 18:26:28 - INFO - llamafactory.model.model_utils.misc - Found linear modules: fc1,v_proj,dense,k_proj,fc2,q_proj\n","09/16/2024 18:26:29 - INFO - llamafactory.model.model_utils.valuehead - Provided path (microsoft/phi-1_5) does not contain value head weights: microsoft/phi-1_5 does not appear to have a file named value_head.bin. Checkout 'https://huggingface.co/microsoft/phi-1_5/tree/main' for available files..\n","09/16/2024 18:26:29 - INFO - llamafactory.model.model_utils.valuehead - Ignore the above message if you are not resuming the training of a value head model.\n","09/16/2024 18:26:29 - INFO - llamafactory.model.loader - trainable params: 1,771,521 || all params: 1,420,042,241 || trainable%: 0.1248\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\", line 304, in hf_raise_for_status\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.10/dist-packages/requests/models.py\", line 1024, in raise_for_status\n","    raise HTTPError(http_error_msg, response=self)\n","requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/smangrul/mistral_lora_clm_with_added_tokens/resolve/main/adapter_config.json\n","\n","The above exception was the direct cause of the following exception:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/peft/config.py\", line 205, in _get_peft_type\n","    config_file = hf_hub_download(\n","  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py\", line 101, in inner_f\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n","    return fn(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\", line 1240, in hf_hub_download\n","    return _hf_hub_download_to_cache_dir(\n","  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\", line 1347, in _hf_hub_download_to_cache_dir\n","    _raise_on_head_call_error(head_call_error, force_download, local_files_only)\n","  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\", line 1855, in _raise_on_head_call_error\n","    raise head_call_error\n","  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\", line 1752, in _get_metadata_or_catch_error\n","    metadata = get_hf_file_metadata(\n","  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n","    return fn(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\", line 1674, in get_hf_file_metadata\n","    r = _request_wrapper(\n","  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\", line 376, in _request_wrapper\n","    response = _request_wrapper(\n","  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\", line 400, in _request_wrapper\n","    hf_raise_for_status(response)\n","  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\", line 352, in hf_raise_for_status\n","    raise RepositoryNotFoundError(message, response) from e\n","huggingface_hub.utils._errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-66e87855-414eea1a7f7773e7101a43f5;51b0d27d-2380-4de2-b114-751f16600995)\n","\n","Repository Not Found for url: https://huggingface.co/smangrul/mistral_lora_clm_with_added_tokens/resolve/main/adapter_config.json.\n","Please make sure you specified the correct `repo_id` and `repo_type`.\n","If you are trying to access a private or gated repo, make sure you are authenticated.\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/llamafactory-cli\", line 8, in <module>\n","    sys.exit(main())\n","  File \"/content/LLaMA-Factory/src/llamafactory/cli.py\", line 111, in main\n","    run_exp()\n","  File \"/content/LLaMA-Factory/src/llamafactory/train/tuner.py\", line 54, in run_exp\n","    run_ppo(model_args, data_args, training_args, finetuning_args, generating_args, callbacks)\n","  File \"/content/LLaMA-Factory/src/llamafactory/train/ppo/workflow.py\", line 53, in run_ppo\n","    reward_model = create_reward_model(model, model_args, finetuning_args)\n","  File \"/content/LLaMA-Factory/src/llamafactory/train/trainer_utils.py\", line 146, in create_reward_model\n","    model.pretrained_model.load_adapter(finetuning_args.reward_model, \"reward\")\n","  File \"/usr/local/lib/python3.10/dist-packages/peft/peft_model.py\", line 1098, in load_adapter\n","    PeftConfig._get_peft_type(\n","  File \"/usr/local/lib/python3.10/dist-packages/peft/config.py\", line 211, in _get_peft_type\n","    raise ValueError(f\"Can't find '{CONFIG_NAME}' at '{model_id}'\")\n","ValueError: Can't find 'adapter_config.json' at 'smangrul/mistral_lora_clm_with_added_tokens'\n","09/16/2024 18:29:20 - WARNING - llamafactory.webui.common - Found complex path, some features may be not available.\n","2024-09-16 18:29:24.054099: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-09-16 18:29:24.075230: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-09-16 18:29:24.081429: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-09-16 18:29:24.096882: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-09-16 18:29:25.249813: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","09/16/2024 18:29:31 - INFO - llamafactory.hparams.parser - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, compute dtype: torch.bfloat16\n","[INFO|configuration_utils.py:733] 2024-09-16 18:29:31,582 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/config.json\n","[INFO|configuration_utils.py:800] 2024-09-16 18:29:31,584 >> Model config PhiConfig {\n","  \"_name_or_path\": \"microsoft/phi-1_5\",\n","  \"architectures\": [\n","    \"PhiForCausalLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": null,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": null,\n","  \"hidden_act\": \"gelu_new\",\n","  \"hidden_size\": 2048,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 2048,\n","  \"model_type\": \"phi\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 24,\n","  \"num_key_value_heads\": 32,\n","  \"partial_rotary_factor\": 0.5,\n","  \"qk_layernorm\": false,\n","  \"resid_pdrop\": 0.0,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"float16\",\n","  \"transformers_version\": \"4.44.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 51200\n","}\n","\n","[INFO|tokenization_utils_base.py:2269] 2024-09-16 18:29:31,693 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/vocab.json\n","[INFO|tokenization_utils_base.py:2269] 2024-09-16 18:29:31,693 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/merges.txt\n","[INFO|tokenization_utils_base.py:2269] 2024-09-16 18:29:31,693 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/tokenizer.json\n","[INFO|tokenization_utils_base.py:2269] 2024-09-16 18:29:31,693 >> loading file added_tokens.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/added_tokens.json\n","[INFO|tokenization_utils_base.py:2269] 2024-09-16 18:29:31,693 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2269] 2024-09-16 18:29:31,693 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/tokenizer_config.json\n","[INFO|configuration_utils.py:733] 2024-09-16 18:29:32,284 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/config.json\n","[INFO|configuration_utils.py:800] 2024-09-16 18:29:32,285 >> Model config PhiConfig {\n","  \"_name_or_path\": \"microsoft/phi-1_5\",\n","  \"architectures\": [\n","    \"PhiForCausalLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": null,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": null,\n","  \"hidden_act\": \"gelu_new\",\n","  \"hidden_size\": 2048,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 2048,\n","  \"model_type\": \"phi\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 24,\n","  \"num_key_value_heads\": 32,\n","  \"partial_rotary_factor\": 0.5,\n","  \"qk_layernorm\": false,\n","  \"resid_pdrop\": 0.0,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"float16\",\n","  \"transformers_version\": \"4.44.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 51200\n","}\n","\n","[INFO|tokenization_utils_base.py:2269] 2024-09-16 18:29:32,392 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/vocab.json\n","[INFO|tokenization_utils_base.py:2269] 2024-09-16 18:29:32,392 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/merges.txt\n","[INFO|tokenization_utils_base.py:2269] 2024-09-16 18:29:32,392 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/tokenizer.json\n","[INFO|tokenization_utils_base.py:2269] 2024-09-16 18:29:32,392 >> loading file added_tokens.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/added_tokens.json\n","[INFO|tokenization_utils_base.py:2269] 2024-09-16 18:29:32,393 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2269] 2024-09-16 18:29:32,393 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/tokenizer_config.json\n","09/16/2024 18:29:32 - INFO - llamafactory.data.template - Add pad token: <|endoftext|>\n","09/16/2024 18:29:32 - INFO - llamafactory.data.loader - Loading dataset alpaca_en_demo.json...\n","training example:\n","input_ids:\n","[20490, 25, 39373, 4892, 257, 1429, 286, 1642, 1126, 12272, 13, 198, 48902, 25]\n","inputs:\n","Human: Describe a process of making crepes.\n","Assistant:\n","[INFO|configuration_utils.py:733] 2024-09-16 18:29:33,054 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/config.json\n","[INFO|configuration_utils.py:800] 2024-09-16 18:29:33,055 >> Model config PhiConfig {\n","  \"_name_or_path\": \"microsoft/phi-1_5\",\n","  \"architectures\": [\n","    \"PhiForCausalLM\"\n","  ],\n","  \"attention_dropout\": 0.0,\n","  \"bos_token_id\": null,\n","  \"embd_pdrop\": 0.0,\n","  \"eos_token_id\": null,\n","  \"hidden_act\": \"gelu_new\",\n","  \"hidden_size\": 2048,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 8192,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 2048,\n","  \"model_type\": \"phi\",\n","  \"num_attention_heads\": 32,\n","  \"num_hidden_layers\": 24,\n","  \"num_key_value_heads\": 32,\n","  \"partial_rotary_factor\": 0.5,\n","  \"qk_layernorm\": false,\n","  \"resid_pdrop\": 0.0,\n","  \"rope_scaling\": null,\n","  \"rope_theta\": 10000.0,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"float16\",\n","  \"transformers_version\": \"4.44.2\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 51200\n","}\n","\n","[INFO|modeling_utils.py:3678] 2024-09-16 18:29:33,089 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/model.safetensors\n","[INFO|modeling_utils.py:1606] 2024-09-16 18:29:33,103 >> Instantiating PhiForCausalLM model under default dtype torch.bfloat16.\n","[INFO|configuration_utils.py:1038] 2024-09-16 18:29:33,105 >> Generate config GenerationConfig {}\n","\n","[INFO|modeling_utils.py:4507] 2024-09-16 18:29:38,118 >> All model checkpoint weights were used when initializing PhiForCausalLM.\n","\n","[INFO|modeling_utils.py:4515] 2024-09-16 18:29:38,118 >> All the weights of PhiForCausalLM were initialized from the model checkpoint at microsoft/phi-1_5.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use PhiForCausalLM for predictions without further training.\n","[INFO|configuration_utils.py:993] 2024-09-16 18:29:38,229 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--microsoft--phi-1_5/snapshots/675aa382d814580b22651a30acb1a585d7c25963/generation_config.json\n","[INFO|configuration_utils.py:1038] 2024-09-16 18:29:38,230 >> Generate config GenerationConfig {}\n","\n","09/16/2024 18:29:38 - INFO - llamafactory.model.model_utils.checkpointing - Gradient checkpointing enabled.\n","09/16/2024 18:29:38 - INFO - llamafactory.model.model_utils.attention - Using torch SDPA for faster training and inference.\n","09/16/2024 18:29:38 - INFO - llamafactory.model.adapter - Upcasting trainable params to float32.\n","09/16/2024 18:29:38 - INFO - llamafactory.model.adapter - Fine-tuning method: LoRA\n","09/16/2024 18:29:38 - INFO - llamafactory.model.model_utils.misc - Found linear modules: k_proj,dense,fc2,q_proj,fc1,v_proj\n","09/16/2024 18:29:38 - INFO - llamafactory.model.model_utils.valuehead - Provided path (microsoft/phi-1_5) does not contain value head weights: microsoft/phi-1_5 does not appear to have a file named value_head.bin. Checkout 'https://huggingface.co/microsoft/phi-1_5/tree/main' for available files..\n","09/16/2024 18:29:38 - INFO - llamafactory.model.model_utils.valuehead - Ignore the above message if you are not resuming the training of a value head model.\n","09/16/2024 18:29:38 - INFO - llamafactory.model.loader - trainable params: 1,771,521 || all params: 1,420,042,241 || trainable%: 0.1248\n","adapter_config.json: 100% 697/697 [00:00<00:00, 5.36MB/s]\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/llamafactory-cli\", line 8, in <module>\n","    sys.exit(main())\n","  File \"/content/LLaMA-Factory/src/llamafactory/cli.py\", line 111, in main\n","    run_exp()\n","  File \"/content/LLaMA-Factory/src/llamafactory/train/tuner.py\", line 54, in run_exp\n","    run_ppo(model_args, data_args, training_args, finetuning_args, generating_args, callbacks)\n","  File \"/content/LLaMA-Factory/src/llamafactory/train/ppo/workflow.py\", line 53, in run_ppo\n","    reward_model = create_reward_model(model, model_args, finetuning_args)\n","  File \"/content/LLaMA-Factory/src/llamafactory/train/trainer_utils.py\", line 146, in create_reward_model\n","    model.pretrained_model.load_adapter(finetuning_args.reward_model, \"reward\")\n","  File \"/usr/local/lib/python3.10/dist-packages/peft/peft_model.py\", line 1111, in load_adapter\n","    self.add_adapter(adapter_name, peft_config)\n","  File \"/usr/local/lib/python3.10/dist-packages/peft/peft_model.py\", line 872, in add_adapter\n","    self.base_model.inject_adapter(self.base_model.model, adapter_name)\n","  File \"/usr/local/lib/python3.10/dist-packages/peft/tuners/tuners_utils.py\", line 435, in inject_adapter\n","    raise ValueError(\n","ValueError: Target modules {'gate_up_proj', 'o_proj', 'qkv_proj', 'down_proj'} not found in the base model. Please check the target modules and try again.\n","09/16/2024 18:32:33 - WARNING - llamafactory.webui.common - Found complex path, some features may be not available.\n","2024-09-16 18:32:37.064909: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-09-16 18:32:37.085131: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-09-16 18:32:37.091417: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-09-16 18:32:37.106192: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-09-16 18:32:38.635490: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","09/16/2024 18:32:44 - INFO - llamafactory.hparams.parser - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, compute dtype: torch.bfloat16\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\", line 304, in hf_raise_for_status\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.10/dist-packages/requests/models.py\", line 1024, in raise_for_status\n","    raise HTTPError(http_error_msg, response=self)\n","requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/Phi-3-mini-4k-instruct-adaptor-f16-code_writer.gguf/resolve/main/config.json\n","\n","The above exception was the direct cause of the following exception:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\", line 402, in cached_file\n","    resolved_file = hf_hub_download(\n","  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py\", line 101, in inner_f\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n","    return fn(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\", line 1240, in hf_hub_download\n","    return _hf_hub_download_to_cache_dir(\n","  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\", line 1347, in _hf_hub_download_to_cache_dir\n","    _raise_on_head_call_error(head_call_error, force_download, local_files_only)\n","  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\", line 1855, in _raise_on_head_call_error\n","    raise head_call_error\n","  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\", line 1752, in _get_metadata_or_catch_error\n","    metadata = get_hf_file_metadata(\n","  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n","    return fn(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\", line 1674, in get_hf_file_metadata\n","    r = _request_wrapper(\n","  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\", line 376, in _request_wrapper\n","    response = _request_wrapper(\n","  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\", line 400, in _request_wrapper\n","    hf_raise_for_status(response)\n","  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\", line 352, in hf_raise_for_status\n","    raise RepositoryNotFoundError(message, response) from e\n","huggingface_hub.utils._errors.RepositoryNotFoundError: 404 Client Error. (Request ID: Root=1-66e879cc-61fe305327e9681d1aca47d2;4222e26f-9df8-4bf2-a2a6-5251860d4d32)\n","\n","Repository Not Found for url: https://huggingface.co/Phi-3-mini-4k-instruct-adaptor-f16-code_writer.gguf/resolve/main/config.json.\n","Please make sure you specified the correct `repo_id` and `repo_type`.\n","If you are trying to access a private or gated repo, make sure you are authenticated.\n","\n","The above exception was the direct cause of the following exception:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/llamafactory-cli\", line 8, in <module>\n","    sys.exit(main())\n","  File \"/content/LLaMA-Factory/src/llamafactory/cli.py\", line 111, in main\n","    run_exp()\n","  File \"/content/LLaMA-Factory/src/llamafactory/train/tuner.py\", line 54, in run_exp\n","    run_ppo(model_args, data_args, training_args, finetuning_args, generating_args, callbacks)\n","  File \"/content/LLaMA-Factory/src/llamafactory/train/ppo/workflow.py\", line 42, in run_ppo\n","    tokenizer_module = load_tokenizer(model_args)\n","  File \"/content/LLaMA-Factory/src/llamafactory/model/loader.py\", line 69, in load_tokenizer\n","    config = load_config(model_args)\n","  File \"/content/LLaMA-Factory/src/llamafactory/model/loader.py\", line 122, in load_config\n","    return AutoConfig.from_pretrained(model_args.model_name_or_path, **init_kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/auto/configuration_auto.py\", line 976, in from_pretrained\n","    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/configuration_utils.py\", line 632, in get_config_dict\n","    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/configuration_utils.py\", line 689, in _get_config_dict\n","    resolved_config_file = cached_file(\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\", line 425, in cached_file\n","    raise EnvironmentError(\n","OSError: Phi-3-mini-4k-instruct-adaptor-f16-code_writer.gguf is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\n","If this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`\n","09/16/2024 18:34:48 - WARNING - llamafactory.webui.common - Found complex path, some features may be not available.\n","2024-09-16 18:34:53.102566: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-09-16 18:34:53.135732: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-09-16 18:34:53.146194: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-09-16 18:34:53.169047: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-09-16 18:34:54.875856: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","09/16/2024 18:34:59 - INFO - llamafactory.hparams.parser - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, compute dtype: torch.bfloat16\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\", line 304, in hf_raise_for_status\n","    response.raise_for_status()\n","  File \"/usr/local/lib/python3.10/dist-packages/requests/models.py\", line 1024, in raise_for_status\n","    raise HTTPError(http_error_msg, response=self)\n","requests.exceptions.HTTPError: 404 Client Error: Not Found for url: https://huggingface.co/zhhan/adapter-Phi-3-mini-4k-instruct_code_writing/resolve/main/config.json\n","\n","The above exception was the direct cause of the following exception:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\", line 402, in cached_file\n","    resolved_file = hf_hub_download(\n","  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_deprecation.py\", line 101, in inner_f\n","    return f(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n","    return fn(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\", line 1240, in hf_hub_download\n","    return _hf_hub_download_to_cache_dir(\n","  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\", line 1303, in _hf_hub_download_to_cache_dir\n","    (url_to_download, etag, commit_hash, expected_size, head_call_error) = _get_metadata_or_catch_error(\n","  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\", line 1752, in _get_metadata_or_catch_error\n","    metadata = get_hf_file_metadata(\n","  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\", line 114, in _inner_fn\n","    return fn(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\", line 1674, in get_hf_file_metadata\n","    r = _request_wrapper(\n","  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\", line 376, in _request_wrapper\n","    response = _request_wrapper(\n","  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\", line 400, in _request_wrapper\n","    hf_raise_for_status(response)\n","  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\", line 315, in hf_raise_for_status\n","    raise EntryNotFoundError(message, response) from e\n","huggingface_hub.utils._errors.EntryNotFoundError: 404 Client Error. (Request ID: Root=1-66e87a53-18e89e5b56ddba0c4fe8b3d7;5319d349-f24e-4f6e-8c97-28af4c18d925)\n","\n","Entry Not Found for url: https://huggingface.co/zhhan/adapter-Phi-3-mini-4k-instruct_code_writing/resolve/main/config.json.\n","\n","The above exception was the direct cause of the following exception:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/llamafactory-cli\", line 8, in <module>\n","    sys.exit(main())\n","  File \"/content/LLaMA-Factory/src/llamafactory/cli.py\", line 111, in main\n","    run_exp()\n","  File \"/content/LLaMA-Factory/src/llamafactory/train/tuner.py\", line 54, in run_exp\n","    run_ppo(model_args, data_args, training_args, finetuning_args, generating_args, callbacks)\n","  File \"/content/LLaMA-Factory/src/llamafactory/train/ppo/workflow.py\", line 42, in run_ppo\n","    tokenizer_module = load_tokenizer(model_args)\n","  File \"/content/LLaMA-Factory/src/llamafactory/model/loader.py\", line 69, in load_tokenizer\n","    config = load_config(model_args)\n","  File \"/content/LLaMA-Factory/src/llamafactory/model/loader.py\", line 122, in load_config\n","    return AutoConfig.from_pretrained(model_args.model_name_or_path, **init_kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/auto/configuration_auto.py\", line 976, in from_pretrained\n","    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/configuration_utils.py\", line 632, in get_config_dict\n","    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/configuration_utils.py\", line 689, in _get_config_dict\n","    resolved_config_file = cached_file(\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\", line 456, in cached_file\n","    raise EnvironmentError(\n","OSError: zhhan/adapter-Phi-3-mini-4k-instruct_code_writing does not appear to have a file named config.json. Checkout 'https://huggingface.co/zhhan/adapter-Phi-3-mini-4k-instruct_code_writing/tree/main' for available files.\n","09/16/2024 18:39:01 - WARNING - llamafactory.webui.common - Found complex path, some features may be not available.\n","2024-09-16 18:39:05.142311: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-09-16 18:39:05.163646: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-09-16 18:39:05.169918: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-09-16 18:39:05.184633: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-09-16 18:39:06.362821: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","09/16/2024 18:39:10 - INFO - llamafactory.hparams.parser - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, compute dtype: torch.bfloat16\n","config.json: 100% 692/692 [00:00<00:00, 3.40MB/s]\n","[INFO|configuration_utils.py:733] 2024-09-16 18:39:11,159 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--edbeeching--gpt-neox-20b-imdb_adapter-lr5e-4-imdb-peft-adapter-removed/snapshots/e325891b5849f5fcc878977379e0c2894be1beae/config.json\n","[INFO|configuration_utils.py:800] 2024-09-16 18:39:11,161 >> Model config GPTNeoXConfig {\n","  \"_name_or_path\": \"edbeeching/gpt-neox-20b-imdb_adapter-lr5e-4-imdb-peft-adapter-removed\",\n","  \"architectures\": [\n","    \"GPTNeoXForCausalLM\"\n","  ],\n","  \"attention_bias\": true,\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": 0.1,\n","  \"eos_token_id\": 0,\n","  \"hidden_act\": \"gelu_fast\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0,\n","  \"hidden_size\": 6144,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 24576,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 2048,\n","  \"model_type\": \"gpt_neox\",\n","  \"num_attention_heads\": 64,\n","  \"num_hidden_layers\": 44,\n","  \"rope_scaling\": null,\n","  \"rotary_emb_base\": 10000,\n","  \"rotary_pct\": 0.25,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"float16\",\n","  \"transformers_version\": \"4.44.2\",\n","  \"use_cache\": true,\n","  \"use_parallel_residual\": true,\n","  \"vocab_size\": 50432\n","}\n","\n","tokenizer_config.json: 100% 415/415 [00:00<00:00, 3.11MB/s]\n","tokenizer.json: 100% 2.11M/2.11M [00:00<00:00, 5.01MB/s]\n","special_tokens_map.json: 100% 99.0/99.0 [00:00<00:00, 573kB/s]\n","[INFO|tokenization_utils_base.py:2269] 2024-09-16 18:39:12,601 >> loading file vocab.json from cache at None\n","[INFO|tokenization_utils_base.py:2269] 2024-09-16 18:39:12,601 >> loading file merges.txt from cache at None\n","[INFO|tokenization_utils_base.py:2269] 2024-09-16 18:39:12,601 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--edbeeching--gpt-neox-20b-imdb_adapter-lr5e-4-imdb-peft-adapter-removed/snapshots/e325891b5849f5fcc878977379e0c2894be1beae/tokenizer.json\n","[INFO|tokenization_utils_base.py:2269] 2024-09-16 18:39:12,601 >> loading file added_tokens.json from cache at None\n","[INFO|tokenization_utils_base.py:2269] 2024-09-16 18:39:12,602 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--edbeeching--gpt-neox-20b-imdb_adapter-lr5e-4-imdb-peft-adapter-removed/snapshots/e325891b5849f5fcc878977379e0c2894be1beae/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2269] 2024-09-16 18:39:12,602 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--edbeeching--gpt-neox-20b-imdb_adapter-lr5e-4-imdb-peft-adapter-removed/snapshots/e325891b5849f5fcc878977379e0c2894be1beae/tokenizer_config.json\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n","[INFO|tokenization_utils_base.py:2513] 2024-09-16 18:39:12,761 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","[INFO|configuration_utils.py:733] 2024-09-16 18:39:13,187 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--edbeeching--gpt-neox-20b-imdb_adapter-lr5e-4-imdb-peft-adapter-removed/snapshots/e325891b5849f5fcc878977379e0c2894be1beae/config.json\n","[INFO|configuration_utils.py:800] 2024-09-16 18:39:13,189 >> Model config GPTNeoXConfig {\n","  \"_name_or_path\": \"edbeeching/gpt-neox-20b-imdb_adapter-lr5e-4-imdb-peft-adapter-removed\",\n","  \"architectures\": [\n","    \"GPTNeoXForCausalLM\"\n","  ],\n","  \"attention_bias\": true,\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": 0.1,\n","  \"eos_token_id\": 0,\n","  \"hidden_act\": \"gelu_fast\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0,\n","  \"hidden_size\": 6144,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 24576,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 2048,\n","  \"model_type\": \"gpt_neox\",\n","  \"num_attention_heads\": 64,\n","  \"num_hidden_layers\": 44,\n","  \"rope_scaling\": null,\n","  \"rotary_emb_base\": 10000,\n","  \"rotary_pct\": 0.25,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"float16\",\n","  \"transformers_version\": \"4.44.2\",\n","  \"use_cache\": true,\n","  \"use_parallel_residual\": true,\n","  \"vocab_size\": 50432\n","}\n","\n","[INFO|tokenization_utils_base.py:2269] 2024-09-16 18:39:13,293 >> loading file vocab.json from cache at None\n","[INFO|tokenization_utils_base.py:2269] 2024-09-16 18:39:13,294 >> loading file merges.txt from cache at None\n","[INFO|tokenization_utils_base.py:2269] 2024-09-16 18:39:13,294 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--edbeeching--gpt-neox-20b-imdb_adapter-lr5e-4-imdb-peft-adapter-removed/snapshots/e325891b5849f5fcc878977379e0c2894be1beae/tokenizer.json\n","[INFO|tokenization_utils_base.py:2269] 2024-09-16 18:39:13,294 >> loading file added_tokens.json from cache at None\n","[INFO|tokenization_utils_base.py:2269] 2024-09-16 18:39:13,294 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--edbeeching--gpt-neox-20b-imdb_adapter-lr5e-4-imdb-peft-adapter-removed/snapshots/e325891b5849f5fcc878977379e0c2894be1beae/special_tokens_map.json\n","[INFO|tokenization_utils_base.py:2269] 2024-09-16 18:39:13,294 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--edbeeching--gpt-neox-20b-imdb_adapter-lr5e-4-imdb-peft-adapter-removed/snapshots/e325891b5849f5fcc878977379e0c2894be1beae/tokenizer_config.json\n","[INFO|tokenization_utils_base.py:2513] 2024-09-16 18:39:13,436 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","09/16/2024 18:39:13 - INFO - llamafactory.data.template - Add pad token: <|endoftext|>\n","09/16/2024 18:39:13 - INFO - llamafactory.data.loader - Loading dataset alpaca_en_demo.json...\n","Running tokenizer on dataset (num_proc=16): 100% 500/500 [00:04<00:00, 104.40 examples/s]\n","training example:\n","input_ids:\n","[22705, 27, 3666, 19268, 247, 1232, 273, 2403, 1424, 19064, 15, 187, 6717, 5567, 27]\n","inputs:\n","Human: Describe a process of making crepes.\n","Assistant:\n","[INFO|configuration_utils.py:733] 2024-09-16 18:39:19,506 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--edbeeching--gpt-neox-20b-imdb_adapter-lr5e-4-imdb-peft-adapter-removed/snapshots/e325891b5849f5fcc878977379e0c2894be1beae/config.json\n","[INFO|configuration_utils.py:800] 2024-09-16 18:39:19,507 >> Model config GPTNeoXConfig {\n","  \"_name_or_path\": \"edbeeching/gpt-neox-20b-imdb_adapter-lr5e-4-imdb-peft-adapter-removed\",\n","  \"architectures\": [\n","    \"GPTNeoXForCausalLM\"\n","  ],\n","  \"attention_bias\": true,\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0,\n","  \"bos_token_id\": 0,\n","  \"classifier_dropout\": 0.1,\n","  \"eos_token_id\": 0,\n","  \"hidden_act\": \"gelu_fast\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0,\n","  \"hidden_size\": 6144,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 24576,\n","  \"layer_norm_eps\": 1e-05,\n","  \"max_position_embeddings\": 2048,\n","  \"model_type\": \"gpt_neox\",\n","  \"num_attention_heads\": 64,\n","  \"num_hidden_layers\": 44,\n","  \"rope_scaling\": null,\n","  \"rotary_emb_base\": 10000,\n","  \"rotary_pct\": 0.25,\n","  \"tie_word_embeddings\": false,\n","  \"torch_dtype\": \"float16\",\n","  \"transformers_version\": \"4.44.2\",\n","  \"use_cache\": true,\n","  \"use_parallel_residual\": true,\n","  \"vocab_size\": 50432\n","}\n","\n","adapter_config.json: 100% 371/371 [00:00<00:00, 3.08MB/s]\n","model.safetensors.index.json: 100% 60.4k/60.4k [00:00<00:00, 742kB/s]\n","[INFO|modeling_utils.py:3678] 2024-09-16 18:39:20,182 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--EleutherAI--gpt-neox-20b/snapshots/c292233c833e336628618a88a648727eb3dff0a7/model.safetensors.index.json\n","Downloading shards:   0% 0/46 [00:00<?, ?it/s]\n","model-00001-of-00046.safetensors:   0% 0.00/926M [00:00<?, ?B/s]\u001b[A\n","model-00001-of-00046.safetensors:   2% 21.0M/926M [00:00<00:07, 117MB/s]\u001b[A\n","model-00001-of-00046.safetensors:   5% 41.9M/926M [00:00<00:06, 142MB/s]\u001b[A\n","model-00001-of-00046.safetensors:   8% 73.4M/926M [00:00<00:04, 194MB/s]\u001b[A\n","model-00001-of-00046.safetensors:  10% 94.4M/926M [00:00<00:04, 194MB/s]\u001b[A\n","model-00001-of-00046.safetensors:  12% 115M/926M [00:00<00:04, 175MB/s] \u001b[A\n","model-00001-of-00046.safetensors:  15% 136M/926M [00:00<00:04, 173MB/s]\u001b[A\n","model-00001-of-00046.safetensors:  17% 157M/926M [00:00<00:04, 157MB/s]\u001b[A\n","model-00001-of-00046.safetensors:  19% 178M/926M [00:01<00:04, 169MB/s]\u001b[A\n","model-00001-of-00046.safetensors:  23% 210M/926M [00:01<00:03, 185MB/s]\u001b[A\n","model-00001-of-00046.safetensors:  25% 231M/926M [00:01<00:03, 190MB/s]\u001b[A\n","model-00001-of-00046.safetensors:  27% 252M/926M [00:01<00:03, 187MB/s]\u001b[A\n","model-00001-of-00046.safetensors:  29% 273M/926M [00:01<00:03, 187MB/s]\u001b[A\n","model-00001-of-00046.safetensors:  32% 294M/926M [00:01<00:03, 187MB/s]\u001b[A\n","model-00001-of-00046.safetensors:  34% 315M/926M [00:01<00:03, 193MB/s]\u001b[A\n","model-00001-of-00046.safetensors:  37% 346M/926M [00:01<00:02, 205MB/s]\u001b[A\n","model-00001-of-00046.safetensors:  41% 377M/926M [00:02<00:02, 213MB/s]\u001b[A\n","model-00001-of-00046.safetensors:  44% 409M/926M [00:02<00:02, 218MB/s]\u001b[A\n","model-00001-of-00046.safetensors:  48% 440M/926M [00:02<00:02, 213MB/s]\u001b[A\n","model-00001-of-00046.safetensors:  51% 472M/926M [00:02<00:02, 215MB/s]\u001b[A\n","model-00001-of-00046.safetensors:  54% 503M/926M [00:02<00:01, 216MB/s]\u001b[A\n","model-00001-of-00046.safetensors:  58% 535M/926M [00:02<00:01, 214MB/s]\u001b[A\n","model-00001-of-00046.safetensors:  61% 566M/926M [00:02<00:01, 213MB/s]\u001b[A\n","model-00001-of-00046.safetensors:  65% 598M/926M [00:03<00:01, 214MB/s]\u001b[A\n","model-00001-of-00046.safetensors:  68% 629M/926M [00:03<00:01, 220MB/s]\u001b[A\n","model-00001-of-00046.safetensors:  71% 661M/926M [00:03<00:01, 208MB/s]\u001b[A\n","model-00001-of-00046.safetensors:  75% 692M/926M [00:03<00:01, 198MB/s]\u001b[A\n","model-00001-of-00046.safetensors:  77% 713M/926M [00:03<00:01, 195MB/s]\u001b[A\n","model-00001-of-00046.safetensors:  80% 744M/926M [00:03<00:00, 205MB/s]\u001b[A\n","model-00001-of-00046.safetensors:  84% 776M/926M [00:04<00:01, 148MB/s]\u001b[A\n","model-00001-of-00046.safetensors:  86% 797M/926M [00:07<00:05, 25.7MB/s]\u001b[A\n","model-00001-of-00046.safetensors:  91% 839M/926M [00:07<00:02, 40.1MB/s]\u001b[A\n","model-00001-of-00046.safetensors:  94% 870M/926M [00:07<00:01, 52.6MB/s]\u001b[A\n","model-00001-of-00046.safetensors:  96% 891M/926M [00:07<00:00, 60.2MB/s]\u001b[A\n","model-00001-of-00046.safetensors: 100% 926M/926M [00:07<00:00, 116MB/s] \n","Downloading shards:   2% 1/46 [00:08<06:06,  8.15s/it]\n","model-00002-of-00046.safetensors:   0% 0.00/910M [00:00<?, ?B/s]\u001b[A\n","model-00002-of-00046.safetensors:   1% 10.5M/910M [00:00<00:12, 72.7MB/s]\u001b[A\n","model-00002-of-00046.safetensors:   3% 31.5M/910M [00:00<00:06, 129MB/s] \u001b[A\n","model-00002-of-00046.safetensors:   7% 62.9M/910M [00:00<00:04, 194MB/s]\u001b[A\n","model-00002-of-00046.safetensors:   9% 83.9M/910M [00:00<00:04, 199MB/s]\u001b[A\n","model-00002-of-00046.safetensors:  13% 115M/910M [00:00<00:04, 196MB/s] \u001b[A\n","model-00002-of-00046.safetensors:  16% 147M/910M [00:00<00:03, 207MB/s]\u001b[A\n","model-00002-of-00046.safetensors:  20% 178M/910M [00:00<00:03, 218MB/s]\u001b[A\n","model-00002-of-00046.safetensors:  23% 210M/910M [00:01<00:03, 210MB/s]\u001b[A\n","model-00002-of-00046.safetensors:  26% 241M/910M [00:01<00:03, 212MB/s]\u001b[A\n","model-00002-of-00046.safetensors:  30% 273M/910M [00:01<00:03, 200MB/s]\u001b[A\n","model-00002-of-00046.safetensors:  33% 304M/910M [00:01<00:02, 211MB/s]\u001b[A\n","model-00002-of-00046.safetensors:  37% 336M/910M [00:01<00:03, 187MB/s]\u001b[A\n","model-00002-of-00046.safetensors:  39% 357M/910M [00:01<00:02, 187MB/s]\u001b[A\n","model-00002-of-00046.safetensors:  41% 377M/910M [00:01<00:02, 188MB/s]\u001b[A\n","model-00002-of-00046.safetensors:  44% 398M/910M [00:02<00:02, 185MB/s]\u001b[A\n","model-00002-of-00046.safetensors:  46% 419M/910M [00:02<00:02, 185MB/s]\u001b[A\n","model-00002-of-00046.safetensors:  48% 440M/910M [00:02<00:04, 106MB/s]\u001b[A\n","model-00002-of-00046.safetensors:  51% 461M/910M [00:02<00:03, 119MB/s]\u001b[A\n","model-00002-of-00046.safetensors:  53% 482M/910M [00:02<00:03, 126MB/s]\u001b[A\n","model-00002-of-00046.safetensors:  55% 503M/910M [00:02<00:02, 142MB/s]\u001b[A\n","model-00002-of-00046.safetensors:  58% 524M/910M [00:03<00:02, 155MB/s]\u001b[A\n","model-00002-of-00046.safetensors:  60% 545M/910M [00:03<00:02, 162MB/s]\u001b[A\n","model-00002-of-00046.safetensors:  62% 566M/910M [00:03<00:01, 173MB/s]\u001b[A\n","model-00002-of-00046.safetensors:  65% 587M/910M [00:03<00:01, 175MB/s]\u001b[A\n","model-00002-of-00046.safetensors:  67% 608M/910M [00:03<00:01, 179MB/s]\u001b[A\n","model-00002-of-00046.safetensors:  69% 629M/910M [00:03<00:01, 175MB/s]\u001b[A\n","model-00002-of-00046.safetensors:  73% 661M/910M [00:03<00:01, 193MB/s]\u001b[A\n","model-00002-of-00046.safetensors:  76% 692M/910M [00:03<00:01, 202MB/s]\u001b[A\n","model-00002-of-00046.safetensors:  78% 713M/910M [00:04<00:01, 194MB/s]\u001b[A\n","model-00002-of-00046.safetensors:  81% 734M/910M [00:04<00:00, 198MB/s]\u001b[A\n","model-00002-of-00046.safetensors:  83% 755M/910M [00:04<00:00, 198MB/s]\u001b[A\n","model-00002-of-00046.safetensors:  86% 786M/910M [00:04<00:00, 212MB/s]\u001b[A\n","model-00002-of-00046.safetensors:  90% 818M/910M [00:04<00:00, 207MB/s]\u001b[A\n","model-00002-of-00046.safetensors:  92% 839M/910M [00:04<00:00, 193MB/s]\u001b[A\n","model-00002-of-00046.safetensors:  94% 860M/910M [00:04<00:00, 178MB/s]\u001b[A\n","model-00002-of-00046.safetensors:  97% 881M/910M [00:04<00:00, 176MB/s]\u001b[A\n","model-00002-of-00046.safetensors: 100% 910M/910M [00:05<00:00, 179MB/s]\n","Downloading shards:   4% 2/46 [00:13<04:42,  6.42s/it]\n","model-00003-of-00046.safetensors:   0% 0.00/910M [00:00<?, ?B/s]\u001b[A\n","model-00003-of-00046.safetensors:   1% 10.5M/910M [00:00<00:11, 80.9MB/s]\u001b[A\n","model-00003-of-00046.safetensors:   3% 31.5M/910M [00:00<00:06, 139MB/s] \u001b[A\n","model-00003-of-00046.safetensors:   6% 52.4M/910M [00:00<00:06, 142MB/s]\u001b[A\n","model-00003-of-00046.safetensors:   8% 73.4M/910M [00:00<00:05, 159MB/s]\u001b[A\n","model-00003-of-00046.safetensors:  10% 94.4M/910M [00:00<00:05, 163MB/s]\u001b[A\n","model-00003-of-00046.safetensors:  13% 115M/910M [00:00<00:04, 165MB/s] \u001b[A\n","model-00003-of-00046.safetensors:  15% 136M/910M [00:00<00:04, 177MB/s]\u001b[A\n","model-00003-of-00046.safetensors:  18% 168M/910M [00:00<00:03, 190MB/s]\u001b[A\n","model-00003-of-00046.safetensors:  22% 199M/910M [00:01<00:03, 213MB/s]\u001b[A\n","model-00003-of-00046.safetensors:  25% 231M/910M [00:01<00:03, 215MB/s]\u001b[A\n","model-00003-of-00046.safetensors:  29% 262M/910M [00:01<00:02, 222MB/s]\u001b[A\n","model-00003-of-00046.safetensors:  32% 294M/910M [00:01<00:02, 229MB/s]\u001b[A\n","model-00003-of-00046.safetensors:  36% 325M/910M [00:01<00:02, 221MB/s]\u001b[A\n","model-00003-of-00046.safetensors:  39% 357M/910M [00:01<00:02, 207MB/s]\u001b[A\n","model-00003-of-00046.safetensors:  43% 388M/910M [00:01<00:02, 210MB/s]\u001b[A\n","model-00003-of-00046.safetensors:  46% 419M/910M [00:02<00:02, 212MB/s]\u001b[A\n","model-00003-of-00046.safetensors:  50% 451M/910M [00:02<00:02, 227MB/s]\u001b[A\n","model-00003-of-00046.safetensors:  53% 482M/910M [00:02<00:02, 200MB/s]\u001b[A\n","model-00003-of-00046.safetensors:  56% 514M/910M [00:02<00:01, 209MB/s]\u001b[A\n","model-00003-of-00046.safetensors:  60% 545M/910M [00:02<00:01, 212MB/s]\u001b[A\n","model-00003-of-00046.safetensors:  63% 577M/910M [00:02<00:01, 207MB/s]\u001b[A\n","model-00003-of-00046.safetensors:  67% 608M/910M [00:03<00:01, 185MB/s]\u001b[A\n","model-00003-of-00046.safetensors:  70% 640M/910M [00:03<00:01, 197MB/s]\u001b[A\n","model-00003-of-00046.safetensors:  74% 671M/910M [00:03<00:01, 207MB/s]\u001b[A\n","model-00003-of-00046.safetensors:  77% 703M/910M [00:03<00:00, 218MB/s]\u001b[A\n","model-00003-of-00046.safetensors:  81% 734M/910M [00:03<00:00, 189MB/s]\u001b[A\n","model-00003-of-00046.safetensors:  83% 755M/910M [00:03<00:00, 182MB/s]\u001b[A\n","model-00003-of-00046.safetensors:  85% 776M/910M [00:03<00:00, 182MB/s]\u001b[A\n","model-00003-of-00046.safetensors:  88% 797M/910M [00:04<00:00, 127MB/s]\u001b[A\n","model-00003-of-00046.safetensors:  90% 818M/910M [00:05<00:02, 42.9MB/s]\u001b[A\n","model-00003-of-00046.safetensors:  92% 839M/910M [00:08<00:03, 18.7MB/s]\u001b[A\n","model-00003-of-00046.safetensors:  96% 870M/910M [00:08<00:01, 28.7MB/s]\u001b[A\n","model-00003-of-00046.safetensors:  98% 891M/910M [00:08<00:00, 36.6MB/s]\u001b[A\n","model-00003-of-00046.safetensors: 100% 910M/910M [00:08<00:00, 103MB/s] \n","Downloading shards:   7% 3/46 [00:22<05:26,  7.58s/it]\n","model-00004-of-00046.safetensors:   0% 0.00/910M [00:00<?, ?B/s]\u001b[A\n","model-00004-of-00046.safetensors:   1% 10.5M/910M [00:00<00:14, 60.5MB/s]\u001b[A\n","model-00004-of-00046.safetensors:   3% 31.5M/910M [00:00<00:07, 119MB/s] \u001b[A\n","model-00004-of-00046.safetensors:   6% 52.4M/910M [00:00<00:05, 152MB/s]\u001b[A\n","model-00004-of-00046.safetensors:   9% 83.9M/910M [00:00<00:04, 186MB/s]\u001b[A\n","model-00004-of-00046.safetensors:  13% 115M/910M [00:00<00:03, 216MB/s] \u001b[A\n","model-00004-of-00046.safetensors:  16% 147M/910M [00:00<00:03, 222MB/s]\u001b[A\n","model-00004-of-00046.safetensors:  20% 178M/910M [00:00<00:03, 229MB/s]\u001b[A\n","model-00004-of-00046.safetensors:  23% 210M/910M [00:01<00:03, 223MB/s]\u001b[A\n","model-00004-of-00046.safetensors:  26% 241M/910M [00:01<00:02, 231MB/s]\u001b[A\n","model-00004-of-00046.safetensors:  30% 273M/910M [00:01<00:02, 221MB/s]\u001b[A\n","model-00004-of-00046.safetensors:  33% 304M/910M [00:02<00:06, 91.7MB/s]\u001b[A\n","model-00004-of-00046.safetensors:  36% 325M/910M [00:02<00:07, 74.1MB/s]\u001b[A\n","model-00004-of-00046.safetensors:  38% 346M/910M [00:05<00:24, 23.5MB/s]\u001b[A\n","model-00004-of-00046.safetensors:  43% 388M/910M [00:05<00:13, 38.0MB/s]\u001b[A\n","model-00004-of-00046.safetensors:  46% 419M/910M [00:05<00:09, 51.0MB/s]\u001b[A\n","model-00004-of-00046.safetensors:  48% 440M/910M [00:05<00:07, 60.0MB/s]\u001b[A\n","model-00004-of-00046.safetensors:  51% 461M/910M [00:05<00:06, 72.4MB/s]\u001b[A\n","model-00004-of-00046.safetensors:  53% 482M/910M [00:05<00:04, 87.1MB/s]\u001b[A\n","model-00004-of-00046.safetensors:  56% 514M/910M [00:06<00:03, 114MB/s] \u001b[A\n","model-00004-of-00046.safetensors:  60% 545M/910M [00:06<00:02, 142MB/s]\u001b[A\n","model-00004-of-00046.safetensors:  63% 577M/910M [00:06<00:02, 161MB/s]\u001b[A\n","model-00004-of-00046.safetensors:  67% 608M/910M [00:06<00:01, 185MB/s]\u001b[A\n","model-00004-of-00046.safetensors:  70% 640M/910M [00:06<00:01, 198MB/s]\u001b[A\n","model-00004-of-00046.safetensors:  74% 671M/910M [00:06<00:01, 210MB/s]\u001b[A\n","model-00004-of-00046.safetensors:  77% 703M/910M [00:06<00:01, 185MB/s]\u001b[A\n","model-00004-of-00046.safetensors:  81% 734M/910M [00:07<00:01, 156MB/s]\u001b[A\n","model-00004-of-00046.safetensors:  83% 755M/910M [00:09<00:03, 39.0MB/s]\u001b[A\n","model-00004-of-00046.safetensors:  85% 776M/910M [00:09<00:02, 45.6MB/s]\u001b[A\n","model-00004-of-00046.safetensors:  88% 797M/910M [00:09<00:02, 55.9MB/s]\u001b[A\n","model-00004-of-00046.safetensors:  92% 839M/910M [00:09<00:00, 85.9MB/s]\u001b[A\n","model-00004-of-00046.safetensors:  96% 870M/910M [00:09<00:00, 107MB/s] \u001b[A\n","model-00004-of-00046.safetensors: 100% 910M/910M [00:09<00:00, 91.4MB/s]\n","Downloading shards:   9% 4/46 [00:32<05:59,  8.57s/it]\n","model-00005-of-00046.safetensors:   0% 0.00/910M [00:00<?, ?B/s]\u001b[A\n","model-00005-of-00046.safetensors:   1% 10.5M/910M [00:00<00:10, 82.3MB/s]\u001b[A\n","model-00005-of-00046.safetensors:   3% 31.5M/910M [00:00<00:06, 128MB/s] \u001b[A\n","model-00005-of-00046.safetensors:   6% 52.4M/910M [00:00<00:05, 148MB/s]\u001b[A\n","model-00005-of-00046.safetensors:   9% 83.9M/910M [00:00<00:04, 182MB/s]\u001b[A\n","model-00005-of-00046.safetensors:  13% 115M/910M [00:00<00:03, 206MB/s] \u001b[A\n","model-00005-of-00046.safetensors:  16% 147M/910M [00:00<00:03, 219MB/s]\u001b[A\n","model-00005-of-00046.safetensors:  20% 178M/910M [00:00<00:03, 231MB/s]\u001b[A\n","model-00005-of-00046.safetensors:  23% 210M/910M [00:01<00:03, 231MB/s]\u001b[A\n","model-00005-of-00046.safetensors:  26% 241M/910M [00:01<00:02, 246MB/s]\u001b[A\n","model-00005-of-00046.safetensors:  30% 273M/910M [00:01<00:02, 250MB/s]\u001b[A\n","model-00005-of-00046.safetensors:  33% 304M/910M [00:01<00:02, 252MB/s]\u001b[A\n","model-00005-of-00046.safetensors:  37% 336M/910M [00:01<00:02, 255MB/s]\u001b[A\n","model-00005-of-00046.safetensors:  40% 367M/910M [00:01<00:02, 239MB/s]\u001b[A\n","model-00005-of-00046.safetensors:  44% 398M/910M [00:01<00:02, 243MB/s]\u001b[A\n","model-00005-of-00046.safetensors:  47% 430M/910M [00:01<00:01, 248MB/s]\u001b[A\n","model-00005-of-00046.safetensors:  51% 461M/910M [00:02<00:01, 254MB/s]\u001b[A\n","model-00005-of-00046.safetensors:  54% 493M/910M [00:02<00:01, 260MB/s]\u001b[A\n","model-00005-of-00046.safetensors:  58% 524M/910M [00:02<00:01, 261MB/s]\u001b[A\n","model-00005-of-00046.safetensors:  61% 556M/910M [00:02<00:01, 261MB/s]\u001b[A\n","model-00005-of-00046.safetensors:  65% 587M/910M [00:02<00:01, 264MB/s]\u001b[A\n","model-00005-of-00046.safetensors:  68% 619M/910M [00:02<00:01, 251MB/s]\u001b[A\n","model-00005-of-00046.safetensors:  71% 650M/910M [00:02<00:01, 197MB/s]\u001b[A\n","model-00005-of-00046.safetensors:  75% 682M/910M [00:03<00:01, 158MB/s]\u001b[A\n","model-00005-of-00046.safetensors:  78% 713M/910M [00:03<00:01, 170MB/s]\u001b[A\n","model-00005-of-00046.safetensors:  81% 734M/910M [00:03<00:01, 155MB/s]\u001b[A\n","model-00005-of-00046.safetensors:  83% 755M/910M [00:03<00:00, 157MB/s]\u001b[A\n","model-00005-of-00046.safetensors:  85% 776M/910M [00:03<00:00, 165MB/s]\u001b[A\n","model-00005-of-00046.safetensors:  88% 797M/910M [00:03<00:00, 159MB/s]\u001b[A\n","model-00005-of-00046.safetensors:  90% 818M/910M [00:04<00:00, 155MB/s]\u001b[A\n","model-00005-of-00046.safetensors:  92% 839M/910M [00:04<00:00, 167MB/s]\u001b[A\n","model-00005-of-00046.safetensors:  96% 870M/910M [00:04<00:00, 188MB/s]\u001b[A\n","model-00005-of-00046.safetensors: 100% 910M/910M [00:04<00:00, 204MB/s]\n","Downloading shards:  11% 5/46 [00:36<04:52,  7.13s/it]\n","model-00006-of-00046.safetensors:   0% 0.00/910M [00:00<?, ?B/s]\u001b[A\n","model-00006-of-00046.safetensors:   1% 10.5M/910M [00:00<00:09, 97.1MB/s]\u001b[A\n","model-00006-of-00046.safetensors:   3% 31.5M/910M [00:00<00:05, 158MB/s] \u001b[A\n","model-00006-of-00046.safetensors:   6% 52.4M/910M [00:00<00:05, 149MB/s]\u001b[A\n","model-00006-of-00046.safetensors:   9% 83.9M/910M [00:00<00:04, 174MB/s]\u001b[A\n","model-00006-of-00046.safetensors:  12% 105M/910M [00:00<00:04, 181MB/s] \u001b[A\n","model-00006-of-00046.safetensors:  14% 126M/910M [00:00<00:04, 186MB/s]\u001b[A\n","model-00006-of-00046.safetensors:  16% 147M/910M [00:00<00:04, 189MB/s]\u001b[A\n","model-00006-of-00046.safetensors:  18% 168M/910M [00:00<00:04, 183MB/s]\u001b[A\n","model-00006-of-00046.safetensors:  22% 199M/910M [00:01<00:03, 206MB/s]\u001b[A\n","model-00006-of-00046.safetensors:  25% 231M/910M [00:01<00:03, 208MB/s]\u001b[A\n","model-00006-of-00046.safetensors:  28% 252M/910M [00:01<00:03, 200MB/s]\u001b[A\n","model-00006-of-00046.safetensors:  30% 273M/910M [00:01<00:03, 202MB/s]\u001b[A\n","model-00006-of-00046.safetensors:  33% 304M/910M [00:01<00:02, 216MB/s]\u001b[A\n","model-00006-of-00046.safetensors:  37% 336M/910M [00:01<00:02, 217MB/s]\u001b[A\n","model-00006-of-00046.safetensors:  40% 367M/910M [00:01<00:02, 214MB/s]\u001b[A\n","model-00006-of-00046.safetensors:  44% 398M/910M [00:02<00:03, 160MB/s]\u001b[A\n","model-00006-of-00046.safetensors:  46% 419M/910M [00:02<00:04, 118MB/s]\u001b[A\n","model-00006-of-00046.safetensors:  48% 440M/910M [00:05<00:18, 25.3MB/s]\u001b[A\n","model-00006-of-00046.safetensors:  50% 451M/910M [00:05<00:18, 25.1MB/s]\u001b[A\n","model-00006-of-00046.safetensors:  52% 472M/910M [00:05<00:13, 33.6MB/s]\u001b[A\n","model-00006-of-00046.safetensors:  54% 493M/910M [00:06<00:10, 39.2MB/s]\u001b[A\n","model-00006-of-00046.safetensors:  58% 524M/910M [00:06<00:06, 58.6MB/s]\u001b[A\n","model-00006-of-00046.safetensors:  61% 556M/910M [00:06<00:04, 81.7MB/s]\u001b[A\n","model-00006-of-00046.safetensors:  63% 577M/910M [00:06<00:03, 96.6MB/s]\u001b[A\n","model-00006-of-00046.safetensors:  66% 598M/910M [00:06<00:02, 108MB/s] \u001b[A\n","model-00006-of-00046.safetensors:  68% 619M/910M [00:06<00:02, 105MB/s]\u001b[A\n","model-00006-of-00046.safetensors:  70% 640M/910M [00:06<00:02, 117MB/s]\u001b[A\n","model-00006-of-00046.safetensors:  74% 671M/910M [00:07<00:01, 140MB/s]\u001b[A\n","model-00006-of-00046.safetensors:  78% 713M/910M [00:07<00:01, 186MB/s]\u001b[A\n","model-00006-of-00046.safetensors:  82% 744M/910M [00:07<00:00, 201MB/s]\u001b[A\n","model-00006-of-00046.safetensors:  85% 776M/910M [00:07<00:00, 191MB/s]\u001b[A\n","model-00006-of-00046.safetensors:  89% 807M/910M [00:07<00:00, 203MB/s]\u001b[A\n","model-00006-of-00046.safetensors:  92% 839M/910M [00:07<00:00, 201MB/s]\u001b[A\n","model-00006-of-00046.safetensors:  96% 870M/910M [00:11<00:01, 28.0MB/s]\u001b[A\n","model-00006-of-00046.safetensors: 100% 910M/910M [00:11<00:00, 79.6MB/s]\n","Downloading shards:  13% 6/46 [00:48<05:45,  8.64s/it]\n","model-00007-of-00046.safetensors:   0% 0.00/910M [00:00<?, ?B/s]\u001b[A\n","model-00007-of-00046.safetensors:   1% 10.5M/910M [00:00<00:09, 91.4MB/s]\u001b[A\n","model-00007-of-00046.safetensors:   3% 31.5M/910M [00:00<00:07, 120MB/s] \u001b[A\n","model-00007-of-00046.safetensors:   6% 52.4M/910M [00:00<00:06, 137MB/s]\u001b[A\n","model-00007-of-00046.safetensors:   8% 73.4M/910M [00:00<00:05, 149MB/s]\u001b[A\n","model-00007-of-00046.safetensors:  12% 105M/910M [00:00<00:04, 173MB/s] \u001b[A\n","model-00007-of-00046.safetensors:  15% 136M/910M [00:00<00:03, 200MB/s]\u001b[A\n","model-00007-of-00046.safetensors:  18% 168M/910M [00:00<00:03, 215MB/s]\u001b[A\n","model-00007-of-00046.safetensors:  22% 199M/910M [00:01<00:03, 214MB/s]\u001b[A\n","model-00007-of-00046.safetensors:  25% 231M/910M [00:01<00:03, 200MB/s]\u001b[A\n","model-00007-of-00046.safetensors:  28% 252M/910M [00:01<00:03, 191MB/s]\u001b[A\n","model-00007-of-00046.safetensors:  31% 283M/910M [00:01<00:03, 204MB/s]\u001b[A\n","model-00007-of-00046.safetensors:  33% 304M/910M [00:01<00:03, 191MB/s]\u001b[A\n","model-00007-of-00046.safetensors:  36% 325M/910M [00:05<00:31, 18.4MB/s]\u001b[A\n","model-00007-of-00046.safetensors:  39% 357M/910M [00:05<00:20, 27.5MB/s]\u001b[A\n","model-00007-of-00046.safetensors:  44% 398M/910M [00:06<00:11, 42.8MB/s]\u001b[A\n","model-00007-of-00046.safetensors:  46% 419M/910M [00:06<00:09, 51.6MB/s]\u001b[A\n","model-00007-of-00046.safetensors:  50% 451M/910M [00:06<00:06, 68.9MB/s]\u001b[A\n","model-00007-of-00046.safetensors:  52% 472M/910M [00:06<00:05, 81.4MB/s]\u001b[A\n","model-00007-of-00046.safetensors:  55% 503M/910M [00:06<00:03, 105MB/s] \u001b[A\n","model-00007-of-00046.safetensors:  59% 535M/910M [00:06<00:02, 129MB/s]\u001b[A\n","model-00007-of-00046.safetensors:  62% 566M/910M [00:06<00:02, 153MB/s]\u001b[A\n","model-00007-of-00046.safetensors:  66% 598M/910M [00:06<00:01, 174MB/s]\u001b[A\n","model-00007-of-00046.safetensors:  69% 629M/910M [00:07<00:01, 192MB/s]\u001b[A\n","model-00007-of-00046.safetensors:  73% 661M/910M [00:07<00:01, 190MB/s]\u001b[A\n","model-00007-of-00046.safetensors:  76% 692M/910M [00:07<00:01, 197MB/s]\u001b[A\n","model-00007-of-00046.safetensors:  79% 724M/910M [00:07<00:00, 204MB/s]\u001b[A\n","model-00007-of-00046.safetensors:  83% 755M/910M [00:07<00:00, 215MB/s]\u001b[A\n","model-00007-of-00046.safetensors:  86% 786M/910M [00:07<00:00, 207MB/s]\u001b[A\n","model-00007-of-00046.safetensors:  90% 818M/910M [00:07<00:00, 200MB/s]\u001b[A\n","model-00007-of-00046.safetensors:  93% 849M/910M [00:08<00:00, 200MB/s]\u001b[A\n","model-00007-of-00046.safetensors: 100% 910M/910M [00:08<00:00, 109MB/s]\n","Downloading shards:  15% 7/46 [00:57<05:34,  8.59s/it]\n","model-00008-of-00046.safetensors:   0% 0.00/910M [00:00<?, ?B/s]\u001b[A\n","model-00008-of-00046.safetensors:   2% 21.0M/910M [00:00<00:06, 138MB/s]\u001b[A\n","model-00008-of-00046.safetensors:   5% 41.9M/910M [00:00<00:05, 172MB/s]\u001b[A\n","model-00008-of-00046.safetensors:   8% 73.4M/910M [00:00<00:04, 191MB/s]\u001b[A\n","model-00008-of-00046.safetensors:  10% 94.4M/910M [00:00<00:04, 187MB/s]\u001b[A\n","model-00008-of-00046.safetensors:  13% 115M/910M [00:03<00:39, 20.3MB/s]\u001b[A\n","model-00008-of-00046.safetensors:  16% 147M/910M [00:03<00:23, 33.0MB/s]\u001b[A\n","model-00008-of-00046.safetensors:  21% 189M/910M [00:03<00:13, 54.7MB/s]\u001b[A\n","model-00008-of-00046.safetensors:  24% 220M/910M [00:03<00:09, 70.9MB/s]\u001b[A\n","model-00008-of-00046.safetensors:  28% 252M/910M [00:03<00:07, 90.0MB/s]\u001b[A\n","model-00008-of-00046.safetensors:  31% 283M/910M [00:04<00:05, 110MB/s] \u001b[A\n","model-00008-of-00046.safetensors:  35% 315M/910M [00:04<00:04, 130MB/s]\u001b[A\n","model-00008-of-00046.safetensors:  38% 346M/910M [00:04<00:04, 140MB/s]\u001b[A\n","model-00008-of-00046.safetensors:  41% 377M/910M [00:04<00:03, 158MB/s]\u001b[A\n","model-00008-of-00046.safetensors:  45% 409M/910M [00:04<00:02, 172MB/s]\u001b[A\n","model-00008-of-00046.safetensors:  48% 440M/910M [00:04<00:02, 178MB/s]\u001b[A\n","model-00008-of-00046.safetensors:  52% 472M/910M [00:05<00:02, 190MB/s]\u001b[A\n","model-00008-of-00046.safetensors:  55% 503M/910M [00:05<00:02, 197MB/s]\u001b[A\n","model-00008-of-00046.safetensors:  59% 535M/910M [00:07<00:09, 38.7MB/s]\u001b[A\n","model-00008-of-00046.safetensors:  62% 566M/910M [00:07<00:06, 52.4MB/s]\u001b[A\n","model-00008-of-00046.safetensors:  65% 587M/910M [00:07<00:05, 60.9MB/s]\u001b[A\n","model-00008-of-00046.safetensors:  67% 608M/910M [00:07<00:04, 68.5MB/s]\u001b[A\n","model-00008-of-00046.safetensors:  69% 629M/910M [00:08<00:03, 82.2MB/s]\u001b[A\n","model-00008-of-00046.safetensors:  71% 650M/910M [00:08<00:02, 97.1MB/s]\u001b[A\n","model-00008-of-00046.safetensors:  74% 671M/910M [00:08<00:02, 110MB/s] \u001b[A\n","model-00008-of-00046.safetensors:  76% 692M/910M [00:08<00:01, 126MB/s]\u001b[A\n","model-00008-of-00046.safetensors:  78% 713M/910M [00:08<00:01, 142MB/s]\u001b[A\n","model-00008-of-00046.safetensors:  82% 744M/910M [00:08<00:00, 171MB/s]\u001b[A\n","model-00008-of-00046.safetensors:  85% 776M/910M [00:08<00:00, 193MB/s]\u001b[A\n","model-00008-of-00046.safetensors:  89% 807M/910M [00:08<00:00, 194MB/s]\u001b[A\n","model-00008-of-00046.safetensors:  92% 839M/910M [00:09<00:00, 213MB/s]\u001b[A\n","model-00008-of-00046.safetensors:  96% 870M/910M [00:09<00:00, 223MB/s]\u001b[A\n","model-00008-of-00046.safetensors: 100% 910M/910M [00:09<00:00, 98.0MB/s]\n","Downloading shards:  17% 8/46 [01:06<05:36,  8.85s/it]\n","model-00009-of-00046.safetensors:   0% 0.00/910M [00:00<?, ?B/s]\u001b[A\n","model-00009-of-00046.safetensors:   1% 10.5M/910M [00:00<00:11, 78.5MB/s]\u001b[A\n","model-00009-of-00046.safetensors:   3% 31.5M/910M [00:00<00:06, 133MB/s] \u001b[A\n","model-00009-of-00046.safetensors:   6% 52.4M/910M [00:00<00:05, 157MB/s]\u001b[A\n","model-00009-of-00046.safetensors:   9% 83.9M/910M [00:00<00:04, 193MB/s]\u001b[A\n","model-00009-of-00046.safetensors:  13% 115M/910M [00:00<00:03, 212MB/s] \u001b[A\n","model-00009-of-00046.safetensors:  16% 147M/910M [00:00<00:05, 140MB/s]\u001b[A\n","model-00009-of-00046.safetensors:  20% 178M/910M [00:01<00:04, 171MB/s]\u001b[A\n","model-00009-of-00046.safetensors:  23% 210M/910M [00:01<00:03, 200MB/s]\u001b[A\n","model-00009-of-00046.safetensors:  26% 241M/910M [00:01<00:03, 206MB/s]\u001b[A\n","model-00009-of-00046.safetensors:  30% 273M/910M [00:01<00:03, 183MB/s]\u001b[A\n","model-00009-of-00046.safetensors:  32% 294M/910M [00:01<00:03, 178MB/s]\u001b[A\n","model-00009-of-00046.safetensors:  35% 315M/910M [00:01<00:03, 176MB/s]\u001b[A\n","model-00009-of-00046.safetensors:  37% 336M/910M [00:01<00:03, 183MB/s]\u001b[A\n","model-00009-of-00046.safetensors:  40% 367M/910M [00:02<00:02, 200MB/s]\u001b[A\n","model-00009-of-00046.safetensors:  44% 398M/910M [00:02<00:02, 216MB/s]\u001b[A\n","model-00009-of-00046.safetensors:  47% 430M/910M [00:02<00:02, 232MB/s]\u001b[A\n","model-00009-of-00046.safetensors:  51% 461M/910M [00:02<00:02, 213MB/s]\u001b[A\n","model-00009-of-00046.safetensors:  54% 493M/910M [00:02<00:02, 206MB/s]\u001b[A\n","model-00009-of-00046.safetensors:  58% 524M/910M [00:02<00:01, 197MB/s]\u001b[A\n","model-00009-of-00046.safetensors:  60% 545M/910M [00:02<00:01, 196MB/s]\u001b[A\n","model-00009-of-00046.safetensors:  63% 577M/910M [00:03<00:01, 211MB/s]\u001b[A\n","model-00009-of-00046.safetensors:  67% 608M/910M [00:03<00:01, 219MB/s]\u001b[A\n","model-00009-of-00046.safetensors:  70% 640M/910M [00:03<00:01, 231MB/s]\u001b[A\n","model-00009-of-00046.safetensors:  74% 671M/910M [00:03<00:01, 222MB/s]\u001b[A\n","model-00009-of-00046.safetensors:  77% 703M/910M [00:03<00:00, 235MB/s]\u001b[A\n","model-00009-of-00046.safetensors:  81% 734M/910M [00:03<00:00, 244MB/s]\u001b[A\n","model-00009-of-00046.safetensors:  84% 765M/910M [00:03<00:00, 242MB/s]\u001b[A\n","model-00009-of-00046.safetensors:  88% 797M/910M [00:03<00:00, 242MB/s]\u001b[A\n","model-00009-of-00046.safetensors:  91% 828M/910M [00:04<00:00, 260MB/s]\u001b[A\n","model-00009-of-00046.safetensors:  94% 860M/910M [00:04<00:00, 263MB/s]\u001b[A\n","model-00009-of-00046.safetensors: 100% 910M/910M [00:04<00:00, 210MB/s]\n","Downloading shards:  20% 9/46 [01:10<04:36,  7.48s/it]\n","model-00010-of-00046.safetensors:   0% 0.00/910M [00:00<?, ?B/s]\u001b[A\n","model-00010-of-00046.safetensors:   1% 10.5M/910M [00:00<00:11, 75.3MB/s]\u001b[A\n","model-00010-of-00046.safetensors:   3% 31.5M/910M [00:00<00:06, 142MB/s] \u001b[A\n","model-00010-of-00046.safetensors:   6% 52.4M/910M [00:00<00:05, 168MB/s]\u001b[A\n","model-00010-of-00046.safetensors:   9% 83.9M/910M [00:00<00:03, 213MB/s]\u001b[A\n","model-00010-of-00046.safetensors:  13% 115M/910M [00:00<00:03, 240MB/s] \u001b[A\n","model-00010-of-00046.safetensors:  16% 147M/910M [00:00<00:03, 226MB/s]\u001b[A\n","model-00010-of-00046.safetensors:  20% 178M/910M [00:00<00:03, 229MB/s]\u001b[A\n","model-00010-of-00046.safetensors:  23% 210M/910M [00:00<00:02, 248MB/s]\u001b[A\n","model-00010-of-00046.safetensors:  26% 241M/910M [00:01<00:02, 235MB/s]\u001b[A\n","model-00010-of-00046.safetensors:  30% 273M/910M [00:01<00:02, 238MB/s]\u001b[A\n","model-00010-of-00046.safetensors:  35% 315M/910M [00:01<00:02, 261MB/s]\u001b[A\n","model-00010-of-00046.safetensors:  38% 346M/910M [00:01<00:02, 229MB/s]\u001b[A\n","model-00010-of-00046.safetensors:  41% 377M/910M [00:01<00:02, 232MB/s]\u001b[A\n","model-00010-of-00046.safetensors:  45% 409M/910M [00:01<00:02, 227MB/s]\u001b[A\n","model-00010-of-00046.safetensors:  48% 440M/910M [00:01<00:02, 220MB/s]\u001b[A\n","model-00010-of-00046.safetensors:  52% 472M/910M [00:02<00:01, 225MB/s]\u001b[A\n","model-00010-of-00046.safetensors:  55% 503M/910M [00:02<00:01, 234MB/s]\u001b[A\n","model-00010-of-00046.safetensors:  59% 535M/910M [00:02<00:01, 247MB/s]\u001b[A\n","model-00010-of-00046.safetensors:  62% 566M/910M [00:02<00:01, 251MB/s]\u001b[A\n","model-00010-of-00046.safetensors:  66% 598M/910M [00:02<00:01, 253MB/s]\u001b[A\n","model-00010-of-00046.safetensors:  69% 629M/910M [00:02<00:01, 255MB/s]\u001b[A\n","model-00010-of-00046.safetensors:  74% 671M/910M [00:02<00:00, 275MB/s]\u001b[A\n","model-00010-of-00046.safetensors:  77% 703M/910M [00:02<00:00, 265MB/s]\u001b[A\n","model-00010-of-00046.safetensors:  81% 734M/910M [00:03<00:00, 252MB/s]\u001b[A\n","model-00010-of-00046.safetensors:  84% 765M/910M [00:03<00:00, 260MB/s]\u001b[A\n","model-00010-of-00046.safetensors:  88% 797M/910M [00:03<00:00, 255MB/s]\u001b[A\n","model-00010-of-00046.safetensors:  91% 828M/910M [00:03<00:00, 235MB/s]\u001b[A\n","model-00010-of-00046.safetensors:  94% 860M/910M [00:03<00:00, 222MB/s]\u001b[A\n","model-00010-of-00046.safetensors: 100% 910M/910M [00:03<00:00, 233MB/s]\n","Downloading shards:  22% 10/46 [01:14<03:51,  6.42s/it]\n","model-00011-of-00046.safetensors:   0% 0.00/910M [00:00<?, ?B/s]\u001b[A\n","model-00011-of-00046.safetensors:   1% 10.5M/910M [00:00<00:15, 59.4MB/s]\u001b[A\n","model-00011-of-00046.safetensors:   3% 31.5M/910M [00:00<00:07, 112MB/s] \u001b[A\n","model-00011-of-00046.safetensors:   6% 52.4M/910M [00:00<00:06, 136MB/s]\u001b[A\n","model-00011-of-00046.safetensors:   8% 73.4M/910M [00:00<00:05, 144MB/s]\u001b[A\n","model-00011-of-00046.safetensors:  10% 94.4M/910M [00:00<00:05, 149MB/s]\u001b[A\n","model-00011-of-00046.safetensors:  13% 115M/910M [00:00<00:04, 161MB/s] \u001b[A\n","model-00011-of-00046.safetensors:  15% 136M/910M [00:00<00:04, 169MB/s]\u001b[A\n","model-00011-of-00046.safetensors:  18% 168M/910M [00:01<00:04, 182MB/s]\u001b[A\n","model-00011-of-00046.safetensors:  21% 189M/910M [00:01<00:04, 170MB/s]\u001b[A\n","model-00011-of-00046.safetensors:  23% 210M/910M [00:01<00:04, 173MB/s]\u001b[A\n","model-00011-of-00046.safetensors:  25% 231M/910M [00:01<00:03, 174MB/s]\u001b[A\n","model-00011-of-00046.safetensors:  28% 252M/910M [00:01<00:04, 160MB/s]\u001b[A\n","model-00011-of-00046.safetensors:  30% 273M/910M [00:01<00:03, 168MB/s]\u001b[A\n","model-00011-of-00046.safetensors:  32% 294M/910M [00:01<00:03, 175MB/s]\u001b[A\n","model-00011-of-00046.safetensors:  35% 315M/910M [00:02<00:11, 50.4MB/s]\u001b[A\n","model-00011-of-00046.safetensors:  37% 336M/910M [00:03<00:15, 37.1MB/s]\u001b[A\n","model-00011-of-00046.safetensors:  40% 367M/910M [00:03<00:09, 56.0MB/s]\u001b[A\n","model-00011-of-00046.safetensors:  43% 388M/910M [00:04<00:07, 68.1MB/s]\u001b[A\n","model-00011-of-00046.safetensors:  45% 409M/910M [00:04<00:06, 82.4MB/s]\u001b[A\n","model-00011-of-00046.safetensors:  48% 440M/910M [00:04<00:04, 103MB/s] \u001b[A\n","model-00011-of-00046.safetensors:  51% 461M/910M [00:04<00:03, 115MB/s]\u001b[A\n","model-00011-of-00046.safetensors:  54% 493M/910M [00:04<00:02, 142MB/s]\u001b[A\n","model-00011-of-00046.safetensors:  58% 524M/910M [00:04<00:02, 147MB/s]\u001b[A\n","model-00011-of-00046.safetensors:  60% 545M/910M [00:04<00:02, 157MB/s]\u001b[A\n","model-00011-of-00046.safetensors:  62% 566M/910M [00:05<00:02, 159MB/s]\u001b[A\n","model-00011-of-00046.safetensors:  65% 587M/910M [00:05<00:01, 165MB/s]\u001b[A\n","model-00011-of-00046.safetensors:  68% 619M/910M [00:05<00:01, 187MB/s]\u001b[A\n","model-00011-of-00046.safetensors:  71% 650M/910M [00:05<00:01, 205MB/s]\u001b[A\n","model-00011-of-00046.safetensors:  75% 682M/910M [00:05<00:01, 184MB/s]\u001b[A\n","model-00011-of-00046.safetensors:  77% 703M/910M [00:05<00:01, 176MB/s]\u001b[A\n","model-00011-of-00046.safetensors:  81% 734M/910M [00:05<00:00, 190MB/s]\u001b[A\n","model-00011-of-00046.safetensors:  84% 765M/910M [00:06<00:00, 213MB/s]\u001b[A\n","model-00011-of-00046.safetensors:  88% 797M/910M [00:06<00:00, 207MB/s]\u001b[A\n","model-00011-of-00046.safetensors:  91% 828M/910M [00:06<00:00, 201MB/s]\u001b[A\n","model-00011-of-00046.safetensors:  94% 860M/910M [00:06<00:00, 215MB/s]\u001b[A\n","model-00011-of-00046.safetensors:  98% 891M/910M [00:10<00:00, 26.4MB/s]\u001b[A\n","model-00011-of-00046.safetensors: 100% 910M/910M [00:10<00:00, 89.2MB/s]\n","Downloading shards:  24% 11/46 [01:25<04:26,  7.62s/it]\n","model-00012-of-00046.safetensors:   0% 0.00/910M [00:00<?, ?B/s]\u001b[A\n","model-00012-of-00046.safetensors:   1% 10.5M/910M [00:00<00:09, 97.8MB/s]\u001b[A\n","model-00012-of-00046.safetensors:   3% 31.5M/910M [00:00<00:06, 133MB/s] \u001b[A\n","model-00012-of-00046.safetensors:   6% 52.4M/910M [00:00<00:05, 160MB/s]\u001b[A\n","model-00012-of-00046.safetensors:   9% 83.9M/910M [00:00<00:04, 178MB/s]\u001b[A\n","model-00012-of-00046.safetensors:  13% 115M/910M [00:00<00:04, 193MB/s] \u001b[A\n","model-00012-of-00046.safetensors:  16% 147M/910M [00:00<00:03, 200MB/s]\u001b[A\n","model-00012-of-00046.safetensors:  20% 178M/910M [00:00<00:03, 213MB/s]\u001b[A\n","model-00012-of-00046.safetensors:  23% 210M/910M [00:01<00:03, 217MB/s]\u001b[A\n","model-00012-of-00046.safetensors:  26% 241M/910M [00:01<00:03, 177MB/s]\u001b[A\n","model-00012-of-00046.safetensors:  29% 262M/910M [00:01<00:04, 155MB/s]\u001b[A\n","model-00012-of-00046.safetensors:  31% 283M/910M [00:01<00:04, 139MB/s]\u001b[A\n","model-00012-of-00046.safetensors:  33% 304M/910M [00:01<00:04, 133MB/s]\u001b[A\n","model-00012-of-00046.safetensors:  36% 325M/910M [00:02<00:04, 129MB/s]\u001b[A\n","model-00012-of-00046.safetensors:  38% 346M/910M [00:02<00:04, 134MB/s]\u001b[A\n","model-00012-of-00046.safetensors:  40% 367M/910M [00:02<00:04, 135MB/s]\u001b[A\n","model-00012-of-00046.safetensors:  43% 388M/910M [00:02<00:03, 143MB/s]\u001b[A\n","model-00012-of-00046.safetensors:  45% 409M/910M [00:02<00:03, 154MB/s]\u001b[A\n","model-00012-of-00046.safetensors:  47% 430M/910M [00:02<00:03, 160MB/s]\u001b[A\n","model-00012-of-00046.safetensors:  50% 451M/910M [00:03<00:05, 82.3MB/s]\u001b[A\n","model-00012-of-00046.safetensors:  52% 472M/910M [00:03<00:04, 98.3MB/s]\u001b[A\n","model-00012-of-00046.safetensors:  54% 493M/910M [00:03<00:03, 113MB/s] \u001b[A\n","model-00012-of-00046.safetensors:  56% 514M/910M [00:03<00:03, 128MB/s]\u001b[A\n","model-00012-of-00046.safetensors:  59% 535M/910M [00:03<00:02, 140MB/s]\u001b[A\n","model-00012-of-00046.safetensors:  61% 556M/910M [00:03<00:02, 145MB/s]\u001b[A\n","model-00012-of-00046.safetensors:  63% 577M/910M [00:03<00:02, 159MB/s]\u001b[A\n","model-00012-of-00046.safetensors:  66% 598M/910M [00:04<00:01, 168MB/s]\u001b[A\n","model-00012-of-00046.safetensors:  68% 619M/910M [00:04<00:01, 172MB/s]\u001b[A\n","model-00012-of-00046.safetensors:  70% 640M/910M [00:04<00:01, 177MB/s]\u001b[A\n","model-00012-of-00046.safetensors:  73% 661M/910M [00:04<00:01, 185MB/s]\u001b[A\n","model-00012-of-00046.safetensors:  75% 682M/910M [00:04<00:01, 190MB/s]\u001b[A\n","model-00012-of-00046.safetensors:  78% 713M/910M [00:04<00:00, 207MB/s]\u001b[A\n","model-00012-of-00046.safetensors:  82% 744M/910M [00:04<00:00, 222MB/s]\u001b[A\n","model-00012-of-00046.safetensors:  85% 776M/910M [00:04<00:00, 211MB/s]\u001b[A\n","model-00012-of-00046.safetensors:  89% 807M/910M [00:05<00:00, 192MB/s]\u001b[A\n","model-00012-of-00046.safetensors:  91% 828M/910M [00:05<00:00, 176MB/s]\u001b[A\n","model-00012-of-00046.safetensors:  93% 849M/910M [00:05<00:00, 124MB/s]\u001b[A\n","model-00012-of-00046.safetensors:  97% 881M/910M [00:05<00:00, 146MB/s]\u001b[A\n","model-00012-of-00046.safetensors: 100% 910M/910M [00:05<00:00, 156MB/s]\n","Downloading shards:  26% 12/46 [01:31<04:02,  7.12s/it]\n","model-00013-of-00046.safetensors:   0% 0.00/910M [00:00<?, ?B/s]\u001b[A\n","model-00013-of-00046.safetensors:   1% 10.5M/910M [00:00<00:09, 93.3MB/s]\u001b[A\n","model-00013-of-00046.safetensors:   3% 31.5M/910M [00:00<00:07, 119MB/s] \u001b[A\n","model-00013-of-00046.safetensors:   6% 52.4M/910M [00:00<00:06, 132MB/s]\u001b[A\n","model-00013-of-00046.safetensors:   9% 83.9M/910M [00:00<00:04, 171MB/s]\u001b[A\n","model-00013-of-00046.safetensors:  12% 105M/910M [00:00<00:04, 178MB/s] \u001b[A\n","model-00013-of-00046.safetensors:  14% 126M/910M [00:00<00:04, 164MB/s]\u001b[A\n","model-00013-of-00046.safetensors:  16% 147M/910M [00:04<00:40, 18.9MB/s]\u001b[A\n","model-00013-of-00046.safetensors:  20% 178M/910M [00:04<00:24, 30.1MB/s]\u001b[A\n","model-00013-of-00046.safetensors:  23% 210M/910M [00:04<00:15, 44.6MB/s]\u001b[A\n","model-00013-of-00046.safetensors:  26% 241M/910M [00:04<00:10, 62.3MB/s]\u001b[A\n","model-00013-of-00046.safetensors:  30% 273M/910M [00:04<00:07, 80.8MB/s]\u001b[A\n","model-00013-of-00046.safetensors:  33% 304M/910M [00:04<00:06, 99.8MB/s]\u001b[A\n","model-00013-of-00046.safetensors:  37% 336M/910M [00:04<00:04, 123MB/s] \u001b[A\n","model-00013-of-00046.safetensors:  40% 367M/910M [00:04<00:03, 144MB/s]\u001b[A\n","model-00013-of-00046.safetensors:  44% 398M/910M [00:05<00:03, 167MB/s]\u001b[A\n","model-00013-of-00046.safetensors:  47% 430M/910M [00:05<00:02, 190MB/s]\u001b[A\n","model-00013-of-00046.safetensors:  51% 461M/910M [00:05<00:02, 206MB/s]\u001b[A\n","model-00013-of-00046.safetensors:  54% 493M/910M [00:05<00:02, 209MB/s]\u001b[A\n","model-00013-of-00046.safetensors:  58% 524M/910M [00:05<00:01, 218MB/s]\u001b[A\n","model-00013-of-00046.safetensors:  61% 556M/910M [00:05<00:01, 234MB/s]\u001b[A\n","model-00013-of-00046.safetensors:  65% 587M/910M [00:05<00:01, 235MB/s]\u001b[A\n","model-00013-of-00046.safetensors:  68% 619M/910M [00:05<00:01, 244MB/s]\u001b[A\n","model-00013-of-00046.safetensors:  71% 650M/910M [00:06<00:01, 247MB/s]\u001b[A\n","model-00013-of-00046.safetensors:  75% 682M/910M [00:06<00:00, 249MB/s]\u001b[A\n","model-00013-of-00046.safetensors:  78% 713M/910M [00:06<00:00, 247MB/s]\u001b[A\n","model-00013-of-00046.safetensors:  82% 744M/910M [00:06<00:00, 237MB/s]\u001b[A\n","model-00013-of-00046.safetensors:  85% 776M/910M [00:06<00:00, 244MB/s]\u001b[A\n","model-00013-of-00046.safetensors:  89% 807M/910M [00:06<00:00, 253MB/s]\u001b[A\n","model-00013-of-00046.safetensors:  92% 839M/910M [00:06<00:00, 251MB/s]\u001b[A\n","model-00013-of-00046.safetensors:  96% 870M/910M [00:06<00:00, 254MB/s]\u001b[A\n","model-00013-of-00046.safetensors: 100% 910M/910M [00:07<00:00, 127MB/s]\n","Downloading shards:  28% 13/46 [01:38<03:56,  7.18s/it]\n","model-00014-of-00046.safetensors:   0% 0.00/910M [00:00<?, ?B/s]\u001b[A\n","model-00014-of-00046.safetensors:   2% 21.0M/910M [00:00<00:04, 180MB/s]\u001b[A\n","model-00014-of-00046.safetensors:   6% 52.4M/910M [00:00<00:04, 214MB/s]\u001b[A\n","model-00014-of-00046.safetensors:   9% 83.9M/910M [00:00<00:03, 225MB/s]\u001b[A\n","model-00014-of-00046.safetensors:  13% 115M/910M [00:00<00:03, 212MB/s] \u001b[A\n","model-00014-of-00046.safetensors:  16% 147M/910M [00:00<00:03, 198MB/s]\u001b[A\n","model-00014-of-00046.safetensors:  20% 178M/910M [00:00<00:03, 216MB/s]\u001b[A\n","model-00014-of-00046.safetensors:  23% 210M/910M [00:00<00:02, 237MB/s]\u001b[A\n","model-00014-of-00046.safetensors:  26% 241M/910M [00:01<00:02, 232MB/s]\u001b[A\n","model-00014-of-00046.safetensors:  30% 273M/910M [00:01<00:02, 230MB/s]\u001b[A\n","model-00014-of-00046.safetensors:  33% 304M/910M [00:01<00:02, 235MB/s]\u001b[A\n","model-00014-of-00046.safetensors:  37% 336M/910M [00:01<00:02, 242MB/s]\u001b[A\n","model-00014-of-00046.safetensors:  40% 367M/910M [00:01<00:02, 247MB/s]\u001b[A\n","model-00014-of-00046.safetensors:  44% 398M/910M [00:01<00:02, 255MB/s]\u001b[A\n","model-00014-of-00046.safetensors:  47% 430M/910M [00:01<00:01, 244MB/s]\u001b[A\n","model-00014-of-00046.safetensors:  51% 461M/910M [00:01<00:01, 249MB/s]\u001b[A\n","model-00014-of-00046.safetensors:  54% 493M/910M [00:02<00:01, 248MB/s]\u001b[A\n","model-00014-of-00046.safetensors:  58% 524M/910M [00:02<00:02, 163MB/s]\u001b[A\n","model-00014-of-00046.safetensors:  62% 566M/910M [00:02<00:01, 198MB/s]\u001b[A\n","model-00014-of-00046.safetensors:  66% 598M/910M [00:02<00:01, 205MB/s]\u001b[A\n","model-00014-of-00046.safetensors:  69% 629M/910M [00:03<00:01, 164MB/s]\u001b[A\n","model-00014-of-00046.safetensors:  71% 650M/910M [00:03<00:01, 169MB/s]\u001b[A\n","model-00014-of-00046.safetensors:  74% 671M/910M [00:03<00:01, 173MB/s]\u001b[A\n","model-00014-of-00046.safetensors:  76% 692M/910M [00:03<00:01, 171MB/s]\u001b[A\n","model-00014-of-00046.safetensors:  78% 713M/910M [00:03<00:01, 174MB/s]\u001b[A\n","model-00014-of-00046.safetensors:  81% 734M/910M [00:06<00:08, 20.4MB/s]\u001b[A\n","model-00014-of-00046.safetensors:  85% 776M/910M [00:07<00:03, 34.4MB/s]\u001b[A\n","model-00014-of-00046.safetensors:  88% 797M/910M [00:07<00:02, 42.9MB/s]\u001b[A\n","model-00014-of-00046.safetensors:  91% 828M/910M [00:07<00:01, 58.3MB/s]\u001b[A\n","model-00014-of-00046.safetensors:  93% 849M/910M [00:07<00:00, 68.4MB/s]\u001b[A\n","model-00014-of-00046.safetensors:  96% 870M/910M [00:07<00:00, 80.8MB/s]\u001b[A\n","model-00014-of-00046.safetensors: 100% 910M/910M [00:07<00:00, 117MB/s] \n","Downloading shards:  30% 14/46 [01:46<03:56,  7.40s/it]\n","model-00015-of-00046.safetensors:   0% 0.00/910M [00:00<?, ?B/s]\u001b[A\n","model-00015-of-00046.safetensors:   1% 10.5M/910M [00:00<00:11, 81.7MB/s]\u001b[A\n","model-00015-of-00046.safetensors:   3% 31.5M/910M [00:00<00:06, 129MB/s] \u001b[A\n","model-00015-of-00046.safetensors:   7% 62.9M/910M [00:00<00:04, 176MB/s]\u001b[A\n","model-00015-of-00046.safetensors:  10% 94.4M/910M [00:00<00:03, 213MB/s]\u001b[A\n","model-00015-of-00046.safetensors:  14% 126M/910M [00:00<00:03, 211MB/s] \u001b[A\n","model-00015-of-00046.safetensors:  17% 157M/910M [00:00<00:03, 209MB/s]\u001b[A\n","model-00015-of-00046.safetensors:  21% 189M/910M [00:00<00:03, 219MB/s]\u001b[A\n","model-00015-of-00046.safetensors:  24% 220M/910M [00:02<00:10, 66.3MB/s]\u001b[A\n","model-00015-of-00046.safetensors:  28% 252M/910M [00:02<00:07, 86.3MB/s]\u001b[A\n","model-00015-of-00046.safetensors:  31% 283M/910M [00:02<00:05, 109MB/s] \u001b[A\n","model-00015-of-00046.safetensors:  35% 315M/910M [00:02<00:04, 131MB/s]\u001b[A\n","model-00015-of-00046.safetensors:  38% 346M/910M [00:02<00:03, 151MB/s]\u001b[A\n","model-00015-of-00046.safetensors:  41% 377M/910M [00:02<00:03, 169MB/s]\u001b[A\n","model-00015-of-00046.safetensors:  45% 409M/910M [00:02<00:02, 190MB/s]\u001b[A\n","model-00015-of-00046.safetensors:  48% 440M/910M [00:03<00:02, 201MB/s]\u001b[A\n","model-00015-of-00046.safetensors:  52% 472M/910M [00:03<00:01, 221MB/s]\u001b[A\n","model-00015-of-00046.safetensors:  55% 503M/910M [00:03<00:01, 219MB/s]\u001b[A\n","model-00015-of-00046.safetensors:  59% 535M/910M [00:03<00:01, 233MB/s]\u001b[A\n","model-00015-of-00046.safetensors:  62% 566M/910M [00:03<00:01, 231MB/s]\u001b[A\n","model-00015-of-00046.safetensors:  66% 598M/910M [00:03<00:01, 235MB/s]\u001b[A\n","model-00015-of-00046.safetensors:  69% 629M/910M [00:03<00:01, 236MB/s]\u001b[A\n","model-00015-of-00046.safetensors:  73% 661M/910M [00:03<00:01, 239MB/s]\u001b[A\n","model-00015-of-00046.safetensors:  76% 692M/910M [00:04<00:00, 244MB/s]\u001b[A\n","model-00015-of-00046.safetensors:  79% 724M/910M [00:04<00:00, 246MB/s]\u001b[A\n","model-00015-of-00046.safetensors:  83% 755M/910M [00:04<00:00, 242MB/s]\u001b[A\n","model-00015-of-00046.safetensors:  86% 786M/910M [00:04<00:00, 243MB/s]\u001b[A\n","model-00015-of-00046.safetensors:  90% 818M/910M [00:04<00:00, 239MB/s]\u001b[A\n","model-00015-of-00046.safetensors:  93% 849M/910M [00:04<00:00, 250MB/s]\u001b[A\n","model-00015-of-00046.safetensors:  97% 881M/910M [00:04<00:00, 247MB/s]\u001b[A\n","model-00015-of-00046.safetensors: 100% 910M/910M [00:04<00:00, 184MB/s]\n","Downloading shards:  33% 15/46 [01:51<03:27,  6.70s/it]\n","model-00016-of-00046.safetensors:   0% 0.00/910M [00:00<?, ?B/s]\u001b[A\n","model-00016-of-00046.safetensors:   2% 21.0M/910M [00:00<00:05, 151MB/s]\u001b[A\n","model-00016-of-00046.safetensors:   5% 41.9M/910M [00:00<00:04, 179MB/s]\u001b[A\n","model-00016-of-00046.safetensors:   8% 73.4M/910M [00:00<00:04, 193MB/s]\u001b[A\n","model-00016-of-00046.safetensors:  12% 105M/910M [00:00<00:03, 218MB/s] \u001b[A\n","model-00016-of-00046.safetensors:  15% 136M/910M [00:00<00:03, 245MB/s]\u001b[A\n","model-00016-of-00046.safetensors:  18% 168M/910M [00:00<00:03, 230MB/s]\u001b[A\n","model-00016-of-00046.safetensors:  22% 199M/910M [00:00<00:03, 227MB/s]\u001b[A\n","model-00016-of-00046.safetensors:  25% 231M/910M [00:01<00:03, 208MB/s]\u001b[A\n","model-00016-of-00046.safetensors:  29% 262M/910M [00:01<00:02, 218MB/s]\u001b[A\n","model-00016-of-00046.safetensors:  32% 294M/910M [00:02<00:07, 83.5MB/s]\u001b[A\n","model-00016-of-00046.safetensors:  36% 325M/910M [00:02<00:05, 106MB/s] \u001b[A\n","model-00016-of-00046.safetensors:  39% 357M/910M [00:02<00:04, 128MB/s]\u001b[A\n","model-00016-of-00046.safetensors:  43% 388M/910M [00:02<00:03, 146MB/s]\u001b[A\n","model-00016-of-00046.safetensors:  46% 419M/910M [00:02<00:03, 159MB/s]\u001b[A\n","model-00016-of-00046.safetensors:  48% 440M/910M [00:02<00:02, 164MB/s]\u001b[A\n","model-00016-of-00046.safetensors:  51% 461M/910M [00:02<00:02, 171MB/s]\u001b[A\n","model-00016-of-00046.safetensors:  53% 482M/910M [00:02<00:02, 175MB/s]\u001b[A\n","model-00016-of-00046.safetensors:  56% 514M/910M [00:03<00:02, 195MB/s]\u001b[A\n","model-00016-of-00046.safetensors:  60% 545M/910M [00:03<00:01, 208MB/s]\u001b[A\n","model-00016-of-00046.safetensors:  63% 577M/910M [00:03<00:01, 227MB/s]\u001b[A\n","model-00016-of-00046.safetensors:  67% 608M/910M [00:03<00:01, 169MB/s]\u001b[A\n","model-00016-of-00046.safetensors:  69% 629M/910M [00:03<00:01, 161MB/s]\u001b[A\n","model-00016-of-00046.safetensors:  71% 650M/910M [00:03<00:01, 163MB/s]\u001b[A\n","model-00016-of-00046.safetensors:  74% 671M/910M [00:04<00:01, 164MB/s]\u001b[A\n","model-00016-of-00046.safetensors:  76% 692M/910M [00:04<00:01, 173MB/s]\u001b[A\n","model-00016-of-00046.safetensors:  79% 724M/910M [00:04<00:00, 202MB/s]\u001b[A\n","model-00016-of-00046.safetensors:  83% 755M/910M [00:04<00:00, 213MB/s]\u001b[A\n","model-00016-of-00046.safetensors:  86% 786M/910M [00:04<00:00, 189MB/s]\u001b[A\n","model-00016-of-00046.safetensors:  89% 807M/910M [00:04<00:00, 182MB/s]\u001b[A\n","model-00016-of-00046.safetensors:  91% 828M/910M [00:04<00:00, 182MB/s]\u001b[A\n","model-00016-of-00046.safetensors:  93% 849M/910M [00:04<00:00, 185MB/s]\u001b[A\n","model-00016-of-00046.safetensors:  96% 870M/910M [00:08<00:01, 21.1MB/s]\u001b[A\n","model-00016-of-00046.safetensors: 100% 910M/910M [00:08<00:00, 109MB/s] \n","Downloading shards:  35% 16/46 [02:00<03:37,  7.25s/it]\n","model-00017-of-00046.safetensors:   0% 0.00/910M [00:00<?, ?B/s]\u001b[A\n","model-00017-of-00046.safetensors:   1% 10.5M/910M [00:00<00:15, 57.9MB/s]\u001b[A\n","model-00017-of-00046.safetensors:   3% 31.5M/910M [00:00<00:08, 109MB/s] \u001b[A\n","model-00017-of-00046.safetensors:   7% 62.9M/910M [00:00<00:05, 157MB/s]\u001b[A\n","model-00017-of-00046.safetensors:   9% 83.9M/910M [00:00<00:05, 162MB/s]\u001b[A\n","model-00017-of-00046.safetensors:  12% 105M/910M [00:00<00:04, 172MB/s] \u001b[A\n","model-00017-of-00046.safetensors:  15% 136M/910M [00:00<00:04, 193MB/s]\u001b[A\n","model-00017-of-00046.safetensors:  18% 168M/910M [00:00<00:03, 203MB/s]\u001b[A\n","model-00017-of-00046.safetensors:  22% 199M/910M [00:01<00:03, 227MB/s]\u001b[A\n","model-00017-of-00046.safetensors:  25% 231M/910M [00:01<00:02, 238MB/s]\u001b[A\n","model-00017-of-00046.safetensors:  29% 262M/910M [00:01<00:02, 245MB/s]\u001b[A\n","model-00017-of-00046.safetensors:  32% 294M/910M [00:01<00:02, 236MB/s]\u001b[A\n","model-00017-of-00046.safetensors:  36% 325M/910M [00:01<00:02, 244MB/s]\u001b[A\n","model-00017-of-00046.safetensors:  39% 357M/910M [00:01<00:02, 240MB/s]\u001b[A\n","model-00017-of-00046.safetensors:  43% 388M/910M [00:01<00:02, 248MB/s]\u001b[A\n","model-00017-of-00046.safetensors:  46% 419M/910M [00:01<00:01, 246MB/s]\u001b[A\n","model-00017-of-00046.safetensors:  50% 451M/910M [00:02<00:01, 249MB/s]\u001b[A\n","model-00017-of-00046.safetensors:  53% 482M/910M [00:02<00:01, 248MB/s]\u001b[A\n","model-00017-of-00046.safetensors:  56% 514M/910M [00:02<00:01, 251MB/s]\u001b[A\n","model-00017-of-00046.safetensors:  60% 545M/910M [00:02<00:01, 248MB/s]\u001b[A\n","model-00017-of-00046.safetensors:  63% 577M/910M [00:02<00:01, 256MB/s]\u001b[A\n","model-00017-of-00046.safetensors:  67% 608M/910M [00:02<00:01, 252MB/s]\u001b[A\n","model-00017-of-00046.safetensors:  70% 640M/910M [00:02<00:01, 248MB/s]\u001b[A\n","model-00017-of-00046.safetensors:  74% 671M/910M [00:02<00:00, 247MB/s]\u001b[A\n","model-00017-of-00046.safetensors:  77% 703M/910M [00:03<00:00, 254MB/s]\u001b[A\n","model-00017-of-00046.safetensors:  81% 734M/910M [00:03<00:00, 249MB/s]\u001b[A\n","model-00017-of-00046.safetensors:  84% 765M/910M [00:03<00:00, 253MB/s]\u001b[A\n","model-00017-of-00046.safetensors:  88% 797M/910M [00:03<00:00, 253MB/s]\u001b[A\n","model-00017-of-00046.safetensors:  91% 828M/910M [00:03<00:00, 248MB/s]\u001b[A\n","model-00017-of-00046.safetensors:  94% 860M/910M [00:03<00:00, 238MB/s]\u001b[A\n","model-00017-of-00046.safetensors: 100% 910M/910M [00:03<00:00, 231MB/s]\n","Downloading shards:  37% 17/46 [02:04<03:02,  6.29s/it]\n","model-00018-of-00046.safetensors:   0% 0.00/910M [00:00<?, ?B/s]\u001b[A\n","model-00018-of-00046.safetensors:   1% 10.5M/910M [00:00<00:10, 86.3MB/s]\u001b[A\n","model-00018-of-00046.safetensors:   3% 31.5M/910M [00:00<00:06, 129MB/s] \u001b[A\n","model-00018-of-00046.safetensors:   7% 62.9M/910M [00:00<00:04, 174MB/s]\u001b[A\n","model-00018-of-00046.safetensors:  10% 94.4M/910M [00:00<00:04, 202MB/s]\u001b[A\n","model-00018-of-00046.safetensors:  13% 115M/910M [00:00<00:03, 202MB/s] \u001b[A\n","model-00018-of-00046.safetensors:  15% 136M/910M [00:00<00:04, 192MB/s]\u001b[A\n","model-00018-of-00046.safetensors:  18% 168M/910M [00:00<00:03, 203MB/s]\u001b[A\n","model-00018-of-00046.safetensors:  22% 199M/910M [00:01<00:03, 223MB/s]\u001b[A\n","model-00018-of-00046.safetensors:  25% 231M/910M [00:01<00:02, 233MB/s]\u001b[A\n","model-00018-of-00046.safetensors:  29% 262M/910M [00:01<00:02, 239MB/s]\u001b[A\n","model-00018-of-00046.safetensors:  32% 294M/910M [00:01<00:02, 252MB/s]\u001b[A\n","model-00018-of-00046.safetensors:  36% 325M/910M [00:01<00:02, 247MB/s]\u001b[A\n","model-00018-of-00046.safetensors:  39% 357M/910M [00:01<00:02, 250MB/s]\u001b[A\n","model-00018-of-00046.safetensors:  43% 388M/910M [00:01<00:02, 252MB/s]\u001b[A\n","model-00018-of-00046.safetensors:  46% 419M/910M [00:01<00:02, 240MB/s]\u001b[A\n","model-00018-of-00046.safetensors:  50% 451M/910M [00:02<00:01, 251MB/s]\u001b[A\n","model-00018-of-00046.safetensors:  53% 482M/910M [00:02<00:01, 222MB/s]\u001b[A\n","model-00018-of-00046.safetensors:  56% 514M/910M [00:02<00:01, 225MB/s]\u001b[A\n","model-00018-of-00046.safetensors:  60% 545M/910M [00:02<00:01, 229MB/s]\u001b[A\n","model-00018-of-00046.safetensors:  63% 577M/910M [00:02<00:01, 242MB/s]\u001b[A\n","model-00018-of-00046.safetensors:  67% 608M/910M [00:02<00:01, 253MB/s]\u001b[A\n","model-00018-of-00046.safetensors:  70% 640M/910M [00:02<00:01, 243MB/s]\u001b[A\n","model-00018-of-00046.safetensors:  74% 671M/910M [00:02<00:00, 247MB/s]\u001b[A\n","model-00018-of-00046.safetensors:  77% 703M/910M [00:03<00:00, 251MB/s]\u001b[A\n","model-00018-of-00046.safetensors:  81% 734M/910M [00:03<00:00, 215MB/s]\u001b[A\n","model-00018-of-00046.safetensors:  84% 765M/910M [00:03<00:00, 212MB/s]\u001b[A\n","model-00018-of-00046.safetensors:  88% 797M/910M [00:03<00:00, 188MB/s]\u001b[A\n","model-00018-of-00046.safetensors:  90% 818M/910M [00:03<00:00, 165MB/s]\u001b[A\n","model-00018-of-00046.safetensors:  92% 839M/910M [00:03<00:00, 165MB/s]\u001b[A\n","model-00018-of-00046.safetensors:  94% 860M/910M [00:04<00:00, 165MB/s]\u001b[A\n","model-00018-of-00046.safetensors:  97% 881M/910M [00:04<00:00, 168MB/s]\u001b[A\n","model-00018-of-00046.safetensors: 100% 910M/910M [00:04<00:00, 209MB/s]\n","Downloading shards:  39% 18/46 [02:08<02:40,  5.75s/it]\n","model-00019-of-00046.safetensors:   0% 0.00/910M [00:00<?, ?B/s]\u001b[A\n","model-00019-of-00046.safetensors:   1% 10.5M/910M [00:00<00:28, 31.2MB/s]\u001b[A\n","model-00019-of-00046.safetensors:   3% 31.5M/910M [00:00<00:12, 68.3MB/s]\u001b[A\n","model-00019-of-00046.safetensors:   6% 52.4M/910M [00:00<00:09, 88.7MB/s]\u001b[A\n","model-00019-of-00046.safetensors:   8% 73.4M/910M [00:00<00:07, 114MB/s] \u001b[A\n","model-00019-of-00046.safetensors:  12% 105M/910M [00:00<00:05, 150MB/s] \u001b[A\n","model-00019-of-00046.safetensors:  14% 126M/910M [00:01<00:05, 150MB/s]\u001b[A\n","model-00019-of-00046.safetensors:  16% 147M/910M [00:01<00:05, 142MB/s]\u001b[A\n","model-00019-of-00046.safetensors:  18% 168M/910M [00:01<00:05, 147MB/s]\u001b[A\n","model-00019-of-00046.safetensors:  21% 189M/910M [00:01<00:07, 99.6MB/s]\u001b[A\n","model-00019-of-00046.safetensors:  24% 220M/910M [00:01<00:05, 132MB/s] \u001b[A\n","model-00019-of-00046.safetensors:  26% 241M/910M [00:01<00:04, 137MB/s]\u001b[A\n","model-00019-of-00046.safetensors:  29% 262M/910M [00:02<00:04, 130MB/s]\u001b[A\n","model-00019-of-00046.safetensors:  31% 283M/910M [00:02<00:04, 132MB/s]\u001b[A\n","model-00019-of-00046.safetensors:  33% 304M/910M [00:02<00:04, 127MB/s]\u001b[A\n","model-00019-of-00046.safetensors:  36% 325M/910M [00:02<00:04, 122MB/s]\u001b[A\n","model-00019-of-00046.safetensors:  38% 346M/910M [00:02<00:04, 123MB/s]\u001b[A\n","model-00019-of-00046.safetensors:  40% 367M/910M [00:03<00:05, 103MB/s]\u001b[A\n","model-00019-of-00046.safetensors:  43% 388M/910M [00:03<00:07, 68.6MB/s]\u001b[A\n","model-00019-of-00046.safetensors:  44% 398M/910M [00:05<00:17, 28.9MB/s]\u001b[A\n","model-00019-of-00046.safetensors:  46% 419M/910M [00:05<00:12, 40.2MB/s]\u001b[A\n","model-00019-of-00046.safetensors:  47% 430M/910M [00:05<00:10, 44.1MB/s]\u001b[A\n","model-00019-of-00046.safetensors:  48% 440M/910M [00:05<00:10, 46.6MB/s]\u001b[A\n","model-00019-of-00046.safetensors:  50% 451M/910M [00:05<00:09, 49.4MB/s]\u001b[A\n","model-00019-of-00046.safetensors:  51% 461M/910M [00:05<00:08, 52.4MB/s]\u001b[A\n","model-00019-of-00046.safetensors:  52% 472M/910M [00:05<00:07, 56.0MB/s]\u001b[A\n","model-00019-of-00046.safetensors:  53% 482M/910M [00:06<00:07, 58.7MB/s]\u001b[A\n","model-00019-of-00046.safetensors:  54% 493M/910M [00:06<00:06, 62.1MB/s]\u001b[A\n","model-00019-of-00046.safetensors:  55% 503M/910M [00:06<00:06, 65.4MB/s]\u001b[A\n","model-00019-of-00046.safetensors:  56% 514M/910M [00:06<00:05, 69.7MB/s]\u001b[A\n","model-00019-of-00046.safetensors:  58% 524M/910M [00:06<00:05, 71.7MB/s]\u001b[A\n","model-00019-of-00046.safetensors:  59% 535M/910M [00:06<00:05, 74.9MB/s]\u001b[A\n","model-00019-of-00046.safetensors:  60% 545M/910M [00:06<00:04, 76.2MB/s]\u001b[A\n","model-00019-of-00046.safetensors:  61% 556M/910M [00:07<00:04, 79.9MB/s]\u001b[A\n","model-00019-of-00046.safetensors:  62% 566M/910M [00:07<00:04, 81.7MB/s]\u001b[A\n","model-00019-of-00046.safetensors:  63% 577M/910M [00:07<00:04, 82.7MB/s]\u001b[A\n","model-00019-of-00046.safetensors:  65% 587M/910M [00:07<00:03, 84.1MB/s]\u001b[A\n","model-00019-of-00046.safetensors:  66% 598M/910M [00:07<00:03, 88.5MB/s]\u001b[A\n","model-00019-of-00046.safetensors:  67% 608M/910M [00:07<00:03, 90.0MB/s]\u001b[A\n","model-00019-of-00046.safetensors:  68% 619M/910M [00:07<00:03, 92.7MB/s]\u001b[A\n","model-00019-of-00046.safetensors:  69% 629M/910M [00:07<00:03, 93.2MB/s]\u001b[A\n","model-00019-of-00046.safetensors:  70% 640M/910M [00:07<00:02, 95.3MB/s]\u001b[A\n","model-00019-of-00046.safetensors:  71% 650M/910M [00:08<00:02, 95.6MB/s]\u001b[A\n","model-00019-of-00046.safetensors:  74% 671M/910M [00:08<00:02, 100MB/s] \u001b[A\n","model-00019-of-00046.safetensors:  75% 682M/910M [00:08<00:02, 100MB/s]\u001b[A\n","model-00019-of-00046.safetensors:  76% 692M/910M [00:08<00:02, 87.5MB/s]\u001b[A\n","model-00019-of-00046.safetensors:  78% 713M/910M [00:08<00:02, 92.0MB/s]\u001b[A\n","model-00019-of-00046.safetensors:  79% 724M/910M [00:08<00:02, 92.0MB/s]\u001b[A\n","model-00019-of-00046.safetensors:  82% 744M/910M [00:09<00:01, 99.8MB/s]\u001b[A\n","model-00019-of-00046.safetensors:  83% 755M/910M [00:09<00:01, 97.4MB/s]\u001b[A\n","model-00019-of-00046.safetensors:  84% 765M/910M [00:09<00:01, 96.8MB/s]\u001b[A\n","model-00019-of-00046.safetensors:  85% 776M/910M [00:09<00:01, 87.5MB/s]\u001b[A\n","model-00019-of-00046.safetensors:  88% 797M/910M [00:09<00:01, 98.8MB/s]\u001b[A\n","model-00019-of-00046.safetensors:  90% 818M/910M [00:10<00:01, 64.3MB/s]\u001b[A\n","model-00019-of-00046.safetensors:  92% 839M/910M [00:10<00:00, 73.6MB/s]\u001b[A\n","model-00019-of-00046.safetensors:  93% 849M/910M [00:10<00:00, 72.9MB/s]\u001b[A\n","model-00019-of-00046.safetensors:  96% 870M/910M [00:10<00:00, 81.0MB/s]\u001b[A\n","model-00019-of-00046.safetensors:  98% 891M/910M [00:10<00:00, 86.6MB/s]\u001b[A\n","model-00019-of-00046.safetensors:  99% 902M/910M [00:11<00:00, 73.2MB/s]\u001b[A\n","model-00019-of-00046.safetensors: 100% 910M/910M [00:11<00:00, 80.9MB/s]\n","Downloading shards:  41% 19/46 [02:20<03:21,  7.45s/it]\n","model-00020-of-00046.safetensors:   0% 0.00/910M [00:00<?, ?B/s]\u001b[A\n","model-00020-of-00046.safetensors:   1% 10.5M/910M [00:00<00:45, 19.7MB/s]\u001b[A\n","model-00020-of-00046.safetensors:   2% 21.0M/910M [00:01<00:44, 20.1MB/s]\u001b[A\n","model-00020-of-00046.safetensors:   3% 31.5M/910M [00:01<00:44, 19.7MB/s]\u001b[A\n","model-00020-of-00046.safetensors:   5% 41.9M/910M [00:02<00:40, 21.4MB/s]\u001b[A\n","model-00020-of-00046.safetensors:   6% 52.4M/910M [00:02<00:39, 21.9MB/s]\u001b[A\n","model-00020-of-00046.safetensors:   7% 62.9M/910M [00:03<00:40, 21.1MB/s]\u001b[A\n","model-00020-of-00046.safetensors:   8% 73.4M/910M [00:03<00:38, 21.6MB/s]\u001b[A\n","model-00020-of-00046.safetensors:   9% 83.9M/910M [00:03<00:29, 27.6MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  10% 94.4M/910M [00:03<00:23, 34.6MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  14% 126M/910M [00:03<00:11, 65.4MB/s] \u001b[A\n","model-00020-of-00046.safetensors:  15% 136M/910M [00:04<00:11, 65.7MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  16% 147M/910M [00:04<00:13, 55.7MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  17% 157M/910M [00:04<00:15, 49.0MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  18% 168M/910M [00:04<00:16, 45.2MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  20% 178M/910M [00:05<00:17, 41.3MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  21% 189M/910M [00:05<00:18, 38.6MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  22% 199M/910M [00:05<00:18, 37.6MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  23% 210M/910M [00:06<00:19, 36.0MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  24% 220M/910M [00:06<00:20, 33.2MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  25% 231M/910M [00:06<00:22, 30.8MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  26% 241M/910M [00:07<00:22, 29.6MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  28% 252M/910M [00:07<00:22, 29.1MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  29% 262M/910M [00:08<00:22, 28.8MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  30% 273M/910M [00:08<00:22, 28.6MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  31% 283M/910M [00:08<00:20, 30.0MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  32% 294M/910M [00:09<00:20, 30.5MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  33% 304M/910M [00:09<00:19, 31.6MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  35% 315M/910M [00:09<00:18, 32.1MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  36% 325M/910M [00:10<00:17, 32.6MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  37% 336M/910M [00:10<00:21, 26.6MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  38% 346M/910M [00:11<00:22, 25.0MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  39% 357M/910M [00:11<00:22, 25.2MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  40% 367M/910M [00:11<00:22, 24.7MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  41% 377M/910M [00:12<00:21, 24.2MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  43% 388M/910M [00:12<00:20, 25.1MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  44% 398M/910M [00:13<00:20, 24.9MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  45% 409M/910M [00:13<00:19, 25.8MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  46% 419M/910M [00:14<00:19, 24.8MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  47% 430M/910M [00:14<00:15, 32.0MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  50% 451M/910M [00:14<00:09, 50.1MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  52% 472M/910M [00:14<00:06, 69.6MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  54% 493M/910M [00:14<00:07, 55.7MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  55% 503M/910M [00:15<00:09, 43.3MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  56% 514M/910M [00:15<00:09, 40.5MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  58% 524M/910M [00:15<00:10, 37.9MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  59% 535M/910M [00:16<00:10, 35.1MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  60% 545M/910M [00:16<00:10, 34.1MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  61% 556M/910M [00:17<00:11, 31.9MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  62% 566M/910M [00:17<00:11, 30.1MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  63% 577M/910M [00:17<00:11, 28.6MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  65% 587M/910M [00:18<00:11, 28.7MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  66% 598M/910M [00:18<00:10, 29.3MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  67% 608M/910M [00:18<00:10, 29.6MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  68% 619M/910M [00:19<00:10, 29.1MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  69% 629M/910M [00:19<00:09, 29.2MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  70% 640M/910M [00:19<00:08, 31.1MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  71% 650M/910M [00:20<00:08, 31.9MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  73% 661M/910M [00:20<00:07, 32.5MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  74% 671M/910M [00:20<00:07, 32.4MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  75% 682M/910M [00:21<00:09, 24.2MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  76% 692M/910M [00:21<00:08, 25.8MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  77% 703M/910M [00:22<00:07, 27.3MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  78% 713M/910M [00:22<00:07, 27.8MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  79% 724M/910M [00:22<00:06, 28.9MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  81% 734M/910M [00:23<00:05, 29.7MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  82% 744M/910M [00:23<00:05, 31.0MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  83% 755M/910M [00:24<00:05, 27.6MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  84% 765M/910M [00:24<00:04, 33.4MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  85% 776M/910M [00:24<00:04, 33.6MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  88% 797M/910M [00:24<00:02, 53.7MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  91% 828M/910M [00:24<00:00, 88.4MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  93% 849M/910M [00:24<00:00, 104MB/s] \u001b[A\n","model-00020-of-00046.safetensors:  96% 870M/910M [00:25<00:00, 120MB/s]\u001b[A\n","model-00020-of-00046.safetensors:  98% 891M/910M [00:25<00:00, 121MB/s]\u001b[A\n","model-00020-of-00046.safetensors: 100% 910M/910M [00:25<00:00, 35.6MB/s]\n","Downloading shards:  43% 20/46 [02:45<05:36, 12.93s/it]\n","model-00021-of-00046.safetensors:   0% 0.00/910M [00:00<?, ?B/s]\u001b[A\n","model-00021-of-00046.safetensors:   1% 10.5M/910M [00:00<00:15, 58.7MB/s]\u001b[A\n","model-00021-of-00046.safetensors:   3% 31.5M/910M [00:00<00:07, 113MB/s] \u001b[A\n","model-00021-of-00046.safetensors:   7% 62.9M/910M [00:00<00:05, 159MB/s]\u001b[A\n","model-00021-of-00046.safetensors:   9% 83.9M/910M [00:00<00:05, 147MB/s]\u001b[A\n","model-00021-of-00046.safetensors:  12% 105M/910M [00:00<00:05, 148MB/s] \u001b[A\n","model-00021-of-00046.safetensors:  14% 126M/910M [00:00<00:05, 152MB/s]\u001b[A\n","model-00021-of-00046.safetensors:  16% 147M/910M [00:01<00:04, 157MB/s]\u001b[A\n","model-00021-of-00046.safetensors:  20% 178M/910M [00:01<00:04, 180MB/s]\u001b[A\n","model-00021-of-00046.safetensors:  23% 210M/910M [00:01<00:03, 192MB/s]\u001b[A\n","model-00021-of-00046.safetensors:  25% 231M/910M [00:01<00:03, 194MB/s]\u001b[A\n","model-00021-of-00046.safetensors:  29% 262M/910M [00:01<00:03, 208MB/s]\u001b[A\n","model-00021-of-00046.safetensors:  31% 283M/910M [00:01<00:03, 178MB/s]\u001b[A\n","model-00021-of-00046.safetensors:  33% 304M/910M [00:01<00:03, 186MB/s]\u001b[A\n","model-00021-of-00046.safetensors:  36% 325M/910M [00:01<00:03, 172MB/s]\u001b[A\n","model-00021-of-00046.safetensors:  39% 357M/910M [00:02<00:02, 189MB/s]\u001b[A\n","model-00021-of-00046.safetensors:  43% 388M/910M [00:02<00:02, 204MB/s]\u001b[A\n","model-00021-of-00046.safetensors:  46% 419M/910M [00:02<00:02, 207MB/s]\u001b[A\n","model-00021-of-00046.safetensors:  48% 440M/910M [00:02<00:02, 196MB/s]\u001b[A\n","model-00021-of-00046.safetensors:  51% 461M/910M [00:02<00:02, 186MB/s]\u001b[A\n","model-00021-of-00046.safetensors:  53% 482M/910M [00:02<00:02, 190MB/s]\u001b[A\n","model-00021-of-00046.safetensors:  56% 514M/910M [00:02<00:01, 199MB/s]\u001b[A\n","model-00021-of-00046.safetensors:  59% 535M/910M [00:05<00:11, 32.0MB/s]\u001b[A\n","model-00021-of-00046.safetensors:  63% 577M/910M [00:05<00:06, 52.0MB/s]\u001b[A\n","model-00021-of-00046.safetensors:  67% 608M/910M [00:05<00:04, 68.5MB/s]\u001b[A\n","model-00021-of-00046.safetensors:  70% 640M/910M [00:05<00:03, 83.5MB/s]\u001b[A\n","model-00021-of-00046.safetensors:  74% 671M/910M [00:05<00:02, 103MB/s] \u001b[A\n","model-00021-of-00046.safetensors:  77% 703M/910M [00:05<00:01, 124MB/s]\u001b[A\n","model-00021-of-00046.safetensors:  81% 734M/910M [00:05<00:01, 147MB/s]\u001b[A\n","model-00021-of-00046.safetensors:  84% 765M/910M [00:06<00:00, 168MB/s]\u001b[A\n","model-00021-of-00046.safetensors:  88% 797M/910M [00:06<00:00, 184MB/s]\u001b[A\n","model-00021-of-00046.safetensors:  91% 828M/910M [00:06<00:00, 203MB/s]\u001b[A\n","model-00021-of-00046.safetensors:  94% 860M/910M [00:06<00:00, 210MB/s]\u001b[A\n","model-00021-of-00046.safetensors: 100% 910M/910M [00:06<00:00, 136MB/s]\n","Downloading shards:  46% 21/46 [02:52<04:38, 11.15s/it]\n","model-00022-of-00046.safetensors:   0% 0.00/910M [00:00<?, ?B/s]\u001b[A\n","model-00022-of-00046.safetensors:   2% 21.0M/910M [00:00<00:06, 136MB/s]\u001b[A\n","model-00022-of-00046.safetensors:   5% 41.9M/910M [00:00<00:05, 158MB/s]\u001b[A\n","model-00022-of-00046.safetensors:   8% 73.4M/910M [00:00<00:04, 188MB/s]\u001b[A\n","model-00022-of-00046.safetensors:  10% 94.4M/910M [00:00<00:04, 164MB/s]\u001b[A\n","model-00022-of-00046.safetensors:  13% 115M/910M [00:00<00:04, 169MB/s] \u001b[A\n","model-00022-of-00046.safetensors:  15% 136M/910M [00:00<00:05, 144MB/s]\u001b[A\n","model-00022-of-00046.safetensors:  17% 157M/910M [00:01<00:07, 98.5MB/s]\u001b[A\n","model-00022-of-00046.safetensors:  20% 178M/910M [00:01<00:10, 70.6MB/s]\u001b[A\n","model-00022-of-00046.safetensors:  21% 189M/910M [00:02<00:12, 58.7MB/s]\u001b[A\n","model-00022-of-00046.safetensors:  22% 199M/910M [00:02<00:14, 50.6MB/s]\u001b[A\n","model-00022-of-00046.safetensors:  24% 220M/910M [00:02<00:10, 68.4MB/s]\u001b[A\n","model-00022-of-00046.safetensors:  26% 241M/910M [00:02<00:07, 87.1MB/s]\u001b[A\n","model-00022-of-00046.safetensors:  30% 273M/910M [00:02<00:05, 112MB/s] \u001b[A\n","model-00022-of-00046.safetensors:  32% 294M/910M [00:02<00:05, 123MB/s]\u001b[A\n","model-00022-of-00046.safetensors:  35% 315M/910M [00:03<00:06, 98.2MB/s]\u001b[A\n","model-00022-of-00046.safetensors:  37% 336M/910M [00:03<00:05, 103MB/s] \u001b[A\n","model-00022-of-00046.safetensors:  39% 357M/910M [00:03<00:05, 110MB/s]\u001b[A\n","model-00022-of-00046.safetensors:  43% 388M/910M [00:03<00:03, 138MB/s]\u001b[A\n","model-00022-of-00046.safetensors:  46% 419M/910M [00:03<00:03, 148MB/s]\u001b[A\n","model-00022-of-00046.safetensors:  50% 451M/910M [00:04<00:02, 157MB/s]\u001b[A\n","model-00022-of-00046.safetensors:  53% 482M/910M [00:04<00:02, 176MB/s]\u001b[A\n","model-00022-of-00046.safetensors:  56% 514M/910M [00:04<00:02, 181MB/s]\u001b[A\n","model-00022-of-00046.safetensors:  59% 535M/910M [00:04<00:02, 185MB/s]\u001b[A\n","model-00022-of-00046.safetensors:  61% 556M/910M [00:04<00:02, 171MB/s]\u001b[A\n","model-00022-of-00046.safetensors:  63% 577M/910M [00:04<00:02, 166MB/s]\u001b[A\n","model-00022-of-00046.safetensors:  67% 608M/910M [00:04<00:01, 169MB/s]\u001b[A\n","model-00022-of-00046.safetensors:  69% 629M/910M [00:08<00:14, 19.8MB/s]\u001b[A\n","model-00022-of-00046.safetensors:  71% 650M/910M [00:09<00:11, 23.1MB/s]\u001b[A\n","model-00022-of-00046.safetensors:  74% 671M/910M [00:09<00:07, 30.3MB/s]\u001b[A\n","model-00022-of-00046.safetensors:  76% 692M/910M [00:09<00:06, 35.9MB/s]\u001b[A\n","model-00022-of-00046.safetensors:  78% 713M/910M [00:10<00:05, 35.7MB/s]\u001b[A\n","model-00022-of-00046.safetensors:  82% 744M/910M [00:10<00:03, 52.3MB/s]\u001b[A\n","model-00022-of-00046.safetensors:  84% 765M/910M [00:10<00:02, 53.1MB/s]\u001b[A\n","model-00022-of-00046.safetensors:  88% 797M/910M [00:11<00:01, 63.1MB/s]\u001b[A\n","model-00022-of-00046.safetensors:  90% 818M/910M [00:11<00:01, 70.9MB/s]\u001b[A\n","model-00022-of-00046.safetensors:  91% 828M/910M [00:11<00:01, 67.9MB/s]\u001b[A\n","model-00022-of-00046.safetensors:  93% 849M/910M [00:11<00:00, 80.7MB/s]\u001b[A\n","model-00022-of-00046.safetensors:  96% 870M/910M [00:11<00:00, 88.6MB/s]\u001b[A\n","model-00022-of-00046.safetensors:  98% 891M/910M [00:11<00:00, 98.8MB/s]\u001b[A\n","model-00022-of-00046.safetensors: 100% 910M/910M [00:12<00:00, 75.0MB/s]\n","Downloading shards:  48% 22/46 [03:05<04:35, 11.49s/it]\n","model-00023-of-00046.safetensors:   0% 0.00/910M [00:00<?, ?B/s]\u001b[A\n","model-00023-of-00046.safetensors:   1% 10.5M/910M [00:00<00:08, 101MB/s]\u001b[A\n","model-00023-of-00046.safetensors:   3% 31.5M/910M [00:00<00:05, 147MB/s]\u001b[A\n","model-00023-of-00046.safetensors:   7% 62.9M/910M [00:00<00:04, 204MB/s]\u001b[A\n","model-00023-of-00046.safetensors:   9% 83.9M/910M [00:00<00:04, 183MB/s]\u001b[A\n","model-00023-of-00046.safetensors:  12% 105M/910M [00:00<00:07, 106MB/s] \u001b[A\n","model-00023-of-00046.safetensors:  14% 126M/910M [00:00<00:06, 117MB/s]\u001b[A\n","model-00023-of-00046.safetensors:  17% 157M/910M [00:01<00:05, 144MB/s]\u001b[A\n","model-00023-of-00046.safetensors:  20% 178M/910M [00:01<00:04, 147MB/s]\u001b[A\n","model-00023-of-00046.safetensors:  22% 199M/910M [00:01<00:05, 134MB/s]\u001b[A\n","model-00023-of-00046.safetensors:  25% 231M/910M [00:01<00:04, 165MB/s]\u001b[A\n","model-00023-of-00046.safetensors:  29% 262M/910M [00:01<00:03, 183MB/s]\u001b[A\n","model-00023-of-00046.safetensors:  31% 283M/910M [00:01<00:04, 156MB/s]\u001b[A\n","model-00023-of-00046.safetensors:  33% 304M/910M [00:02<00:03, 160MB/s]\u001b[A\n","model-00023-of-00046.safetensors:  36% 325M/910M [00:02<00:04, 134MB/s]\u001b[A\n","model-00023-of-00046.safetensors:  38% 346M/910M [00:09<01:00, 9.35MB/s]\u001b[A\n","model-00023-of-00046.safetensors:  40% 367M/910M [00:09<00:42, 12.8MB/s]\u001b[A\n","model-00023-of-00046.safetensors:  43% 388M/910M [00:10<00:29, 17.5MB/s]\u001b[A\n","model-00023-of-00046.safetensors:  45% 409M/910M [00:10<00:21, 23.4MB/s]\u001b[A\n","model-00023-of-00046.safetensors:  47% 430M/910M [00:10<00:15, 30.6MB/s]\u001b[A\n","model-00023-of-00046.safetensors:  50% 451M/910M [00:10<00:12, 36.6MB/s]\u001b[A\n","model-00023-of-00046.safetensors:  52% 472M/910M [00:10<00:09, 46.1MB/s]\u001b[A\n","model-00023-of-00046.safetensors:  54% 493M/910M [00:11<00:07, 55.2MB/s]\u001b[A\n","model-00023-of-00046.safetensors:  56% 514M/910M [00:11<00:05, 67.8MB/s]\u001b[A\n","model-00023-of-00046.safetensors:  59% 535M/910M [00:11<00:04, 83.9MB/s]\u001b[A\n","model-00023-of-00046.safetensors:  61% 556M/910M [00:11<00:03, 90.0MB/s]\u001b[A\n","model-00023-of-00046.safetensors:  63% 577M/910M [00:11<00:03, 108MB/s] \u001b[A\n","model-00023-of-00046.safetensors:  66% 598M/910M [00:11<00:02, 117MB/s]\u001b[A\n","model-00023-of-00046.safetensors:  68% 619M/910M [00:11<00:02, 120MB/s]\u001b[A\n","model-00023-of-00046.safetensors:  70% 640M/910M [00:12<00:02, 127MB/s]\u001b[A\n","model-00023-of-00046.safetensors:  73% 661M/910M [00:12<00:02, 119MB/s]\u001b[A\n","model-00023-of-00046.safetensors:  75% 682M/910M [00:12<00:01, 128MB/s]\u001b[A\n","model-00023-of-00046.safetensors:  77% 703M/910M [00:12<00:01, 142MB/s]\u001b[A\n","model-00023-of-00046.safetensors:  79% 724M/910M [00:12<00:01, 105MB/s]\u001b[A\n","model-00023-of-00046.safetensors:  82% 744M/910M [00:13<00:01, 111MB/s]\u001b[A\n","model-00023-of-00046.safetensors:  84% 765M/910M [00:13<00:01, 119MB/s]\u001b[A\n","model-00023-of-00046.safetensors:  86% 786M/910M [00:13<00:00, 132MB/s]\u001b[A\n","model-00023-of-00046.safetensors:  89% 807M/910M [00:13<00:00, 124MB/s]\u001b[A\n","model-00023-of-00046.safetensors:  91% 828M/910M [00:13<00:00, 135MB/s]\u001b[A\n","model-00023-of-00046.safetensors:  93% 849M/910M [00:13<00:00, 140MB/s]\u001b[A\n","model-00023-of-00046.safetensors:  96% 870M/910M [00:13<00:00, 143MB/s]\u001b[A\n","model-00023-of-00046.safetensors: 100% 910M/910M [00:14<00:00, 64.4MB/s]\n","Downloading shards:  50% 23/46 [03:19<04:43, 12.32s/it]\n","model-00024-of-00046.safetensors:   0% 0.00/910M [00:00<?, ?B/s]\u001b[A\n","model-00024-of-00046.safetensors:   1% 10.5M/910M [00:00<00:09, 93.1MB/s]\u001b[A\n","model-00024-of-00046.safetensors:   3% 31.5M/910M [00:00<00:06, 138MB/s] \u001b[A\n","model-00024-of-00046.safetensors:   6% 52.4M/910M [00:00<00:06, 135MB/s]\u001b[A\n","model-00024-of-00046.safetensors:   9% 83.9M/910M [00:00<00:04, 173MB/s]\u001b[A\n","model-00024-of-00046.safetensors:  12% 105M/910M [00:01<00:12, 62.1MB/s]\u001b[A\n","model-00024-of-00046.safetensors:  14% 126M/910M [00:01<00:09, 78.7MB/s]\u001b[A\n","model-00024-of-00046.safetensors:  16% 147M/910M [00:01<00:09, 83.7MB/s]\u001b[A\n","model-00024-of-00046.safetensors:  18% 168M/910M [00:01<00:07, 102MB/s] \u001b[A\n","model-00024-of-00046.safetensors:  21% 189M/910M [00:01<00:06, 113MB/s]\u001b[A\n","model-00024-of-00046.safetensors:  23% 210M/910M [00:02<00:08, 86.4MB/s]\u001b[A\n","model-00024-of-00046.safetensors:  25% 231M/910M [00:02<00:07, 97.0MB/s]\u001b[A\n","model-00024-of-00046.safetensors:  28% 252M/910M [00:02<00:06, 109MB/s] \u001b[A\n","model-00024-of-00046.safetensors:  30% 273M/910M [00:02<00:05, 121MB/s]\u001b[A\n","model-00024-of-00046.safetensors:  32% 294M/910M [00:03<00:06, 91.6MB/s]\u001b[A\n","model-00024-of-00046.safetensors:  35% 315M/910M [00:03<00:05, 105MB/s] \u001b[A\n","model-00024-of-00046.safetensors:  37% 336M/910M [00:03<00:05, 114MB/s]\u001b[A\n","model-00024-of-00046.safetensors:  39% 357M/910M [00:03<00:04, 119MB/s]\u001b[A\n","model-00024-of-00046.safetensors:  41% 377M/910M [00:03<00:04, 114MB/s]\u001b[A\n","model-00024-of-00046.safetensors:  44% 398M/910M [00:03<00:04, 123MB/s]\u001b[A\n","model-00024-of-00046.safetensors:  46% 419M/910M [00:04<00:04, 117MB/s]\u001b[A\n","model-00024-of-00046.safetensors:  50% 451M/910M [00:04<00:03, 132MB/s]\u001b[A\n","model-00024-of-00046.safetensors:  52% 472M/910M [00:05<00:07, 62.6MB/s]\u001b[A\n","model-00024-of-00046.safetensors:  53% 482M/910M [00:06<00:16, 25.3MB/s]\u001b[A\n","model-00024-of-00046.safetensors:  55% 503M/910M [00:06<00:12, 33.7MB/s]\u001b[A\n","model-00024-of-00046.safetensors:  58% 524M/910M [00:06<00:08, 45.5MB/s]\u001b[A\n","model-00024-of-00046.safetensors:  60% 545M/910M [00:07<00:06, 58.6MB/s]\u001b[A\n","model-00024-of-00046.safetensors:  63% 577M/910M [00:07<00:06, 50.7MB/s]\u001b[A\n","model-00024-of-00046.safetensors:  66% 598M/910M [00:07<00:05, 62.3MB/s]\u001b[A\n","model-00024-of-00046.safetensors:  68% 619M/910M [00:08<00:03, 74.0MB/s]\u001b[A\n","model-00024-of-00046.safetensors:  70% 640M/910M [00:08<00:03, 88.2MB/s]\u001b[A\n","model-00024-of-00046.safetensors:  73% 661M/910M [00:08<00:02, 97.1MB/s]\u001b[A\n","model-00024-of-00046.safetensors:  75% 682M/910M [00:08<00:02, 105MB/s] \u001b[A\n","model-00024-of-00046.safetensors:  77% 703M/910M [00:08<00:01, 105MB/s]\u001b[A\n","model-00024-of-00046.safetensors:  79% 724M/910M [00:08<00:01, 110MB/s]\u001b[A\n","model-00024-of-00046.safetensors:  82% 744M/910M [00:09<00:01, 113MB/s]\u001b[A\n","model-00024-of-00046.safetensors:  84% 765M/910M [00:09<00:01, 114MB/s]\u001b[A\n","model-00024-of-00046.safetensors:  86% 786M/910M [00:09<00:01, 123MB/s]\u001b[A\n","model-00024-of-00046.safetensors:  89% 807M/910M [00:13<00:05, 17.2MB/s]\u001b[A\n","model-00024-of-00046.safetensors:  92% 839M/910M [00:13<00:02, 27.2MB/s]\u001b[A\n","model-00024-of-00046.safetensors:  96% 870M/910M [00:13<00:01, 39.8MB/s]\u001b[A\n","model-00024-of-00046.safetensors: 100% 910M/910M [00:13<00:00, 67.0MB/s]\n","Downloading shards:  52% 24/46 [03:33<04:40, 12.74s/it]\n","model-00025-of-00046.safetensors:   0% 0.00/910M [00:00<?, ?B/s]\u001b[A\n","model-00025-of-00046.safetensors:   1% 10.5M/910M [00:00<00:09, 98.5MB/s]\u001b[A\n","model-00025-of-00046.safetensors:   3% 31.5M/910M [00:00<00:06, 130MB/s] \u001b[A\n","model-00025-of-00046.safetensors:   6% 52.4M/910M [00:00<00:05, 146MB/s]\u001b[A\n","model-00025-of-00046.safetensors:   8% 73.4M/910M [00:00<00:05, 166MB/s]\u001b[A\n","model-00025-of-00046.safetensors:  12% 105M/910M [00:00<00:03, 201MB/s] \u001b[A\n","model-00025-of-00046.safetensors:  14% 126M/910M [00:00<00:04, 195MB/s]\u001b[A\n","model-00025-of-00046.safetensors:  17% 157M/910M [00:00<00:03, 210MB/s]\u001b[A\n","model-00025-of-00046.safetensors:  20% 178M/910M [00:00<00:03, 207MB/s]\u001b[A\n","model-00025-of-00046.safetensors:  22% 199M/910M [00:05<00:42, 16.7MB/s]\u001b[A\n","model-00025-of-00046.safetensors:  24% 220M/910M [00:05<00:30, 22.7MB/s]\u001b[A\n","model-00025-of-00046.safetensors:  28% 252M/910M [00:05<00:18, 34.9MB/s]\u001b[A\n","model-00025-of-00046.safetensors:  30% 273M/910M [00:05<00:15, 40.4MB/s]\u001b[A\n","model-00025-of-00046.safetensors:  33% 304M/910M [00:05<00:10, 58.9MB/s]\u001b[A\n","model-00025-of-00046.safetensors:  36% 325M/910M [00:05<00:08, 72.0MB/s]\u001b[A\n","model-00025-of-00046.safetensors:  39% 357M/910M [00:06<00:05, 94.3MB/s]\u001b[A\n","model-00025-of-00046.safetensors:  43% 388M/910M [00:06<00:04, 120MB/s] \u001b[A\n","model-00025-of-00046.safetensors:  46% 419M/910M [00:06<00:03, 143MB/s]\u001b[A\n","model-00025-of-00046.safetensors:  50% 451M/910M [00:06<00:03, 146MB/s]\u001b[A\n","model-00025-of-00046.safetensors:  52% 472M/910M [00:06<00:03, 146MB/s]\u001b[A\n","model-00025-of-00046.safetensors:  55% 503M/910M [00:06<00:02, 167MB/s]\u001b[A\n","model-00025-of-00046.safetensors:  58% 524M/910M [00:06<00:02, 174MB/s]\u001b[A\n","model-00025-of-00046.safetensors:  60% 545M/910M [00:06<00:02, 179MB/s]\u001b[A\n","model-00025-of-00046.safetensors:  63% 577M/910M [00:07<00:01, 200MB/s]\u001b[A\n","model-00025-of-00046.safetensors:  67% 608M/910M [00:09<00:08, 36.7MB/s]\u001b[A\n","model-00025-of-00046.safetensors:  69% 629M/910M [00:09<00:06, 45.6MB/s]\u001b[A\n","model-00025-of-00046.safetensors:  73% 661M/910M [00:09<00:03, 63.7MB/s]\u001b[A\n","model-00025-of-00046.safetensors:  76% 692M/910M [00:09<00:02, 83.3MB/s]\u001b[A\n","model-00025-of-00046.safetensors:  79% 724M/910M [00:09<00:01, 104MB/s] \u001b[A\n","model-00025-of-00046.safetensors:  83% 755M/910M [00:10<00:01, 119MB/s]\u001b[A\n","model-00025-of-00046.safetensors:  85% 776M/910M [00:10<00:01, 107MB/s]\u001b[A\n","model-00025-of-00046.safetensors:  88% 797M/910M [00:10<00:00, 117MB/s]\u001b[A\n","model-00025-of-00046.safetensors:  91% 828M/910M [00:10<00:00, 132MB/s]\u001b[A\n","model-00025-of-00046.safetensors:  93% 849M/910M [00:10<00:00, 114MB/s]\u001b[A\n","model-00025-of-00046.safetensors:  96% 870M/910M [00:11<00:00, 85.8MB/s]\u001b[A\n","model-00025-of-00046.safetensors:  98% 891M/910M [00:11<00:00, 84.0MB/s]\u001b[A\n","model-00025-of-00046.safetensors: 100% 910M/910M [00:11<00:00, 77.3MB/s]\n","Downloading shards:  54% 25/46 [03:44<04:22, 12.49s/it]\n","model-00026-of-00046.safetensors:   0% 0.00/910M [00:00<?, ?B/s]\u001b[A\n","model-00026-of-00046.safetensors:   2% 21.0M/910M [00:00<00:06, 129MB/s]\u001b[A\n","model-00026-of-00046.safetensors:   5% 41.9M/910M [00:00<00:05, 155MB/s]\u001b[A\n","model-00026-of-00046.safetensors:   7% 62.9M/910M [00:00<00:04, 172MB/s]\u001b[A\n","model-00026-of-00046.safetensors:  10% 94.4M/910M [00:00<00:04, 194MB/s]\u001b[A\n","model-00026-of-00046.safetensors:  14% 126M/910M [00:00<00:04, 183MB/s] \u001b[A\n","model-00026-of-00046.safetensors:  16% 147M/910M [00:00<00:04, 184MB/s]\u001b[A\n","model-00026-of-00046.safetensors:  18% 168M/910M [00:00<00:04, 185MB/s]\u001b[A\n","model-00026-of-00046.safetensors:  21% 189M/910M [00:01<00:04, 180MB/s]\u001b[A\n","model-00026-of-00046.safetensors:  23% 210M/910M [00:01<00:03, 176MB/s]\u001b[A\n","model-00026-of-00046.safetensors:  25% 231M/910M [00:01<00:04, 166MB/s]\u001b[A\n","model-00026-of-00046.safetensors:  29% 262M/910M [00:01<00:03, 187MB/s]\u001b[A\n","model-00026-of-00046.safetensors:  32% 294M/910M [00:01<00:03, 171MB/s]\u001b[A\n","model-00026-of-00046.safetensors:  35% 315M/910M [00:02<00:08, 70.3MB/s]\u001b[A\n","model-00026-of-00046.safetensors:  37% 336M/910M [00:02<00:06, 85.0MB/s]\u001b[A\n","model-00026-of-00046.safetensors:  40% 367M/910M [00:02<00:04, 111MB/s] \u001b[A\n","model-00026-of-00046.safetensors:  44% 398M/910M [00:02<00:03, 135MB/s]\u001b[A\n","model-00026-of-00046.safetensors:  46% 419M/910M [00:03<00:03, 138MB/s]\u001b[A\n","model-00026-of-00046.safetensors:  48% 440M/910M [00:03<00:03, 148MB/s]\u001b[A\n","model-00026-of-00046.safetensors:  51% 461M/910M [00:03<00:03, 118MB/s]\u001b[A\n","model-00026-of-00046.safetensors:  53% 482M/910M [00:03<00:03, 111MB/s]\u001b[A\n","model-00026-of-00046.safetensors:  55% 503M/910M [00:03<00:03, 111MB/s]\u001b[A\n","model-00026-of-00046.safetensors:  58% 524M/910M [00:03<00:03, 115MB/s]\u001b[A\n","model-00026-of-00046.safetensors:  60% 545M/910M [00:04<00:02, 122MB/s]\u001b[A\n","model-00026-of-00046.safetensors:  62% 566M/910M [00:04<00:02, 129MB/s]\u001b[A\n","model-00026-of-00046.safetensors:  65% 587M/910M [00:04<00:02, 121MB/s]\u001b[A\n","model-00026-of-00046.safetensors:  67% 608M/910M [00:04<00:02, 131MB/s]\u001b[A\n","model-00026-of-00046.safetensors:  69% 629M/910M [00:04<00:01, 143MB/s]\u001b[A\n","model-00026-of-00046.safetensors:  71% 650M/910M [00:04<00:01, 141MB/s]\u001b[A\n","model-00026-of-00046.safetensors:  74% 671M/910M [00:04<00:01, 150MB/s]\u001b[A\n","model-00026-of-00046.safetensors:  76% 692M/910M [00:05<00:01, 152MB/s]\u001b[A\n","model-00026-of-00046.safetensors:  78% 713M/910M [00:05<00:01, 155MB/s]\u001b[A\n","model-00026-of-00046.safetensors:  81% 734M/910M [00:05<00:01, 155MB/s]\u001b[A\n","model-00026-of-00046.safetensors:  83% 755M/910M [00:05<00:00, 164MB/s]\u001b[A\n","model-00026-of-00046.safetensors:  86% 786M/910M [00:05<00:00, 193MB/s]\u001b[A\n","model-00026-of-00046.safetensors:  90% 818M/910M [00:05<00:00, 196MB/s]\u001b[A\n","model-00026-of-00046.safetensors:  92% 839M/910M [00:05<00:00, 178MB/s]\u001b[A\n","model-00026-of-00046.safetensors:  94% 860M/910M [00:06<00:00, 176MB/s]\u001b[A\n","model-00026-of-00046.safetensors:  97% 881M/910M [00:06<00:00, 180MB/s]\u001b[A\n","model-00026-of-00046.safetensors: 100% 910M/910M [00:06<00:00, 138MB/s]\n","Downloading shards:  57% 26/46 [03:51<03:35, 10.77s/it]\n","model-00027-of-00046.safetensors:   0% 0.00/910M [00:00<?, ?B/s]\u001b[A\n","model-00027-of-00046.safetensors:   1% 10.5M/910M [00:00<00:11, 78.0MB/s]\u001b[A\n","model-00027-of-00046.safetensors:   2% 21.0M/910M [00:00<00:38, 22.9MB/s]\u001b[A\n","model-00027-of-00046.safetensors:   5% 41.9M/910M [00:00<00:17, 50.4MB/s]\u001b[A\n","model-00027-of-00046.safetensors:   8% 73.4M/910M [00:01<00:09, 92.1MB/s]\u001b[A\n","model-00027-of-00046.safetensors:  12% 105M/910M [00:01<00:06, 129MB/s]  \u001b[A\n","model-00027-of-00046.safetensors:  15% 136M/910M [00:01<00:04, 163MB/s]\u001b[A\n","model-00027-of-00046.safetensors:  18% 168M/910M [00:01<00:04, 170MB/s]\u001b[A\n","model-00027-of-00046.safetensors:  21% 189M/910M [00:01<00:04, 175MB/s]\u001b[A\n","model-00027-of-00046.safetensors:  24% 220M/910M [00:01<00:03, 203MB/s]\u001b[A\n","model-00027-of-00046.safetensors:  28% 252M/910M [00:01<00:03, 218MB/s]\u001b[A\n","model-00027-of-00046.safetensors:  31% 283M/910M [00:01<00:02, 211MB/s]\u001b[A\n","model-00027-of-00046.safetensors:  35% 315M/910M [00:02<00:02, 212MB/s]\u001b[A\n","model-00027-of-00046.safetensors:  38% 346M/910M [00:02<00:02, 224MB/s]\u001b[A\n","model-00027-of-00046.safetensors:  41% 377M/910M [00:02<00:02, 229MB/s]\u001b[A\n","model-00027-of-00046.safetensors:  45% 409M/910M [00:02<00:02, 217MB/s]\u001b[A\n","model-00027-of-00046.safetensors:  48% 440M/910M [00:02<00:02, 227MB/s]\u001b[A\n","model-00027-of-00046.safetensors:  52% 472M/910M [00:02<00:01, 239MB/s]\u001b[A\n","model-00027-of-00046.safetensors:  55% 503M/910M [00:02<00:01, 234MB/s]\u001b[A\n","model-00027-of-00046.safetensors:  60% 545M/910M [00:03<00:01, 248MB/s]\u001b[A\n","model-00027-of-00046.safetensors:  63% 577M/910M [00:03<00:01, 248MB/s]\u001b[A\n","model-00027-of-00046.safetensors:  67% 608M/910M [00:03<00:01, 234MB/s]\u001b[A\n","model-00027-of-00046.safetensors:  70% 640M/910M [00:03<00:01, 228MB/s]\u001b[A\n","model-00027-of-00046.safetensors:  74% 671M/910M [00:03<00:01, 204MB/s]\u001b[A\n","model-00027-of-00046.safetensors:  77% 703M/910M [00:03<00:00, 217MB/s]\u001b[A\n","model-00027-of-00046.safetensors:  81% 734M/910M [00:06<00:05, 33.1MB/s]\u001b[A\n","model-00027-of-00046.safetensors:  83% 755M/910M [00:06<00:04, 37.5MB/s]\u001b[A\n","model-00027-of-00046.safetensors:  88% 797M/910M [00:07<00:01, 57.1MB/s]\u001b[A\n","model-00027-of-00046.safetensors:  91% 828M/910M [00:07<00:01, 74.6MB/s]\u001b[A\n","model-00027-of-00046.safetensors:  94% 860M/910M [00:07<00:00, 88.6MB/s]\u001b[A\n","model-00027-of-00046.safetensors: 100% 910M/910M [00:07<00:00, 119MB/s]\n","Downloading shards:  59% 27/46 [03:59<03:07,  9.87s/it]\n","model-00028-of-00046.safetensors:   0% 0.00/910M [00:00<?, ?B/s]\u001b[A\n","model-00028-of-00046.safetensors:   1% 10.5M/910M [00:00<00:10, 86.4MB/s]\u001b[A\n","model-00028-of-00046.safetensors:   3% 31.5M/910M [00:00<00:07, 122MB/s] \u001b[A\n","model-00028-of-00046.safetensors:   6% 52.4M/910M [00:00<00:05, 153MB/s]\u001b[A\n","model-00028-of-00046.safetensors:   9% 83.9M/910M [00:00<00:04, 203MB/s]\u001b[A\n","model-00028-of-00046.safetensors:  12% 105M/910M [00:00<00:03, 205MB/s] \u001b[A\n","model-00028-of-00046.safetensors:  14% 126M/910M [00:00<00:03, 203MB/s]\u001b[A\n","model-00028-of-00046.safetensors:  17% 157M/910M [00:00<00:03, 214MB/s]\u001b[A\n","model-00028-of-00046.safetensors:  21% 189M/910M [00:03<00:22, 31.6MB/s]\u001b[A\n","model-00028-of-00046.safetensors:  24% 220M/910M [00:03<00:15, 45.1MB/s]\u001b[A\n","model-00028-of-00046.safetensors:  28% 252M/910M [00:03<00:10, 61.3MB/s]\u001b[A\n","model-00028-of-00046.safetensors:  31% 283M/910M [00:03<00:07, 80.5MB/s]\u001b[A\n","model-00028-of-00046.safetensors:  33% 304M/910M [00:03<00:06, 86.7MB/s]\u001b[A\n","model-00028-of-00046.safetensors:  36% 325M/910M [00:03<00:06, 97.4MB/s]\u001b[A\n","model-00028-of-00046.safetensors:  38% 346M/910M [00:04<00:05, 107MB/s] \u001b[A\n","model-00028-of-00046.safetensors:  40% 367M/910M [00:04<00:04, 119MB/s]\u001b[A\n","model-00028-of-00046.safetensors:  43% 388M/910M [00:04<00:04, 130MB/s]\u001b[A\n","model-00028-of-00046.safetensors:  45% 409M/910M [00:04<00:03, 142MB/s]\u001b[A\n","model-00028-of-00046.safetensors:  47% 430M/910M [00:04<00:03, 145MB/s]\u001b[A\n","model-00028-of-00046.safetensors:  50% 451M/910M [00:04<00:03, 152MB/s]\u001b[A\n","model-00028-of-00046.safetensors:  52% 472M/910M [00:04<00:02, 154MB/s]\u001b[A\n","model-00028-of-00046.safetensors:  54% 493M/910M [00:05<00:02, 158MB/s]\u001b[A\n","model-00028-of-00046.safetensors:  56% 514M/910M [00:05<00:02, 144MB/s]\u001b[A\n","model-00028-of-00046.safetensors:  59% 535M/910M [00:05<00:02, 132MB/s]\u001b[A\n","model-00028-of-00046.safetensors:  61% 556M/910M [00:09<00:23, 15.2MB/s]\u001b[A\n","model-00028-of-00046.safetensors:  66% 598M/910M [00:09<00:11, 27.0MB/s]\u001b[A\n","model-00028-of-00046.safetensors:  68% 619M/910M [00:09<00:08, 34.0MB/s]\u001b[A\n","model-00028-of-00046.safetensors:  71% 650M/910M [00:10<00:05, 48.1MB/s]\u001b[A\n","model-00028-of-00046.safetensors:  74% 671M/910M [00:10<00:04, 49.5MB/s]\u001b[A\n","model-00028-of-00046.safetensors:  76% 692M/910M [00:10<00:04, 48.1MB/s]\u001b[A\n","model-00028-of-00046.safetensors:  78% 713M/910M [00:11<00:03, 52.4MB/s]\u001b[A\n","model-00028-of-00046.safetensors:  81% 734M/910M [00:11<00:02, 61.4MB/s]\u001b[A\n","model-00028-of-00046.safetensors:  82% 744M/910M [00:11<00:02, 62.2MB/s]\u001b[A\n","model-00028-of-00046.safetensors:  85% 776M/910M [00:11<00:01, 86.8MB/s]\u001b[A\n","model-00028-of-00046.safetensors:  89% 807M/910M [00:11<00:00, 111MB/s] \u001b[A\n","model-00028-of-00046.safetensors:  91% 828M/910M [00:12<00:00, 109MB/s]\u001b[A\n","model-00028-of-00046.safetensors:  94% 860M/910M [00:12<00:00, 136MB/s]\u001b[A\n","model-00028-of-00046.safetensors: 100% 910M/910M [00:12<00:00, 73.2MB/s]\n","Downloading shards:  61% 28/46 [04:12<03:12, 10.68s/it]\n","model-00029-of-00046.safetensors:   0% 0.00/910M [00:00<?, ?B/s]\u001b[A\n","model-00029-of-00046.safetensors:   3% 31.5M/910M [00:00<00:03, 232MB/s]\u001b[A\n","model-00029-of-00046.safetensors:   7% 62.9M/910M [00:00<00:04, 199MB/s]\u001b[A\n","model-00029-of-00046.safetensors:  10% 94.4M/910M [00:00<00:03, 219MB/s]\u001b[A\n","model-00029-of-00046.safetensors:  14% 126M/910M [00:00<00:03, 230MB/s] \u001b[A\n","model-00029-of-00046.safetensors:  17% 157M/910M [00:00<00:03, 206MB/s]\u001b[A\n","model-00029-of-00046.safetensors:  21% 189M/910M [00:00<00:03, 208MB/s]\u001b[A\n","model-00029-of-00046.safetensors:  24% 220M/910M [00:01<00:03, 226MB/s]\u001b[A\n","model-00029-of-00046.safetensors:  28% 252M/910M [00:01<00:03, 211MB/s]\u001b[A\n","model-00029-of-00046.safetensors:  31% 283M/910M [00:01<00:03, 190MB/s]\u001b[A\n","model-00029-of-00046.safetensors:  35% 315M/910M [00:01<00:02, 203MB/s]\u001b[A\n","model-00029-of-00046.safetensors:  38% 346M/910M [00:01<00:02, 217MB/s]\u001b[A\n","model-00029-of-00046.safetensors:  41% 377M/910M [00:01<00:02, 212MB/s]\u001b[A\n","model-00029-of-00046.safetensors:  45% 409M/910M [00:01<00:02, 205MB/s]\u001b[A\n","model-00029-of-00046.safetensors:  47% 430M/910M [00:02<00:02, 199MB/s]\u001b[A\n","model-00029-of-00046.safetensors:  51% 461M/910M [00:02<00:02, 216MB/s]\u001b[A\n","model-00029-of-00046.safetensors:  54% 493M/910M [00:02<00:01, 232MB/s]\u001b[A\n","model-00029-of-00046.safetensors:  58% 524M/910M [00:02<00:01, 225MB/s]\u001b[A\n","model-00029-of-00046.safetensors:  61% 556M/910M [00:02<00:01, 233MB/s]\u001b[A\n","model-00029-of-00046.safetensors:  65% 587M/910M [00:02<00:01, 232MB/s]\u001b[A\n","model-00029-of-00046.safetensors:  68% 619M/910M [00:02<00:01, 200MB/s]\u001b[A\n","model-00029-of-00046.safetensors:  71% 650M/910M [00:03<00:01, 204MB/s]\u001b[A\n","model-00029-of-00046.safetensors:  75% 682M/910M [00:03<00:01, 190MB/s]\u001b[A\n","model-00029-of-00046.safetensors:  77% 703M/910M [00:03<00:01, 180MB/s]\u001b[A\n","model-00029-of-00046.safetensors:  79% 724M/910M [00:03<00:01, 179MB/s]\u001b[A\n","model-00029-of-00046.safetensors:  82% 744M/910M [00:03<00:00, 169MB/s]\u001b[A\n","model-00029-of-00046.safetensors:  84% 765M/910M [00:07<00:07, 20.6MB/s]\u001b[A\n","model-00029-of-00046.safetensors:  86% 786M/910M [00:07<00:04, 27.1MB/s]\u001b[A\n","model-00029-of-00046.safetensors:  89% 807M/910M [00:07<00:02, 35.7MB/s]\u001b[A\n","model-00029-of-00046.safetensors:  92% 839M/910M [00:07<00:01, 52.8MB/s]\u001b[A\n","model-00029-of-00046.safetensors:  94% 860M/910M [00:07<00:00, 65.7MB/s]\u001b[A\n","model-00029-of-00046.safetensors:  97% 881M/910M [00:07<00:00, 79.5MB/s]\u001b[A\n","model-00029-of-00046.safetensors: 100% 910M/910M [00:07<00:00, 116MB/s]\n","Downloading shards:  63% 29/46 [04:20<02:47,  9.87s/it]\n","model-00030-of-00046.safetensors:   0% 0.00/910M [00:00<?, ?B/s]\u001b[A\n","model-00030-of-00046.safetensors:   1% 10.5M/910M [00:00<00:13, 65.6MB/s]\u001b[A\n","model-00030-of-00046.safetensors:   3% 31.5M/910M [00:00<00:07, 121MB/s] \u001b[A\n","model-00030-of-00046.safetensors:   6% 52.4M/910M [00:00<00:06, 142MB/s]\u001b[A\n","model-00030-of-00046.safetensors:   8% 73.4M/910M [00:00<00:08, 95.3MB/s]\u001b[A\n","model-00030-of-00046.safetensors:  12% 105M/910M [00:00<00:05, 135MB/s]  \u001b[A\n","model-00030-of-00046.safetensors:  14% 126M/910M [00:00<00:05, 151MB/s]\u001b[A\n","model-00030-of-00046.safetensors:  16% 147M/910M [00:01<00:04, 153MB/s]\u001b[A\n","model-00030-of-00046.safetensors:  18% 168M/910M [00:01<00:04, 164MB/s]\u001b[A\n","model-00030-of-00046.safetensors:  22% 199M/910M [00:01<00:03, 183MB/s]\u001b[A\n","model-00030-of-00046.safetensors:  24% 220M/910M [00:02<00:11, 59.5MB/s]\u001b[A\n","model-00030-of-00046.safetensors:  28% 252M/910M [00:02<00:07, 82.7MB/s]\u001b[A\n","model-00030-of-00046.safetensors:  31% 283M/910M [00:02<00:05, 106MB/s] \u001b[A\n","model-00030-of-00046.safetensors:  33% 304M/910M [00:02<00:05, 116MB/s]\u001b[A\n","model-00030-of-00046.safetensors:  36% 325M/910M [00:02<00:05, 113MB/s]\u001b[A\n","model-00030-of-00046.safetensors:  38% 346M/910M [00:03<00:05, 104MB/s]\u001b[A\n","model-00030-of-00046.safetensors:  40% 367M/910M [00:03<00:05, 99.3MB/s]\u001b[A\n","model-00030-of-00046.safetensors:  43% 388M/910M [00:03<00:05, 97.5MB/s]\u001b[A\n","model-00030-of-00046.safetensors:  45% 409M/910M [00:03<00:05, 96.6MB/s]\u001b[A\n","model-00030-of-00046.safetensors:  47% 430M/910M [00:04<00:04, 97.9MB/s]\u001b[A\n","model-00030-of-00046.safetensors:  50% 451M/910M [00:04<00:04, 99.4MB/s]\u001b[A\n","model-00030-of-00046.safetensors:  52% 472M/910M [00:04<00:04, 103MB/s] \u001b[A\n","model-00030-of-00046.safetensors:  54% 493M/910M [00:04<00:03, 105MB/s]\u001b[A\n","model-00030-of-00046.safetensors:  56% 514M/910M [00:04<00:03, 106MB/s]\u001b[A\n","model-00030-of-00046.safetensors:  59% 535M/910M [00:04<00:03, 109MB/s]\u001b[A\n","model-00030-of-00046.safetensors:  61% 556M/910M [00:05<00:03, 112MB/s]\u001b[A\n","model-00030-of-00046.safetensors:  63% 577M/910M [00:05<00:03, 109MB/s]\u001b[A\n","model-00030-of-00046.safetensors:  66% 598M/910M [00:05<00:02, 117MB/s]\u001b[A\n","model-00030-of-00046.safetensors:  68% 619M/910M [00:05<00:02, 101MB/s]\u001b[A\n","model-00030-of-00046.safetensors:  70% 640M/910M [00:06<00:03, 89.1MB/s]\u001b[A\n","model-00030-of-00046.safetensors:  71% 650M/910M [00:06<00:03, 85.0MB/s]\u001b[A\n","model-00030-of-00046.safetensors:  73% 661M/910M [00:06<00:03, 82.3MB/s]\u001b[A\n","model-00030-of-00046.safetensors:  74% 671M/910M [00:06<00:02, 79.9MB/s]\u001b[A\n","model-00030-of-00046.safetensors:  75% 682M/910M [00:06<00:02, 79.9MB/s]\u001b[A\n","model-00030-of-00046.safetensors:  76% 692M/910M [00:06<00:02, 79.9MB/s]\u001b[A\n","model-00030-of-00046.safetensors:  77% 703M/910M [00:06<00:02, 80.9MB/s]\u001b[A\n","model-00030-of-00046.safetensors:  78% 713M/910M [00:07<00:02, 81.3MB/s]\u001b[A\n","model-00030-of-00046.safetensors:  79% 724M/910M [00:07<00:02, 84.8MB/s]\u001b[A\n","model-00030-of-00046.safetensors:  81% 734M/910M [00:07<00:02, 85.2MB/s]\u001b[A\n","model-00030-of-00046.safetensors:  82% 744M/910M [00:07<00:01, 86.5MB/s]\u001b[A\n","model-00030-of-00046.safetensors:  83% 755M/910M [00:07<00:01, 86.2MB/s]\u001b[A\n","model-00030-of-00046.safetensors:  84% 765M/910M [00:07<00:01, 89.9MB/s]\u001b[A\n","model-00030-of-00046.safetensors:  85% 776M/910M [00:07<00:01, 91.7MB/s]\u001b[A\n","model-00030-of-00046.safetensors:  86% 786M/910M [00:07<00:01, 94.9MB/s]\u001b[A\n","model-00030-of-00046.safetensors:  88% 797M/910M [00:07<00:01, 94.7MB/s]\u001b[A\n","model-00030-of-00046.safetensors:  89% 807M/910M [00:08<00:01, 97.3MB/s]\u001b[A\n","model-00030-of-00046.safetensors:  90% 818M/910M [00:08<00:00, 96.8MB/s]\u001b[A\n","model-00030-of-00046.safetensors:  91% 828M/910M [00:08<00:00, 91.1MB/s]\u001b[A\n","model-00030-of-00046.safetensors:  92% 839M/910M [00:08<00:00, 93.1MB/s]\u001b[A\n","model-00030-of-00046.safetensors:  94% 860M/910M [00:08<00:00, 97.8MB/s]\u001b[A\n","model-00030-of-00046.safetensors:  97% 881M/910M [00:08<00:00, 105MB/s] \u001b[A\n","model-00030-of-00046.safetensors: 100% 910M/910M [00:09<00:00, 100MB/s]\n","Downloading shards:  65% 30/46 [04:29<02:34,  9.67s/it]\n","model-00031-of-00046.safetensors:   0% 0.00/910M [00:00<?, ?B/s]\u001b[A\n","model-00031-of-00046.safetensors:   1% 10.5M/910M [00:00<00:13, 64.3MB/s]\u001b[A\n","model-00031-of-00046.safetensors:   3% 31.5M/910M [00:00<00:07, 116MB/s] \u001b[A\n","model-00031-of-00046.safetensors:   7% 62.9M/910M [00:00<00:05, 165MB/s]\u001b[A\n","model-00031-of-00046.safetensors:  10% 94.4M/910M [00:00<00:04, 179MB/s]\u001b[A\n","model-00031-of-00046.safetensors:  13% 115M/910M [00:00<00:05, 157MB/s] \u001b[A\n","model-00031-of-00046.safetensors:  15% 136M/910M [00:00<00:04, 158MB/s]\u001b[A\n","model-00031-of-00046.safetensors:  17% 157M/910M [00:01<00:04, 164MB/s]\u001b[A\n","model-00031-of-00046.safetensors:  20% 178M/910M [00:01<00:04, 168MB/s]\u001b[A\n","model-00031-of-00046.safetensors:  23% 210M/910M [00:01<00:03, 182MB/s]\u001b[A\n","model-00031-of-00046.safetensors:  25% 231M/910M [00:01<00:03, 185MB/s]\u001b[A\n","model-00031-of-00046.safetensors:  29% 262M/910M [00:01<00:03, 204MB/s]\u001b[A\n","model-00031-of-00046.safetensors:  32% 294M/910M [00:01<00:03, 194MB/s]\u001b[A\n","model-00031-of-00046.safetensors:  35% 315M/910M [00:01<00:03, 180MB/s]\u001b[A\n","model-00031-of-00046.safetensors:  37% 336M/910M [00:01<00:03, 173MB/s]\u001b[A\n","model-00031-of-00046.safetensors:  39% 357M/910M [00:02<00:03, 170MB/s]\u001b[A\n","model-00031-of-00046.safetensors:  43% 388M/910M [00:02<00:02, 190MB/s]\u001b[A\n","model-00031-of-00046.safetensors:  45% 409M/910M [00:02<00:02, 189MB/s]\u001b[A\n","model-00031-of-00046.safetensors:  48% 440M/910M [00:02<00:02, 190MB/s]\u001b[A\n","model-00031-of-00046.safetensors:  51% 461M/910M [00:02<00:02, 172MB/s]\u001b[A\n","model-00031-of-00046.safetensors:  53% 482M/910M [00:02<00:02, 171MB/s]\u001b[A\n","model-00031-of-00046.safetensors:  55% 503M/910M [00:02<00:02, 175MB/s]\u001b[A\n","model-00031-of-00046.safetensors:  59% 535M/910M [00:03<00:01, 193MB/s]\u001b[A\n","model-00031-of-00046.safetensors:  61% 556M/910M [00:03<00:02, 170MB/s]\u001b[A\n","model-00031-of-00046.safetensors:  65% 587M/910M [00:03<00:01, 188MB/s]\u001b[A\n","model-00031-of-00046.safetensors:  67% 608M/910M [00:03<00:01, 190MB/s]\u001b[A\n","model-00031-of-00046.safetensors:  69% 629M/910M [00:03<00:02, 130MB/s]\u001b[A\n","model-00031-of-00046.safetensors:  73% 661M/910M [00:03<00:01, 158MB/s]\u001b[A\n","model-00031-of-00046.safetensors:  76% 692M/910M [00:03<00:01, 185MB/s]\u001b[A\n","model-00031-of-00046.safetensors:  79% 724M/910M [00:04<00:00, 202MB/s]\u001b[A\n","model-00031-of-00046.safetensors:  83% 755M/910M [00:04<00:00, 210MB/s]\u001b[A\n","model-00031-of-00046.safetensors:  86% 786M/910M [00:04<00:00, 218MB/s]\u001b[A\n","model-00031-of-00046.safetensors:  90% 818M/910M [00:04<00:00, 217MB/s]\u001b[A\n","model-00031-of-00046.safetensors:  93% 849M/910M [00:04<00:00, 214MB/s]\u001b[A\n","model-00031-of-00046.safetensors:  97% 881M/910M [00:04<00:00, 214MB/s]\u001b[A\n","model-00031-of-00046.safetensors: 100% 910M/910M [00:04<00:00, 184MB/s]\n","Downloading shards:  67% 31/46 [04:34<02:04,  8.30s/it]\n","model-00032-of-00046.safetensors:   0% 0.00/910M [00:00<?, ?B/s]\u001b[A\n","model-00032-of-00046.safetensors:   1% 10.5M/910M [00:00<00:08, 100MB/s]\u001b[A\n","model-00032-of-00046.safetensors:   5% 41.9M/910M [00:00<00:04, 180MB/s]\u001b[A\n","model-00032-of-00046.safetensors:   8% 73.4M/910M [00:00<00:04, 203MB/s]\u001b[A\n","model-00032-of-00046.safetensors:  10% 94.4M/910M [00:00<00:04, 180MB/s]\u001b[A\n","model-00032-of-00046.safetensors:  13% 115M/910M [00:00<00:04, 183MB/s] \u001b[A\n","model-00032-of-00046.safetensors:  15% 136M/910M [00:00<00:04, 181MB/s]\u001b[A\n","model-00032-of-00046.safetensors:  17% 157M/910M [00:00<00:03, 189MB/s]\u001b[A\n","model-00032-of-00046.safetensors:  21% 189M/910M [00:01<00:03, 199MB/s]\u001b[A\n","model-00032-of-00046.safetensors:  24% 220M/910M [00:01<00:03, 216MB/s]\u001b[A\n","model-00032-of-00046.safetensors:  28% 252M/910M [00:01<00:02, 225MB/s]\u001b[A\n","model-00032-of-00046.safetensors:  31% 283M/910M [00:01<00:02, 225MB/s]\u001b[A\n","model-00032-of-00046.safetensors:  35% 315M/910M [00:01<00:02, 230MB/s]\u001b[A\n","model-00032-of-00046.safetensors:  38% 346M/910M [00:01<00:02, 236MB/s]\u001b[A\n","model-00032-of-00046.safetensors:  41% 377M/910M [00:01<00:02, 249MB/s]\u001b[A\n","model-00032-of-00046.safetensors:  45% 409M/910M [00:01<00:01, 263MB/s]\u001b[A\n","model-00032-of-00046.safetensors:  48% 440M/910M [00:01<00:01, 258MB/s]\u001b[A\n","model-00032-of-00046.safetensors:  52% 472M/910M [00:02<00:01, 262MB/s]\u001b[A\n","model-00032-of-00046.safetensors:  55% 503M/910M [00:02<00:01, 273MB/s]\u001b[A\n","model-00032-of-00046.safetensors:  59% 535M/910M [00:02<00:01, 271MB/s]\u001b[A\n","model-00032-of-00046.safetensors:  62% 566M/910M [00:02<00:01, 245MB/s]\u001b[A\n","model-00032-of-00046.safetensors:  66% 598M/910M [00:02<00:01, 211MB/s]\u001b[A\n","model-00032-of-00046.safetensors:  69% 629M/910M [00:02<00:01, 212MB/s]\u001b[A\n","model-00032-of-00046.safetensors:  73% 661M/910M [00:02<00:01, 227MB/s]\u001b[A\n","model-00032-of-00046.safetensors:  76% 692M/910M [00:03<00:01, 187MB/s]\u001b[A\n","model-00032-of-00046.safetensors:  79% 724M/910M [00:03<00:00, 204MB/s]\u001b[A\n","model-00032-of-00046.safetensors:  83% 755M/910M [00:03<00:00, 223MB/s]\u001b[A\n","model-00032-of-00046.safetensors:  86% 786M/910M [00:03<00:00, 213MB/s]\u001b[A\n","model-00032-of-00046.safetensors:  90% 818M/910M [00:03<00:00, 208MB/s]\u001b[A\n","model-00032-of-00046.safetensors:  93% 849M/910M [00:03<00:00, 215MB/s]\u001b[A\n","model-00032-of-00046.safetensors:  97% 881M/910M [00:04<00:00, 221MB/s]\u001b[A\n","model-00032-of-00046.safetensors: 100% 910M/910M [00:04<00:00, 220MB/s]\n","Downloading shards:  70% 32/46 [04:38<01:39,  7.09s/it]\n","model-00033-of-00046.safetensors:   0% 0.00/910M [00:00<?, ?B/s]\u001b[A\n","model-00033-of-00046.safetensors:   2% 21.0M/910M [00:00<00:04, 194MB/s]\u001b[A\n","model-00033-of-00046.safetensors:   6% 52.4M/910M [00:00<00:03, 252MB/s]\u001b[A\n","model-00033-of-00046.safetensors:   9% 83.9M/910M [00:00<00:03, 247MB/s]\u001b[A\n","model-00033-of-00046.safetensors:  13% 115M/910M [00:00<00:03, 231MB/s] \u001b[A\n","model-00033-of-00046.safetensors:  16% 147M/910M [00:00<00:03, 224MB/s]\u001b[A\n","model-00033-of-00046.safetensors:  20% 178M/910M [00:00<00:03, 235MB/s]\u001b[A\n","model-00033-of-00046.safetensors:  23% 210M/910M [00:00<00:02, 254MB/s]\u001b[A\n","model-00033-of-00046.safetensors:  26% 241M/910M [00:00<00:02, 262MB/s]\u001b[A\n","model-00033-of-00046.safetensors:  30% 273M/910M [00:01<00:02, 237MB/s]\u001b[A\n","model-00033-of-00046.safetensors:  33% 304M/910M [00:01<00:02, 224MB/s]\u001b[A\n","model-00033-of-00046.safetensors:  37% 336M/910M [00:01<00:02, 196MB/s]\u001b[A\n","model-00033-of-00046.safetensors:  40% 367M/910M [00:01<00:02, 213MB/s]\u001b[A\n","model-00033-of-00046.safetensors:  44% 398M/910M [00:01<00:02, 209MB/s]\u001b[A\n","model-00033-of-00046.safetensors:  47% 430M/910M [00:01<00:02, 229MB/s]\u001b[A\n","model-00033-of-00046.safetensors:  51% 461M/910M [00:02<00:01, 233MB/s]\u001b[A\n","model-00033-of-00046.safetensors:  54% 493M/910M [00:02<00:01, 216MB/s]\u001b[A\n","model-00033-of-00046.safetensors:  58% 524M/910M [00:02<00:02, 190MB/s]\u001b[A\n","model-00033-of-00046.safetensors:  61% 556M/910M [00:02<00:01, 204MB/s]\u001b[A\n","model-00033-of-00046.safetensors:  65% 587M/910M [00:02<00:01, 214MB/s]\u001b[A\n","model-00033-of-00046.safetensors:  68% 619M/910M [00:02<00:01, 202MB/s]\u001b[A\n","model-00033-of-00046.safetensors:  71% 650M/910M [00:02<00:01, 211MB/s]\u001b[A\n","model-00033-of-00046.safetensors:  75% 682M/910M [00:05<00:05, 41.0MB/s]\u001b[A\n","model-00033-of-00046.safetensors:  78% 713M/910M [00:05<00:03, 54.6MB/s]\u001b[A\n","model-00033-of-00046.safetensors:  82% 744M/910M [00:05<00:02, 70.8MB/s]\u001b[A\n","model-00033-of-00046.safetensors:  84% 765M/910M [00:05<00:01, 81.7MB/s]\u001b[A\n","model-00033-of-00046.safetensors:  86% 786M/910M [00:05<00:01, 89.2MB/s]\u001b[A\n","model-00033-of-00046.safetensors:  89% 807M/910M [00:05<00:01, 102MB/s] \u001b[A\n","model-00033-of-00046.safetensors:  91% 828M/910M [00:05<00:00, 113MB/s]\u001b[A\n","model-00033-of-00046.safetensors:  93% 849M/910M [00:06<00:00, 124MB/s]\u001b[A\n","model-00033-of-00046.safetensors:  96% 870M/910M [00:06<00:00, 139MB/s]\u001b[A\n","model-00033-of-00046.safetensors: 100% 910M/910M [00:06<00:00, 141MB/s]\n","Downloading shards:  72% 33/46 [04:45<01:30,  6.94s/it]\n","model-00034-of-00046.safetensors:   0% 0.00/910M [00:00<?, ?B/s]\u001b[A\n","model-00034-of-00046.safetensors:   1% 10.5M/910M [00:00<00:11, 77.2MB/s]\u001b[A\n","model-00034-of-00046.safetensors:   3% 31.5M/910M [00:00<00:06, 131MB/s] \u001b[A\n","model-00034-of-00046.safetensors:   6% 52.4M/910M [00:00<00:05, 153MB/s]\u001b[A\n","model-00034-of-00046.safetensors:   8% 73.4M/910M [00:00<00:04, 171MB/s]\u001b[A\n","model-00034-of-00046.safetensors:  12% 105M/910M [00:02<00:24, 32.7MB/s]\u001b[A\n","model-00034-of-00046.safetensors:  15% 136M/910M [00:02<00:15, 50.4MB/s]\u001b[A\n","model-00034-of-00046.safetensors:  18% 168M/910M [00:02<00:10, 70.5MB/s]\u001b[A\n","model-00034-of-00046.safetensors:  22% 199M/910M [00:02<00:07, 93.9MB/s]\u001b[A\n","model-00034-of-00046.safetensors:  25% 231M/910M [00:02<00:05, 119MB/s] \u001b[A\n","model-00034-of-00046.safetensors:  29% 262M/910M [00:02<00:04, 133MB/s]\u001b[A\n","model-00034-of-00046.safetensors:  32% 294M/910M [00:03<00:04, 153MB/s]\u001b[A\n","model-00034-of-00046.safetensors:  36% 325M/910M [00:03<00:03, 172MB/s]\u001b[A\n","model-00034-of-00046.safetensors:  39% 357M/910M [00:03<00:02, 191MB/s]\u001b[A\n","model-00034-of-00046.safetensors:  43% 388M/910M [00:03<00:02, 190MB/s]\u001b[A\n","model-00034-of-00046.safetensors:  46% 419M/910M [00:03<00:02, 176MB/s]\u001b[A\n","model-00034-of-00046.safetensors:  48% 440M/910M [00:03<00:02, 173MB/s]\u001b[A\n","model-00034-of-00046.safetensors:  52% 472M/910M [00:04<00:02, 183MB/s]\u001b[A\n","model-00034-of-00046.safetensors:  55% 503M/910M [00:04<00:02, 185MB/s]\u001b[A\n","model-00034-of-00046.safetensors:  58% 524M/910M [00:04<00:02, 169MB/s]\u001b[A\n","model-00034-of-00046.safetensors:  60% 545M/910M [00:04<00:02, 176MB/s]\u001b[A\n","model-00034-of-00046.safetensors:  63% 577M/910M [00:04<00:01, 192MB/s]\u001b[A\n","model-00034-of-00046.safetensors:  66% 598M/910M [00:04<00:01, 184MB/s]\u001b[A\n","model-00034-of-00046.safetensors:  68% 619M/910M [00:04<00:01, 158MB/s]\u001b[A\n","model-00034-of-00046.safetensors:  71% 650M/910M [00:05<00:01, 183MB/s]\u001b[A\n","model-00034-of-00046.safetensors:  75% 682M/910M [00:05<00:01, 197MB/s]\u001b[A\n","model-00034-of-00046.safetensors:  78% 713M/910M [00:05<00:01, 197MB/s]\u001b[A\n","model-00034-of-00046.safetensors:  82% 744M/910M [00:05<00:00, 211MB/s]\u001b[A\n","model-00034-of-00046.safetensors:  85% 776M/910M [00:05<00:00, 220MB/s]\u001b[A\n","model-00034-of-00046.safetensors:  89% 807M/910M [00:05<00:00, 207MB/s]\u001b[A\n","model-00034-of-00046.safetensors:  92% 839M/910M [00:05<00:00, 203MB/s]\u001b[A\n","model-00034-of-00046.safetensors:  94% 860M/910M [00:06<00:00, 202MB/s]\u001b[A\n","model-00034-of-00046.safetensors:  97% 881M/910M [00:06<00:00, 199MB/s]\u001b[A\n","model-00034-of-00046.safetensors: 100% 910M/910M [00:06<00:00, 145MB/s]\n","Downloading shards:  74% 34/46 [04:51<01:21,  6.77s/it]\n","model-00035-of-00046.safetensors:   0% 0.00/910M [00:00<?, ?B/s]\u001b[A\n","model-00035-of-00046.safetensors:   1% 10.5M/910M [00:00<00:11, 75.3MB/s]\u001b[A\n","model-00035-of-00046.safetensors:   3% 31.5M/910M [00:00<00:06, 134MB/s] \u001b[A\n","model-00035-of-00046.safetensors:   6% 52.4M/910M [00:00<00:05, 159MB/s]\u001b[A\n","model-00035-of-00046.safetensors:   8% 73.4M/910M [00:01<00:27, 30.6MB/s]\u001b[A\n","model-00035-of-00046.safetensors:  12% 105M/910M [00:01<00:15, 52.9MB/s] \u001b[A\n","model-00035-of-00046.safetensors:  15% 136M/910M [00:02<00:10, 77.0MB/s]\u001b[A\n","model-00035-of-00046.safetensors:  18% 168M/910M [00:02<00:07, 104MB/s] \u001b[A\n","model-00035-of-00046.safetensors:  22% 199M/910M [00:02<00:05, 133MB/s]\u001b[A\n","model-00035-of-00046.safetensors:  25% 231M/910M [00:02<00:04, 154MB/s]\u001b[A\n","model-00035-of-00046.safetensors:  29% 262M/910M [00:02<00:03, 179MB/s]\u001b[A\n","model-00035-of-00046.safetensors:  32% 294M/910M [00:02<00:03, 197MB/s]\u001b[A\n","model-00035-of-00046.safetensors:  36% 325M/910M [00:02<00:02, 214MB/s]\u001b[A\n","model-00035-of-00046.safetensors:  39% 357M/910M [00:02<00:02, 223MB/s]\u001b[A\n","model-00035-of-00046.safetensors:  43% 388M/910M [00:03<00:02, 208MB/s]\u001b[A\n","model-00035-of-00046.safetensors:  46% 419M/910M [00:03<00:02, 213MB/s]\u001b[A\n","model-00035-of-00046.safetensors:  50% 451M/910M [00:03<00:02, 206MB/s]\u001b[A\n","model-00035-of-00046.safetensors:  53% 482M/910M [00:03<00:02, 211MB/s]\u001b[A\n","model-00035-of-00046.safetensors:  56% 514M/910M [00:03<00:02, 197MB/s]\u001b[A\n","model-00035-of-00046.safetensors:  59% 535M/910M [00:03<00:02, 181MB/s]\u001b[A\n","model-00035-of-00046.safetensors:  61% 556M/910M [00:03<00:02, 175MB/s]\u001b[A\n","model-00035-of-00046.safetensors:  63% 577M/910M [00:04<00:01, 176MB/s]\u001b[A\n","model-00035-of-00046.safetensors:  66% 598M/910M [00:04<00:01, 177MB/s]\u001b[A\n","model-00035-of-00046.safetensors:  68% 619M/910M [00:04<00:03, 96.6MB/s]\u001b[A\n","model-00035-of-00046.safetensors:  70% 640M/910M [00:08<00:16, 16.8MB/s]\u001b[A\n","model-00035-of-00046.safetensors:  73% 661M/910M [00:08<00:10, 22.8MB/s]\u001b[A\n","model-00035-of-00046.safetensors:  75% 682M/910M [00:08<00:07, 30.3MB/s]\u001b[A\n","model-00035-of-00046.safetensors:  78% 713M/910M [00:08<00:04, 45.5MB/s]\u001b[A\n","model-00035-of-00046.safetensors:  82% 744M/910M [00:09<00:02, 63.2MB/s]\u001b[A\n","model-00035-of-00046.safetensors:  85% 776M/910M [00:09<00:01, 81.7MB/s]\u001b[A\n","model-00035-of-00046.safetensors:  89% 807M/910M [00:09<00:00, 104MB/s] \u001b[A\n","model-00035-of-00046.safetensors:  92% 839M/910M [00:09<00:00, 119MB/s]\u001b[A\n","model-00035-of-00046.safetensors:  94% 860M/910M [00:09<00:00, 102MB/s]\u001b[A\n","model-00035-of-00046.safetensors: 100% 910M/910M [00:10<00:00, 89.2MB/s]\n","Downloading shards:  76% 35/46 [05:01<01:26,  7.84s/it]\n","model-00036-of-00046.safetensors:   0% 0.00/910M [00:00<?, ?B/s]\u001b[A\n","model-00036-of-00046.safetensors:   2% 21.0M/910M [00:00<00:06, 144MB/s]\u001b[A\n","model-00036-of-00046.safetensors:   5% 41.9M/910M [00:00<00:05, 151MB/s]\u001b[A\n","model-00036-of-00046.safetensors:   8% 73.4M/910M [00:00<00:04, 184MB/s]\u001b[A\n","model-00036-of-00046.safetensors:  10% 94.4M/910M [00:00<00:04, 172MB/s]\u001b[A\n","model-00036-of-00046.safetensors:  13% 115M/910M [00:00<00:04, 175MB/s] \u001b[A\n","model-00036-of-00046.safetensors:  15% 136M/910M [00:00<00:04, 169MB/s]\u001b[A\n","model-00036-of-00046.safetensors:  17% 157M/910M [00:01<00:11, 67.8MB/s]\u001b[A\n","model-00036-of-00046.safetensors:  21% 189M/910M [00:01<00:07, 95.7MB/s]\u001b[A\n","model-00036-of-00046.safetensors:  24% 220M/910M [00:01<00:05, 121MB/s] \u001b[A\n","model-00036-of-00046.safetensors:  28% 252M/910M [00:01<00:04, 144MB/s]\u001b[A\n","model-00036-of-00046.safetensors:  31% 283M/910M [00:02<00:03, 168MB/s]\u001b[A\n","model-00036-of-00046.safetensors:  35% 315M/910M [00:02<00:03, 176MB/s]\u001b[A\n","model-00036-of-00046.safetensors:  37% 336M/910M [00:02<00:03, 174MB/s]\u001b[A\n","model-00036-of-00046.safetensors:  39% 357M/910M [00:02<00:03, 177MB/s]\u001b[A\n","model-00036-of-00046.safetensors:  41% 377M/910M [00:02<00:03, 176MB/s]\u001b[A\n","model-00036-of-00046.safetensors:  44% 398M/910M [00:02<00:02, 183MB/s]\u001b[A\n","model-00036-of-00046.safetensors:  46% 419M/910M [00:02<00:02, 184MB/s]\u001b[A\n","model-00036-of-00046.safetensors:  48% 440M/910M [00:02<00:02, 188MB/s]\u001b[A\n","model-00036-of-00046.safetensors:  51% 461M/910M [00:03<00:02, 181MB/s]\u001b[A\n","model-00036-of-00046.safetensors:  53% 482M/910M [00:03<00:02, 185MB/s]\u001b[A\n","model-00036-of-00046.safetensors:  56% 514M/910M [00:03<00:01, 203MB/s]\u001b[A\n","model-00036-of-00046.safetensors:  60% 545M/910M [00:03<00:01, 202MB/s]\u001b[A\n","model-00036-of-00046.safetensors:  63% 577M/910M [00:03<00:01, 201MB/s]\u001b[A\n","model-00036-of-00046.safetensors:  66% 598M/910M [00:03<00:01, 189MB/s]\u001b[A\n","model-00036-of-00046.safetensors:  69% 629M/910M [00:03<00:01, 192MB/s]\u001b[A\n","model-00036-of-00046.safetensors:  71% 650M/910M [00:03<00:01, 183MB/s]\u001b[A\n","model-00036-of-00046.safetensors:  74% 671M/910M [00:04<00:01, 175MB/s]\u001b[A\n","model-00036-of-00046.safetensors:  77% 703M/910M [00:04<00:01, 190MB/s]\u001b[A\n","model-00036-of-00046.safetensors:  81% 734M/910M [00:04<00:00, 206MB/s]\u001b[A\n","model-00036-of-00046.safetensors:  84% 765M/910M [00:04<00:00, 229MB/s]\u001b[A\n","model-00036-of-00046.safetensors:  88% 797M/910M [00:04<00:00, 225MB/s]\u001b[A\n","model-00036-of-00046.safetensors:  91% 828M/910M [00:04<00:00, 213MB/s]\u001b[A\n","model-00036-of-00046.safetensors:  94% 860M/910M [00:04<00:00, 203MB/s]\u001b[A\n","model-00036-of-00046.safetensors: 100% 910M/910M [00:05<00:00, 175MB/s]\n","Downloading shards:  78% 36/46 [05:07<01:10,  7.09s/it]\n","model-00037-of-00046.safetensors:   0% 0.00/910M [00:00<?, ?B/s]\u001b[A\n","model-00037-of-00046.safetensors:   2% 21.0M/910M [00:00<00:06, 140MB/s]\u001b[A\n","model-00037-of-00046.safetensors:   5% 41.9M/910M [00:00<00:06, 132MB/s]\u001b[A\n","model-00037-of-00046.safetensors:   8% 73.4M/910M [00:00<00:05, 161MB/s]\u001b[A\n","model-00037-of-00046.safetensors:  10% 94.4M/910M [00:00<00:05, 163MB/s]\u001b[A\n","model-00037-of-00046.safetensors:  13% 115M/910M [00:00<00:04, 168MB/s] \u001b[A\n","model-00037-of-00046.safetensors:  15% 136M/910M [00:00<00:04, 155MB/s]\u001b[A\n","model-00037-of-00046.safetensors:  17% 157M/910M [00:00<00:04, 163MB/s]\u001b[A\n","model-00037-of-00046.safetensors:  20% 178M/910M [00:03<00:25, 28.3MB/s]\u001b[A\n","model-00037-of-00046.safetensors:  23% 210M/910M [00:03<00:15, 44.5MB/s]\u001b[A\n","model-00037-of-00046.safetensors:  26% 241M/910M [00:03<00:10, 64.5MB/s]\u001b[A\n","model-00037-of-00046.safetensors:  30% 273M/910M [00:03<00:07, 83.8MB/s]\u001b[A\n","model-00037-of-00046.safetensors:  33% 304M/910M [00:03<00:05, 105MB/s] \u001b[A\n","model-00037-of-00046.safetensors:  37% 336M/910M [00:03<00:04, 128MB/s]\u001b[A\n","model-00037-of-00046.safetensors:  40% 367M/910M [00:03<00:03, 152MB/s]\u001b[A\n","model-00037-of-00046.safetensors:  44% 398M/910M [00:03<00:02, 171MB/s]\u001b[A\n","model-00037-of-00046.safetensors:  47% 430M/910M [00:04<00:02, 176MB/s]\u001b[A\n","model-00037-of-00046.safetensors:  51% 461M/910M [00:04<00:02, 193MB/s]\u001b[A\n","model-00037-of-00046.safetensors:  54% 493M/910M [00:04<00:02, 207MB/s]\u001b[A\n","model-00037-of-00046.safetensors:  58% 524M/910M [00:04<00:01, 206MB/s]\u001b[A\n","model-00037-of-00046.safetensors:  61% 556M/910M [00:04<00:01, 209MB/s]\u001b[A\n","model-00037-of-00046.safetensors:  65% 587M/910M [00:04<00:01, 215MB/s]\u001b[A\n","model-00037-of-00046.safetensors:  68% 619M/910M [00:04<00:01, 224MB/s]\u001b[A\n","model-00037-of-00046.safetensors:  71% 650M/910M [00:05<00:01, 238MB/s]\u001b[A\n","model-00037-of-00046.safetensors:  75% 682M/910M [00:05<00:00, 249MB/s]\u001b[A\n","model-00037-of-00046.safetensors:  78% 713M/910M [00:05<00:00, 232MB/s]\u001b[A\n","model-00037-of-00046.safetensors:  82% 744M/910M [00:05<00:00, 236MB/s]\u001b[A\n","model-00037-of-00046.safetensors:  85% 776M/910M [00:05<00:00, 250MB/s]\u001b[A\n","model-00037-of-00046.safetensors:  89% 807M/910M [00:05<00:00, 245MB/s]\u001b[A\n","model-00037-of-00046.safetensors:  92% 839M/910M [00:05<00:00, 241MB/s]\u001b[A\n","model-00037-of-00046.safetensors:  96% 870M/910M [00:05<00:00, 241MB/s]\u001b[A\n","model-00037-of-00046.safetensors: 100% 910M/910M [00:06<00:00, 148MB/s]\n","Downloading shards:  80% 37/46 [05:13<01:01,  6.85s/it]\n","model-00038-of-00046.safetensors:   0% 0.00/910M [00:00<?, ?B/s]\u001b[A\n","model-00038-of-00046.safetensors:   2% 21.0M/910M [00:00<00:04, 194MB/s]\u001b[A\n","model-00038-of-00046.safetensors:   6% 52.4M/910M [00:00<00:03, 251MB/s]\u001b[A\n","model-00038-of-00046.safetensors:   9% 83.9M/910M [00:00<00:03, 265MB/s]\u001b[A\n","model-00038-of-00046.safetensors:  13% 115M/910M [00:00<00:02, 273MB/s] \u001b[A\n","model-00038-of-00046.safetensors:  16% 147M/910M [00:00<00:03, 234MB/s]\u001b[A\n","model-00038-of-00046.safetensors:  20% 178M/910M [00:00<00:03, 222MB/s]\u001b[A\n","model-00038-of-00046.safetensors:  23% 210M/910M [00:00<00:02, 237MB/s]\u001b[A\n","model-00038-of-00046.safetensors:  26% 241M/910M [00:00<00:02, 246MB/s]\u001b[A\n","model-00038-of-00046.safetensors:  30% 273M/910M [00:01<00:02, 238MB/s]\u001b[A\n","model-00038-of-00046.safetensors:  33% 304M/910M [00:01<00:02, 241MB/s]\u001b[A\n","model-00038-of-00046.safetensors:  37% 336M/910M [00:01<00:02, 224MB/s]\u001b[A\n","model-00038-of-00046.safetensors:  40% 367M/910M [00:01<00:02, 229MB/s]\u001b[A\n","model-00038-of-00046.safetensors:  44% 398M/910M [00:01<00:02, 235MB/s]\u001b[A\n","model-00038-of-00046.safetensors:  47% 430M/910M [00:01<00:02, 233MB/s]\u001b[A\n","model-00038-of-00046.safetensors:  51% 461M/910M [00:01<00:01, 233MB/s]\u001b[A\n","model-00038-of-00046.safetensors:  54% 493M/910M [00:02<00:02, 160MB/s]\u001b[A\n","model-00038-of-00046.safetensors:  58% 524M/910M [00:02<00:02, 179MB/s]\u001b[A\n","model-00038-of-00046.safetensors:  61% 556M/910M [00:02<00:01, 200MB/s]\u001b[A\n","model-00038-of-00046.safetensors:  65% 587M/910M [00:05<00:09, 35.1MB/s]\u001b[A\n","model-00038-of-00046.safetensors:  68% 619M/910M [00:05<00:06, 47.5MB/s]\u001b[A\n","model-00038-of-00046.safetensors:  71% 650M/910M [00:05<00:04, 62.7MB/s]\u001b[A\n","model-00038-of-00046.safetensors:  75% 682M/910M [00:05<00:02, 81.7MB/s]\u001b[A\n","model-00038-of-00046.safetensors:  78% 713M/910M [00:05<00:01, 103MB/s] \u001b[A\n","model-00038-of-00046.safetensors:  82% 744M/910M [00:05<00:01, 101MB/s]\u001b[A\n","model-00038-of-00046.safetensors:  84% 765M/910M [00:06<00:01, 105MB/s]\u001b[A\n","model-00038-of-00046.safetensors:  88% 797M/910M [00:06<00:00, 128MB/s]\u001b[A\n","model-00038-of-00046.safetensors:  91% 828M/910M [00:06<00:00, 153MB/s]\u001b[A\n","model-00038-of-00046.safetensors:  94% 860M/910M [00:06<00:00, 174MB/s]\u001b[A\n","model-00038-of-00046.safetensors: 100% 910M/910M [00:06<00:00, 135MB/s]\n","Downloading shards:  83% 38/46 [05:20<00:54,  6.86s/it]\n","model-00039-of-00046.safetensors:   0% 0.00/910M [00:00<?, ?B/s]\u001b[A\n","model-00039-of-00046.safetensors:   1% 10.5M/910M [00:00<00:11, 75.9MB/s]\u001b[A\n","model-00039-of-00046.safetensors:   3% 31.5M/910M [00:00<00:06, 131MB/s] \u001b[A\n","model-00039-of-00046.safetensors:   7% 62.9M/910M [00:00<00:04, 178MB/s]\u001b[A\n","model-00039-of-00046.safetensors:   9% 83.9M/910M [00:00<00:04, 166MB/s]\u001b[A\n","model-00039-of-00046.safetensors:  12% 105M/910M [00:00<00:04, 173MB/s] \u001b[A\n","model-00039-of-00046.safetensors:  14% 126M/910M [00:00<00:04, 177MB/s]\u001b[A\n","model-00039-of-00046.safetensors:  16% 147M/910M [00:00<00:04, 181MB/s]\u001b[A\n","model-00039-of-00046.safetensors:  18% 168M/910M [00:00<00:04, 184MB/s]\u001b[A\n","model-00039-of-00046.safetensors:  21% 189M/910M [00:04<00:37, 19.4MB/s]\u001b[A\n","model-00039-of-00046.safetensors:  23% 210M/910M [00:04<00:26, 26.0MB/s]\u001b[A\n","model-00039-of-00046.safetensors:  26% 241M/910M [00:04<00:16, 40.7MB/s]\u001b[A\n","model-00039-of-00046.safetensors:  30% 273M/910M [00:04<00:10, 59.0MB/s]\u001b[A\n","model-00039-of-00046.safetensors:  32% 294M/910M [00:04<00:08, 71.2MB/s]\u001b[A\n","model-00039-of-00046.safetensors:  35% 315M/910M [00:04<00:07, 84.7MB/s]\u001b[A\n","model-00039-of-00046.safetensors:  38% 346M/910M [00:04<00:05, 111MB/s] \u001b[A\n","model-00039-of-00046.safetensors:  40% 367M/910M [00:05<00:04, 125MB/s]\u001b[A\n","model-00039-of-00046.safetensors:  44% 398M/910M [00:05<00:03, 150MB/s]\u001b[A\n","model-00039-of-00046.safetensors:  47% 430M/910M [00:05<00:02, 174MB/s]\u001b[A\n","model-00039-of-00046.safetensors:  51% 461M/910M [00:05<00:02, 195MB/s]\u001b[A\n","model-00039-of-00046.safetensors:  54% 493M/910M [00:05<00:02, 204MB/s]\u001b[A\n","model-00039-of-00046.safetensors:  58% 524M/910M [00:05<00:01, 197MB/s]\u001b[A\n","model-00039-of-00046.safetensors:  61% 556M/910M [00:05<00:01, 220MB/s]\u001b[A\n","model-00039-of-00046.safetensors:  65% 587M/910M [00:06<00:01, 236MB/s]\u001b[A\n","model-00039-of-00046.safetensors:  68% 619M/910M [00:06<00:01, 217MB/s]\u001b[A\n","model-00039-of-00046.safetensors:  71% 650M/910M [00:06<00:01, 213MB/s]\u001b[A\n","model-00039-of-00046.safetensors:  75% 682M/910M [00:06<00:01, 221MB/s]\u001b[A\n","model-00039-of-00046.safetensors:  78% 713M/910M [00:06<00:00, 198MB/s]\u001b[A\n","model-00039-of-00046.safetensors:  81% 734M/910M [00:06<00:00, 188MB/s]\u001b[A\n","model-00039-of-00046.safetensors:  83% 755M/910M [00:06<00:00, 188MB/s]\u001b[A\n","model-00039-of-00046.safetensors:  85% 776M/910M [00:06<00:00, 191MB/s]\u001b[A\n","model-00039-of-00046.safetensors:  88% 797M/910M [00:07<00:00, 124MB/s]\u001b[A\n","model-00039-of-00046.safetensors:  90% 818M/910M [00:08<00:01, 67.1MB/s]\u001b[A\n","model-00039-of-00046.safetensors:  92% 839M/910M [00:08<00:00, 80.0MB/s]\u001b[A\n","model-00039-of-00046.safetensors:  94% 860M/910M [00:08<00:00, 92.6MB/s]\u001b[A\n","model-00039-of-00046.safetensors:  97% 881M/910M [00:08<00:00, 110MB/s] \u001b[A\n","model-00039-of-00046.safetensors: 100% 910M/910M [00:08<00:00, 106MB/s]\n","Downloading shards:  85% 39/46 [05:29<00:52,  7.43s/it]\n","model-00040-of-00046.safetensors:   0% 0.00/910M [00:00<?, ?B/s]\u001b[A\n","model-00040-of-00046.safetensors:   1% 10.5M/910M [00:00<00:14, 60.8MB/s]\u001b[A\n","model-00040-of-00046.safetensors:   3% 31.5M/910M [00:00<00:07, 118MB/s] \u001b[A\n","model-00040-of-00046.safetensors:   6% 52.4M/910M [00:00<00:06, 139MB/s]\u001b[A\n","model-00040-of-00046.safetensors:   9% 83.9M/910M [00:00<00:04, 167MB/s]\u001b[A\n","model-00040-of-00046.safetensors:  12% 105M/910M [00:00<00:04, 176MB/s] \u001b[A\n","model-00040-of-00046.safetensors:  14% 126M/910M [00:00<00:04, 166MB/s]\u001b[A\n","model-00040-of-00046.safetensors:  16% 147M/910M [00:00<00:04, 174MB/s]\u001b[A\n","model-00040-of-00046.safetensors:  18% 168M/910M [00:01<00:04, 177MB/s]\u001b[A\n","model-00040-of-00046.safetensors:  21% 189M/910M [00:01<00:04, 178MB/s]\u001b[A\n","model-00040-of-00046.safetensors:  23% 210M/910M [00:01<00:04, 169MB/s]\u001b[A\n","model-00040-of-00046.safetensors:  26% 241M/910M [00:01<00:03, 189MB/s]\u001b[A\n","model-00040-of-00046.safetensors:  30% 273M/910M [00:01<00:03, 203MB/s]\u001b[A\n","model-00040-of-00046.safetensors:  33% 304M/910M [00:01<00:02, 217MB/s]\u001b[A\n","model-00040-of-00046.safetensors:  37% 336M/910M [00:01<00:02, 227MB/s]\u001b[A\n","model-00040-of-00046.safetensors:  40% 367M/910M [00:01<00:02, 235MB/s]\u001b[A\n","model-00040-of-00046.safetensors:  44% 398M/910M [00:02<00:02, 218MB/s]\u001b[A\n","model-00040-of-00046.safetensors:  47% 430M/910M [00:02<00:02, 184MB/s]\u001b[A\n","model-00040-of-00046.safetensors:  50% 451M/910M [00:02<00:02, 184MB/s]\u001b[A\n","model-00040-of-00046.safetensors:  53% 482M/910M [00:02<00:02, 202MB/s]\u001b[A\n","model-00040-of-00046.safetensors:  56% 514M/910M [00:02<00:01, 215MB/s]\u001b[A\n","model-00040-of-00046.safetensors:  60% 545M/910M [00:02<00:01, 206MB/s]\u001b[A\n","model-00040-of-00046.safetensors:  63% 577M/910M [00:03<00:01, 209MB/s]\u001b[A\n","model-00040-of-00046.safetensors:  67% 608M/910M [00:03<00:02, 139MB/s]\u001b[A\n","model-00040-of-00046.safetensors:  69% 629M/910M [00:05<00:08, 32.4MB/s]\u001b[A\n","model-00040-of-00046.safetensors:  73% 661M/910M [00:05<00:05, 45.2MB/s]\u001b[A\n","model-00040-of-00046.safetensors:  76% 692M/910M [00:06<00:03, 61.3MB/s]\u001b[A\n","model-00040-of-00046.safetensors:  78% 713M/910M [00:06<00:02, 70.0MB/s]\u001b[A\n","model-00040-of-00046.safetensors:  81% 734M/910M [00:06<00:02, 81.6MB/s]\u001b[A\n","model-00040-of-00046.safetensors:  84% 765M/910M [00:06<00:01, 105MB/s] \u001b[A\n","model-00040-of-00046.safetensors:  88% 797M/910M [00:06<00:00, 125MB/s]\u001b[A\n","model-00040-of-00046.safetensors:  91% 828M/910M [00:06<00:00, 149MB/s]\u001b[A\n","model-00040-of-00046.safetensors:  93% 849M/910M [00:06<00:00, 154MB/s]\u001b[A\n","model-00040-of-00046.safetensors:  96% 870M/910M [00:06<00:00, 164MB/s]\u001b[A\n","model-00040-of-00046.safetensors: 100% 910M/910M [00:07<00:00, 128MB/s]\n","Downloading shards:  87% 40/46 [05:36<00:44,  7.38s/it]\n","model-00041-of-00046.safetensors:   0% 0.00/910M [00:00<?, ?B/s]\u001b[A\n","model-00041-of-00046.safetensors:   1% 10.5M/910M [00:00<00:14, 62.7MB/s]\u001b[A\n","model-00041-of-00046.safetensors:   3% 31.5M/910M [00:00<00:07, 120MB/s] \u001b[A\n","model-00041-of-00046.safetensors:   6% 52.4M/910M [00:00<00:06, 130MB/s]\u001b[A\n","model-00041-of-00046.safetensors:   9% 83.9M/910M [00:00<00:04, 170MB/s]\u001b[A\n","model-00041-of-00046.safetensors:  13% 115M/910M [00:00<00:04, 182MB/s] \u001b[A\n","model-00041-of-00046.safetensors:  15% 136M/910M [00:00<00:04, 183MB/s]\u001b[A\n","model-00041-of-00046.safetensors:  17% 157M/910M [00:00<00:04, 169MB/s]\u001b[A\n","model-00041-of-00046.safetensors:  21% 189M/910M [00:01<00:03, 193MB/s]\u001b[A\n","model-00041-of-00046.safetensors:  23% 210M/910M [00:01<00:10, 66.2MB/s]\u001b[A\n","model-00041-of-00046.safetensors:  26% 241M/910M [00:02<00:07, 89.9MB/s]\u001b[A\n","model-00041-of-00046.safetensors:  30% 273M/910M [00:02<00:05, 111MB/s] \u001b[A\n","model-00041-of-00046.safetensors:  32% 294M/910M [00:02<00:05, 121MB/s]\u001b[A\n","model-00041-of-00046.safetensors:  36% 325M/910M [00:02<00:04, 134MB/s]\u001b[A\n","model-00041-of-00046.safetensors:  39% 357M/910M [00:02<00:03, 160MB/s]\u001b[A\n","model-00041-of-00046.safetensors:  43% 388M/910M [00:02<00:02, 181MB/s]\u001b[A\n","model-00041-of-00046.safetensors:  46% 419M/910M [00:03<00:02, 175MB/s]\u001b[A\n","model-00041-of-00046.safetensors:  50% 451M/910M [00:03<00:02, 188MB/s]\u001b[A\n","model-00041-of-00046.safetensors:  53% 482M/910M [00:03<00:02, 205MB/s]\u001b[A\n","model-00041-of-00046.safetensors:  58% 524M/910M [00:03<00:01, 234MB/s]\u001b[A\n","model-00041-of-00046.safetensors:  62% 566M/910M [00:03<00:01, 258MB/s]\u001b[A\n","model-00041-of-00046.safetensors:  66% 598M/910M [00:04<00:02, 118MB/s]\u001b[A\n","model-00041-of-00046.safetensors:  68% 619M/910M [00:04<00:02, 125MB/s]\u001b[A\n","model-00041-of-00046.safetensors:  71% 650M/910M [00:04<00:01, 143MB/s]\u001b[A\n","model-00041-of-00046.safetensors:  74% 671M/910M [00:04<00:01, 149MB/s]\u001b[A\n","model-00041-of-00046.safetensors:  77% 703M/910M [00:04<00:01, 171MB/s]\u001b[A\n","model-00041-of-00046.safetensors:  81% 734M/910M [00:04<00:01, 163MB/s]\u001b[A\n","model-00041-of-00046.safetensors:  84% 765M/910M [00:05<00:00, 181MB/s]\u001b[A\n","model-00041-of-00046.safetensors:  88% 797M/910M [00:05<00:00, 189MB/s]\u001b[A\n","model-00041-of-00046.safetensors:  90% 818M/910M [00:05<00:00, 190MB/s]\u001b[A\n","model-00041-of-00046.safetensors:  93% 849M/910M [00:05<00:00, 193MB/s]\u001b[A\n","model-00041-of-00046.safetensors:  97% 881M/910M [00:05<00:00, 203MB/s]\u001b[A\n","model-00041-of-00046.safetensors: 100% 910M/910M [00:05<00:00, 157MB/s]\n","Downloading shards:  89% 41/46 [05:42<00:34,  6.95s/it]\n","model-00042-of-00046.safetensors:   0% 0.00/910M [00:00<?, ?B/s]\u001b[A\n","model-00042-of-00046.safetensors:   1% 10.5M/910M [00:00<00:13, 66.5MB/s]\u001b[A\n","model-00042-of-00046.safetensors:   2% 21.0M/910M [00:03<03:07, 4.75MB/s]\u001b[A\n","model-00042-of-00046.safetensors:   5% 41.9M/910M [00:03<01:12, 12.0MB/s]\u001b[A\n","model-00042-of-00046.safetensors:   7% 62.9M/910M [00:04<00:39, 21.5MB/s]\u001b[A\n","model-00042-of-00046.safetensors:   9% 83.9M/910M [00:04<00:24, 33.5MB/s]\u001b[A\n","model-00042-of-00046.safetensors:  13% 115M/910M [00:04<00:14, 55.1MB/s] \u001b[A\n","model-00042-of-00046.safetensors:  15% 136M/910M [00:04<00:11, 68.8MB/s]\u001b[A\n","model-00042-of-00046.safetensors:  17% 157M/910M [00:04<00:09, 81.6MB/s]\u001b[A\n","model-00042-of-00046.safetensors:  20% 178M/910M [00:04<00:07, 93.7MB/s]\u001b[A\n","model-00042-of-00046.safetensors:  22% 199M/910M [00:04<00:06, 111MB/s] \u001b[A\n","model-00042-of-00046.safetensors:  24% 220M/910M [00:05<00:05, 119MB/s]\u001b[A\n","model-00042-of-00046.safetensors:  26% 241M/910M [00:05<00:05, 123MB/s]\u001b[A\n","model-00042-of-00046.safetensors:  29% 262M/910M [00:05<00:04, 137MB/s]\u001b[A\n","model-00042-of-00046.safetensors:  31% 283M/910M [00:05<00:04, 147MB/s]\u001b[A\n","model-00042-of-00046.safetensors:  33% 304M/910M [00:05<00:03, 159MB/s]\u001b[A\n","model-00042-of-00046.safetensors:  36% 325M/910M [00:05<00:03, 158MB/s]\u001b[A\n","model-00042-of-00046.safetensors:  38% 346M/910M [00:05<00:03, 154MB/s]\u001b[A\n","model-00042-of-00046.safetensors:  40% 367M/910M [00:05<00:03, 159MB/s]\u001b[A\n","model-00042-of-00046.safetensors:  43% 388M/910M [00:06<00:03, 158MB/s]\u001b[A\n","model-00042-of-00046.safetensors:  46% 419M/910M [00:06<00:02, 173MB/s]\u001b[A\n","model-00042-of-00046.safetensors:  48% 440M/910M [00:06<00:02, 176MB/s]\u001b[A\n","model-00042-of-00046.safetensors:  51% 461M/910M [00:06<00:02, 181MB/s]\u001b[A\n","model-00042-of-00046.safetensors:  53% 482M/910M [00:06<00:02, 183MB/s]\u001b[A\n","model-00042-of-00046.safetensors:  56% 514M/910M [00:06<00:02, 189MB/s]\u001b[A\n","model-00042-of-00046.safetensors:  60% 545M/910M [00:06<00:01, 201MB/s]\u001b[A\n","model-00042-of-00046.safetensors:  63% 577M/910M [00:06<00:01, 199MB/s]\u001b[A\n","model-00042-of-00046.safetensors:  67% 608M/910M [00:07<00:01, 209MB/s]\u001b[A\n","model-00042-of-00046.safetensors:  70% 640M/910M [00:07<00:01, 215MB/s]\u001b[A\n","model-00042-of-00046.safetensors:  74% 671M/910M [00:07<00:01, 219MB/s]\u001b[A\n","model-00042-of-00046.safetensors:  77% 703M/910M [00:07<00:00, 228MB/s]\u001b[A\n","model-00042-of-00046.safetensors:  81% 734M/910M [00:07<00:00, 222MB/s]\u001b[A\n","model-00042-of-00046.safetensors:  84% 765M/910M [00:07<00:00, 219MB/s]\u001b[A\n","model-00042-of-00046.safetensors:  88% 797M/910M [00:08<00:00, 145MB/s]\u001b[A\n","model-00042-of-00046.safetensors:  91% 828M/910M [00:08<00:00, 167MB/s]\u001b[A\n","model-00042-of-00046.safetensors:  94% 860M/910M [00:08<00:00, 185MB/s]\u001b[A\n","model-00042-of-00046.safetensors: 100% 910M/910M [00:08<00:00, 105MB/s]\n","Downloading shards:  91% 42/46 [05:51<00:30,  7.51s/it]\n","model-00043-of-00046.safetensors:   0% 0.00/910M [00:00<?, ?B/s]\u001b[A\n","model-00043-of-00046.safetensors:   3% 31.5M/910M [00:00<00:03, 252MB/s]\u001b[A\n","model-00043-of-00046.safetensors:   7% 62.9M/910M [00:00<00:03, 228MB/s]\u001b[A\n","model-00043-of-00046.safetensors:  10% 94.4M/910M [00:04<00:48, 16.8MB/s]\u001b[A\n","model-00043-of-00046.safetensors:  14% 126M/910M [00:04<00:30, 26.1MB/s] \u001b[A\n","model-00043-of-00046.safetensors:  16% 147M/910M [00:04<00:22, 34.0MB/s]\u001b[A\n","model-00043-of-00046.safetensors:  18% 168M/910M [00:04<00:16, 44.3MB/s]\u001b[A\n","model-00043-of-00046.safetensors:  22% 199M/910M [00:04<00:11, 63.3MB/s]\u001b[A\n","model-00043-of-00046.safetensors:  25% 231M/910M [00:04<00:08, 83.0MB/s]\u001b[A\n","model-00043-of-00046.safetensors:  29% 262M/910M [00:05<00:06, 105MB/s] \u001b[A\n","model-00043-of-00046.safetensors:  31% 283M/910M [00:05<00:05, 117MB/s]\u001b[A\n","model-00043-of-00046.safetensors:  33% 304M/910M [00:05<00:04, 129MB/s]\u001b[A\n","model-00043-of-00046.safetensors:  37% 336M/910M [00:05<00:03, 151MB/s]\u001b[A\n","model-00043-of-00046.safetensors:  40% 367M/910M [00:05<00:03, 174MB/s]\u001b[A\n","model-00043-of-00046.safetensors:  44% 398M/910M [00:05<00:02, 184MB/s]\u001b[A\n","model-00043-of-00046.safetensors:  47% 430M/910M [00:05<00:02, 199MB/s]\u001b[A\n","model-00043-of-00046.safetensors:  51% 461M/910M [00:05<00:02, 206MB/s]\u001b[A\n","model-00043-of-00046.safetensors:  54% 493M/910M [00:06<00:02, 199MB/s]\u001b[A\n","model-00043-of-00046.safetensors:  58% 524M/910M [00:06<00:01, 204MB/s]\u001b[A\n","model-00043-of-00046.safetensors:  61% 556M/910M [00:06<00:02, 166MB/s]\u001b[A\n","model-00043-of-00046.safetensors:  63% 577M/910M [00:07<00:05, 59.4MB/s]\u001b[A\n","model-00043-of-00046.safetensors:  66% 598M/910M [00:07<00:04, 68.3MB/s]\u001b[A\n","model-00043-of-00046.safetensors:  68% 619M/910M [00:08<00:03, 79.1MB/s]\u001b[A\n","model-00043-of-00046.safetensors:  70% 640M/910M [00:08<00:02, 92.1MB/s]\u001b[A\n","model-00043-of-00046.safetensors:  73% 661M/910M [00:08<00:02, 106MB/s] \u001b[A\n","model-00043-of-00046.safetensors:  75% 682M/910M [00:08<00:01, 121MB/s]\u001b[A\n","model-00043-of-00046.safetensors:  77% 703M/910M [00:08<00:01, 132MB/s]\u001b[A\n","model-00043-of-00046.safetensors:  79% 724M/910M [00:08<00:01, 147MB/s]\u001b[A\n","model-00043-of-00046.safetensors:  82% 744M/910M [00:08<00:01, 158MB/s]\u001b[A\n","model-00043-of-00046.safetensors:  84% 765M/910M [00:08<00:00, 165MB/s]\u001b[A\n","model-00043-of-00046.safetensors:  86% 786M/910M [00:08<00:00, 156MB/s]\u001b[A\n","model-00043-of-00046.safetensors:  89% 807M/910M [00:09<00:00, 158MB/s]\u001b[A\n","model-00043-of-00046.safetensors:  91% 828M/910M [00:09<00:00, 160MB/s]\u001b[A\n","model-00043-of-00046.safetensors:  93% 849M/910M [00:09<00:00, 163MB/s]\u001b[A\n","model-00043-of-00046.safetensors:  96% 870M/910M [00:09<00:00, 173MB/s]\u001b[A\n","model-00043-of-00046.safetensors: 100% 910M/910M [00:09<00:00, 94.2MB/s]\n","Downloading shards:  93% 43/46 [06:00<00:24,  8.19s/it]\n","model-00044-of-00046.safetensors:   0% 0.00/910M [00:00<?, ?B/s]\u001b[A\n","model-00044-of-00046.safetensors:   2% 21.0M/910M [00:00<00:06, 127MB/s]\u001b[A\n","model-00044-of-00046.safetensors:   5% 41.9M/910M [00:00<00:06, 133MB/s]\u001b[A\n","model-00044-of-00046.safetensors:   7% 62.9M/910M [00:00<00:05, 150MB/s]\u001b[A\n","model-00044-of-00046.safetensors:  10% 94.4M/910M [00:00<00:05, 155MB/s]\u001b[A\n","model-00044-of-00046.safetensors:  13% 115M/910M [00:04<00:55, 14.4MB/s]\u001b[A\n","model-00044-of-00046.safetensors:  16% 147M/910M [00:05<00:32, 23.3MB/s]\u001b[A\n","model-00044-of-00046.safetensors:  20% 178M/910M [00:05<00:20, 35.0MB/s]\u001b[A\n","model-00044-of-00046.safetensors:  23% 210M/910M [00:05<00:14, 49.4MB/s]\u001b[A\n","model-00044-of-00046.safetensors:  25% 231M/910M [00:05<00:11, 60.7MB/s]\u001b[A\n","model-00044-of-00046.safetensors:  28% 252M/910M [00:05<00:09, 72.4MB/s]\u001b[A\n","model-00044-of-00046.safetensors:  31% 283M/910M [00:05<00:06, 96.9MB/s]\u001b[A\n","model-00044-of-00046.safetensors:  35% 315M/910M [00:05<00:05, 118MB/s] \u001b[A\n","model-00044-of-00046.safetensors:  38% 346M/910M [00:05<00:03, 143MB/s]\u001b[A\n","model-00044-of-00046.safetensors:  41% 377M/910M [00:06<00:03, 163MB/s]\u001b[A\n","model-00044-of-00046.safetensors:  45% 409M/910M [00:06<00:02, 172MB/s]\u001b[A\n","model-00044-of-00046.safetensors:  48% 440M/910M [00:06<00:02, 184MB/s]\u001b[A\n","model-00044-of-00046.safetensors:  52% 472M/910M [00:06<00:02, 192MB/s]\u001b[A\n","model-00044-of-00046.safetensors:  55% 503M/910M [00:08<00:10, 39.0MB/s]\u001b[A\n","model-00044-of-00046.safetensors:  59% 535M/910M [00:08<00:07, 52.6MB/s]\u001b[A\n","model-00044-of-00046.safetensors:  62% 566M/910M [00:09<00:04, 69.1MB/s]\u001b[A\n","model-00044-of-00046.safetensors:  66% 598M/910M [00:09<00:03, 87.1MB/s]\u001b[A\n","model-00044-of-00046.safetensors:  69% 629M/910M [00:09<00:02, 100MB/s] \u001b[A\n","model-00044-of-00046.safetensors:  71% 650M/910M [00:09<00:02, 111MB/s]\u001b[A\n","model-00044-of-00046.safetensors:  75% 682M/910M [00:09<00:01, 132MB/s]\u001b[A\n","model-00044-of-00046.safetensors:  77% 703M/910M [00:09<00:01, 144MB/s]\u001b[A\n","model-00044-of-00046.safetensors:  81% 734M/910M [00:09<00:01, 165MB/s]\u001b[A\n","model-00044-of-00046.safetensors:  84% 765M/910M [00:10<00:00, 181MB/s]\u001b[A\n","model-00044-of-00046.safetensors:  88% 797M/910M [00:10<00:00, 188MB/s]\u001b[A\n","model-00044-of-00046.safetensors:  91% 828M/910M [00:10<00:00, 190MB/s]\u001b[A\n","model-00044-of-00046.safetensors:  93% 849M/910M [00:10<00:00, 177MB/s]\u001b[A\n","model-00044-of-00046.safetensors:  97% 881M/910M [00:10<00:00, 188MB/s]\u001b[A\n","model-00044-of-00046.safetensors: 100% 910M/910M [00:10<00:00, 84.6MB/s]\n","Downloading shards:  96% 44/46 [06:11<00:17,  9.00s/it]\n","model-00045-of-00046.safetensors:   0% 0.00/604M [00:00<?, ?B/s]\u001b[A\n","model-00045-of-00046.safetensors:   5% 31.5M/604M [00:00<00:02, 209MB/s]\u001b[A\n","model-00045-of-00046.safetensors:   9% 52.4M/604M [00:00<00:03, 175MB/s]\u001b[A\n","model-00045-of-00046.safetensors:  12% 73.4M/604M [00:00<00:03, 167MB/s]\u001b[A\n","model-00045-of-00046.safetensors:  16% 94.4M/604M [00:00<00:03, 161MB/s]\u001b[A\n","model-00045-of-00046.safetensors:  19% 115M/604M [00:00<00:03, 162MB/s] \u001b[A\n","model-00045-of-00046.safetensors:  24% 147M/604M [00:00<00:02, 181MB/s]\u001b[A\n","model-00045-of-00046.safetensors:  28% 168M/604M [00:00<00:02, 180MB/s]\u001b[A\n","model-00045-of-00046.safetensors:  31% 189M/604M [00:01<00:02, 185MB/s]\u001b[A\n","model-00045-of-00046.safetensors:  35% 210M/604M [00:01<00:02, 178MB/s]\u001b[A\n","model-00045-of-00046.safetensors:  38% 231M/604M [00:01<00:02, 174MB/s]\u001b[A\n","model-00045-of-00046.safetensors:  42% 252M/604M [00:01<00:02, 170MB/s]\u001b[A\n","model-00045-of-00046.safetensors:  45% 273M/604M [00:01<00:02, 164MB/s]\u001b[A\n","model-00045-of-00046.safetensors:  49% 294M/604M [00:04<00:12, 25.6MB/s]\u001b[A\n","model-00045-of-00046.safetensors:  54% 325M/604M [00:04<00:07, 39.3MB/s]\u001b[A\n","model-00045-of-00046.safetensors:  59% 357M/604M [00:04<00:04, 56.4MB/s]\u001b[A\n","model-00045-of-00046.safetensors:  64% 388M/604M [00:04<00:02, 76.2MB/s]\u001b[A\n","model-00045-of-00046.safetensors:  68% 409M/604M [00:04<00:02, 88.8MB/s]\u001b[A\n","model-00045-of-00046.safetensors:  71% 430M/604M [00:04<00:01, 102MB/s] \u001b[A\n","model-00045-of-00046.safetensors:  75% 451M/604M [00:04<00:01, 115MB/s]\u001b[A\n","model-00045-of-00046.safetensors:  78% 472M/604M [00:04<00:01, 129MB/s]\u001b[A\n","model-00045-of-00046.safetensors:  83% 503M/604M [00:05<00:00, 152MB/s]\u001b[A\n","model-00045-of-00046.safetensors:  87% 524M/604M [00:05<00:00, 163MB/s]\u001b[A\n","model-00045-of-00046.safetensors:  92% 556M/604M [00:05<00:00, 184MB/s]\u001b[A\n","model-00045-of-00046.safetensors: 100% 604M/604M [00:05<00:00, 110MB/s]\n","Downloading shards:  98% 45/46 [06:17<00:07,  7.98s/it]\n","model-00046-of-00046.safetensors:   0% 0.00/620M [00:00<?, ?B/s]\u001b[A\n","model-00046-of-00046.safetensors:   5% 31.5M/620M [00:00<00:02, 271MB/s]\u001b[A\n","model-00046-of-00046.safetensors:  10% 62.9M/620M [00:00<00:02, 241MB/s]\u001b[A\n","model-00046-of-00046.safetensors:  15% 94.4M/620M [00:00<00:02, 234MB/s]\u001b[A\n","model-00046-of-00046.safetensors:  20% 126M/620M [00:00<00:02, 223MB/s] \u001b[A\n","model-00046-of-00046.safetensors:  25% 157M/620M [00:00<00:02, 172MB/s]\u001b[A\n","model-00046-of-00046.safetensors:  29% 178M/620M [00:01<00:03, 140MB/s]\u001b[A\n","model-00046-of-00046.safetensors:  32% 199M/620M [00:02<00:09, 44.5MB/s]\u001b[A\n","model-00046-of-00046.safetensors:  37% 231M/620M [00:02<00:06, 62.7MB/s]\u001b[A\n","model-00046-of-00046.safetensors:  41% 252M/620M [00:02<00:04, 76.4MB/s]\u001b[A\n","model-00046-of-00046.safetensors:  44% 273M/620M [00:02<00:03, 91.1MB/s]\u001b[A\n","model-00046-of-00046.safetensors:  49% 304M/620M [00:02<00:02, 118MB/s] \u001b[A\n","model-00046-of-00046.safetensors:  54% 336M/620M [00:03<00:01, 143MB/s]\u001b[A\n","model-00046-of-00046.safetensors:  58% 357M/620M [00:03<00:01, 138MB/s]\u001b[A\n","model-00046-of-00046.safetensors:  63% 388M/620M [00:03<00:01, 153MB/s]\u001b[A\n","model-00046-of-00046.safetensors:  66% 409M/620M [00:03<00:01, 163MB/s]\u001b[A\n","model-00046-of-00046.safetensors:  69% 430M/620M [00:03<00:01, 173MB/s]\u001b[A\n","model-00046-of-00046.safetensors:  73% 451M/620M [00:03<00:00, 181MB/s]\u001b[A\n","model-00046-of-00046.safetensors:  78% 482M/620M [00:03<00:00, 193MB/s]\u001b[A\n","model-00046-of-00046.safetensors:  81% 503M/620M [00:04<00:00, 129MB/s]\u001b[A\n","model-00046-of-00046.safetensors:  86% 535M/620M [00:04<00:00, 157MB/s]\u001b[A\n","model-00046-of-00046.safetensors:  90% 556M/620M [00:04<00:00, 162MB/s]\u001b[A\n","model-00046-of-00046.safetensors:  95% 587M/620M [00:04<00:00, 179MB/s]\u001b[A\n","model-00046-of-00046.safetensors: 100% 620M/620M [00:04<00:00, 134MB/s]\n","Downloading shards: 100% 46/46 [06:22<00:00,  8.31s/it]\n","[INFO|modeling_utils.py:1606] 2024-09-16 18:45:42,383 >> Instantiating GPTNeoXForCausalLM model under default dtype torch.bfloat16.\n","[INFO|configuration_utils.py:1038] 2024-09-16 18:45:42,385 >> Generate config GenerationConfig {\n","  \"bos_token_id\": 0,\n","  \"eos_token_id\": 0\n","}\n","\n","Loading checkpoint shards:  37% 17/46 [01:11<02:01,  4.19s/it]\n","Traceback (most recent call last):\n","  File \"/usr/local/bin/llamafactory-cli\", line 8, in <module>\n","    sys.exit(main())\n","  File \"/content/LLaMA-Factory/src/llamafactory/cli.py\", line 111, in main\n","    run_exp()\n","  File \"/content/LLaMA-Factory/src/llamafactory/train/tuner.py\", line 54, in run_exp\n","    run_ppo(model_args, data_args, training_args, finetuning_args, generating_args, callbacks)\n","  File \"/content/LLaMA-Factory/src/llamafactory/train/ppo/workflow.py\", line 46, in run_ppo\n","    model = load_model(tokenizer, model_args, finetuning_args, training_args.do_train, add_valuehead=True)\n","  File \"/content/LLaMA-Factory/src/llamafactory/model/loader.py\", line 162, in load_model\n","    model = load_class.from_pretrained(**init_kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\", line 564, in from_pretrained\n","    return model_class.from_pretrained(\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\", line 3960, in from_pretrained\n","    ) = cls._load_pretrained_model(\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\", line 4434, in _load_pretrained_model\n","    new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(\n","  File \"/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\", line 961, in _load_state_dict_into_meta_model\n","    set_module_tensor_to_device(model, param_name, param_device, **set_module_kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/accelerate/utils/modeling.py\", line 416, in set_module_tensor_to_device\n","    new_value = value.to(device)\n","torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 288.00 MiB. GPU \n"]}]}]}